{"pages":[{"title":"404","text":"&lt;!DOCTYPE html&gt; 404 &lt;!DOCTYPE html&gt; 404","link":"/404/index.html"},{"title":"开发者以技术为中心","text":"如果你想联系我微信: 17663083790 邮箱: 17663083790@163.com QQ: 3230452986","link":"/about/index.html"},{"title":"分类","text":"","link":"/categories/index.html"}],"posts":[{"title":"Hexo+GitHub搭建个人博客  for Windows","text":"hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 绑定一下github,就可以让别人通过你自定义的域名来访问你的博客, 我使用的正是Hexo的框架,我的博客地址 : https://aaatao66.github.io/ 1.安装 node.jsnode.js 官方网站: https://nodejs.org/zh-cn/ node是我们搭建博客必须的一个插件,下载长期支持版就ok了,安装很简单,与其他软件没区别,一直点下一步就好了 安装完成后除了node.js本身,还有npm管理器 1cmd输入 npm -v 查看一下版本,我这里用的6.4.1版本 2.安装 gitgit 官方网站 git官网：https://git-scm.com/ 这个我就不发图了,你如果不会用的话,可以去这个廖雪峰老师的网站: https://www.liaoxuefeng.com/wiki/896043488029600&gt; 廖雪峰老师讲的很详细,百万级别的阅读量不是闹着玩的 现在你的输入 node -v npm -v git –version看一下版本号说明成功了 12345678C:\\Users\\My&gt;node -vv10.15.3C:\\Users\\My&gt;npm -v6.4.1C:\\Users\\My&gt;git --versiongit version 2.21.0.windows.1 3.github我们需要一个github的账号,如果你没有,那就去注册个 鼠标右键&gt;打开Git Bash(接下来的命令基于这里面运行) 这里👇输入你自己的用户名和邮箱(不要输错) 12git config --global user.name \"GitHub 用户名\"git config --global user.email \"GitHub 邮箱\" 👇创建一个SSH密匙 1ssh-keygen -t rsa -C \"GitHub 邮箱\" 目录是自动生成的,可以看一下我的目录,id_rsa.pub里面就是你的密匙,复制它 进入你的github选择&gt;setting 4.创建 GitHub Pages (仓库)在你的github主页, ​ 点击右上角 + 号 &gt; New repository ​ Repository name 中输入 用户名.github.io ​ 勾选 “Initialize this repository with a README” ​ Description 选填 点Create repository后你的博客地址就生成了 地址为: https://用户名.github.io 5.修改一下hexo目录下的config.yml文件 repo输入你自己的地址,地址就是你刚才建的pages里 6.本地安装 Hexo 博客程序新建一个文件夹,专门存放hexo以及你的博客文章的,参考我的这个也行 重点 : 如果你想对hexo进行操作,无论是Git Bash 还是 CMD ,都必须再这个目录下进行 安装Hexo命令👇 1npm install -g hexo-cli 这应该是从国外进行下载过来的,有点慢,你可以等待下载过程,不然你也知道该怎么做 初始化and安装组件 12hexo init 初始化npm install 安装组件 完成后输入下面命令👇 hexo g 就是生成静态页面 hexo s 就是 server的意思 启动你的本地服务器(类似tomcat启动) 12hexo g hexo s 启动后访问:http://localhost:4000,希望你可以访问成功,没成功也没关系,hexo这个框架非常的火,以至于网上有关于它的各种解决方案,如果你遇到了什么问题,可以通过搜索引擎解决你的问题 123hexo clean 清理一下缓存,如果你修改的主题或上传文章什么的,刷新网页不管用,那你可以clean一下hexo g 生成静态页面hexo d 上传github 执行好上面的命令你就可以访问真正的域名: 用户名.github.io 例如我的 : https://aaatao66.github.io/ 什么?你说自带的主题太丑了?好吧! 打开github &gt; 搜索 hexo theme &gt;下载一个自己喜欢的风格&gt;把下载好的文件夹放在你刚刚建立的hexo文件夹里的 ..:.….\\Hexo\\themes文件夹里 然后回到hexo文件夹 用文本方式打开 _config.yml &gt;找到 theme : XXX &gt;xxx就是你刚刚下载的主题的文件夹名字 再次 hexo clean 一下 然后 hexo s进入预览一下,有可能会很慢,稍等再shift+f5刷新一下","link":"/2019/05/20/Hexo+GitHub-for-Windows/"},{"title":"Hadoop生态圈一文概览","text":"转自知乎: 如何形象的比喻大数据技术生态? 这些回答太好了,以致于我不禁想放到自己的博客上,文章末尾有原地址 有大数据,不得不提Google的3篇论文,大数据江湖因为这三篇论文兴起! 《Google file system》：论述了怎样借助普通机器有效的存储海量的大数据； 《Google MapReduce》：论述了怎样快速计算海量的数据； 《Google BigTable》：论述了怎样实现海量数据的快速查询； 中文版 大数据本身是个很宽泛的概念，Hadoop生态圈（或者泛生态圈）基本上都是为了处理超过单机尺度的数据处理而诞生的。你可以把它比作一个厨房所以需要的各种工具。锅碗瓢盆，各有各的用处，互相之间又有重合。你可以用汤锅直接当碗吃饭喝汤，你可以用小刀或者刨子去皮。但是每个工具有自己的特性，虽然奇怪的组合也能工作，但是未必是最佳选择。 大数据，首先你要能存的下大数据。传统的文件系统是单机的，不能横跨不同的机器。HDFS（Hadoop Distributed FileSystem）的设计本质上是为了大量的数据能横跨成百上千台机器，但是你看到的是一个文件系统而不是很多文件系统。比如你说我要获取/hdfs/tmp/file1的数据，你引用的是一个文件路径，但是实际的数据存放在很多不同的机器上。你作为用户，不需要知道这些，就好比在单机上你不关心文件分散在什么磁道什么扇区一样。HDFS为你管理这些数据。 存的下数据之后，你就开始考虑怎么处理数据。虽然HDFS可以为你整体管理不同机器上的数据，但是这些数据太大了。一台机器读取成T上P的数据（很大的数据哦，比如整个东京热有史以来所有高清电影的大小甚至更大），一台机器慢慢跑也许需要好几天甚至好几周。对于很多公司来说，单机处理是不可忍受的，比如微博要更新24小时热博，它必须在24小时之内跑完这些处理。那么我如果要用很多台机器处理，我就面临了如何分配工作，如果一台机器挂了如何重新启动相应的任务，机器之间如何互相通信交换数据以完成复杂的计算等等。这就是MapReduce / Tez / Spark的功能。MapReduce是第一代计算引擎，Tez和Spark是第二代。MapReduce的设计，采用了很简化的计算模型，只有Map和Reduce两个计算过程（中间用Shuffle串联），用这个模型，已经可以处理大数据领域很大一部分问题了。那什么是Map什么是Reduce？考虑如果你要统计一个巨大的文本文件存储在类似HDFS上，你想要知道这个文本里各个词的出现频率。你启动了一个MapReduce程序。Map阶段，几百台机器同时读取这个文件的各个部分，分别把各自读到的部分分别统计出词频，产生类似（hello, 12100次），（world，15214次）等等这样的Pair（我这里把Map和Combine放在一起说以便简化）；这几百台机器各自都产生了如上的集合，然后又有几百台机器启动Reduce处理。Reducer机器A将从Mapper机器收到所有以A开头的统计结果，机器B将收到B开头的词汇统计结果（当然实际上不会真的以字母开头做依据，而是用函数产生Hash值以避免数据串化。因为类似X开头的词肯定比其他要少得多，而你不希望数据处理各个机器的工作量相差悬殊）。然后这些Reducer将再次汇总，（hello，12100）＋（hello，12311）＋（hello，345881）= （hello，370292）。每个Reducer都如上处理，你就得到了整个文件的词频结果。这看似是个很简单的模型，但很多算法都可以用这个模型描述了。Map＋Reduce的简单模型很黄很暴力，虽然好用，但是很笨重。第二代的Tez和Spark除了内存Cache之类的新feature，本质上来说，是让Map/Reduce模型更通用，让Map和Reduce之间的界限更模糊，数据交换更灵活，更少的磁盘读写，以便更方便地描述复杂算法，取得更高的吞吐量。 有了MapReduce，Tez和Spark之后，程序员发现，MapReduce的程序写起来真麻烦。他们希望简化这个过程。这就好比你有了汇编语言，虽然你几乎什么都能干了，但是你还是觉得繁琐。你希望有个更高层更抽象的语言层来描述算法和数据处理流程。于是就有了Pig和Hive。Pig是接近脚本方式去描述MapReduce，Hive则用的是SQL。它们把脚本和SQL语言翻译成MapReduce程序，丢给计算引擎去计算，而你就从繁琐的MapReduce程序中解脱出来，用更简单更直观的语言去写程序了。 有了Hive之后，人们发现SQL对比Java有巨大的优势。一个是它太容易写了。刚才词频的东西，用SQL描述就只有一两行，MapReduce写起来大约要几十上百行。而更重要的是，非计算机背景的用户终于感受到了爱：我也会写SQL！于是数据分析人员终于从乞求工程师帮忙的窘境解脱出来，工程师也从写奇怪的一次性的处理程序中解脱出来。大家都开心了。Hive逐渐成长成了大数据仓库的核心组件。甚至很多公司的流水线作业集完全是用SQL描述，因为易写易改，一看就懂，容易维护。 自从数据分析人员开始用Hive分析数据之后，它们发现，Hive在MapReduce上跑，真鸡巴慢！流水线作业集也许没啥关系，比如24小时更新的推荐，反正24小时内跑完就算了。但是数据分析，人们总是希望能跑更快一些。比如我希望看过去一个小时内多少人在充气娃娃页面驻足，分别停留了多久，对于一个巨型网站海量数据下，这个处理过程也许要花几十分钟甚至很多小时。而这个分析也许只是你万里长征的第一步，你还要看多少人浏览了跳蛋多少人看了拉赫曼尼诺夫的CD，以便跟老板汇报，我们的用户是猥琐男闷骚女更多还是文艺青年／少女更多。你无法忍受等待的折磨，只能跟帅帅的工程师蝈蝈说，快，快，再快一点！于是Impala，Presto，Drill诞生了（当然还有无数非著名的交互SQL引擎，就不一一列举了）。三个系统的核心理念是，MapReduce引擎太慢，因为它太通用，太强壮，太保守，我们SQL需要更轻量，更激进地获取资源，更专门地对SQL做优化，而且不需要那么多容错性保证（因为系统出错了大不了重新启动任务，如果整个处理时间更短的话，比如几分钟之内）。这些系统让用户更快速地处理SQL任务，牺牲了通用性稳定性等特性。如果说MapReduce是大砍刀，砍啥都不怕，那上面三个就是剔骨刀，灵巧锋利，但是不能搞太大太硬的东西。 这些系统，说实话，一直没有达到人们期望的流行度。因为这时候又两个异类被造出来了。他们是Hive on Tez / Spark和SparkSQL。它们的设计理念是，MapReduce慢，但是如果我用新一代通用计算引擎Tez或者Spark来跑SQL，那我就能跑的更快。而且用户不需要维护两套系统。这就好比如果你厨房小，人又懒，对吃的精细程度要求有限，那你可以买个电饭煲，能蒸能煲能烧，省了好多厨具。 上面的介绍，基本就是一个数据仓库的构架了。底层HDFS，上面跑MapReduce／Tez／Spark，在上面跑Hive，Pig。或者HDFS上直接跑Impala，Drill，Presto。这解决了中低速数据处理的要求。 那如果我要更高速的处理呢？如果我是一个类似微博的公司，我希望显示不是24小时热博，我想看一个不断变化的热播榜，更新延迟在一分钟之内，上面的手段都将无法胜任。于是又一种计算模型被开发出来，这就是Streaming（流）计算。Storm是最流行的流计算平台。流计算的思路是，如果要达到更实时的更新，我何不在数据流进来的时候就处理了？比如还是词频统计的例子，我的数据流是一个一个的词，我就让他们一边流过我就一边开始统计了。流计算很牛逼，基本无延迟，但是它的短处是，不灵活，你想要统计的东西必须预先知道，毕竟数据流过就没了，你没算的东西就无法补算了。因此它是个很好的东西，但是无法替代上面数据仓库和批处理系统。 还有一个有些独立的模块是KV Store，比如Cassandra，HBase，MongoDB以及很多很多很多很多其他的（多到无法想象）。所以KV Store就是说，我有一堆键值，我能很快速滴获取与这个Key绑定的数据。比如我用身份证号，能取到你的身份数据。这个动作用MapReduce也能完成，但是很可能要扫描整个数据集。而KV Store专用来处理这个操作，所有存和取都专门为此优化了。从几个P的数据中查找一个身份证号，也许只要零点几秒。这让大数据公司的一些专门操作被大大优化了。比如我网页上有个根据订单号查找订单内容的页面，而整个网站的订单数量无法单机数据库存储，我就会考虑用KV Store来存。KV Store的理念是，基本无法处理复杂的计算，大多没法JOIN，也许没法聚合，没有强一致性保证（不同数据分布在不同机器上，你每次读取也许会读到不同的结果，也无法处理类似银行转账那样的强一致性要求的操作）。但是丫就是快。极快。每个不同的KV Store设计都有不同取舍，有些更快，有些容量更高，有些可以支持更复杂的操作。必有一款适合你。 除此之外，还有一些更特制的系统／组件，比如Mahout是分布式机器学习库，Protobuf是数据交换的编码和库，ZooKeeper是高一致性的分布存取协同系统，等等。 有了这么多乱七八糟的工具，都在同一个集群上运转，大家需要互相尊重有序工作。所以另外一个重要组件是，调度系统。现在最流行的是Yarn。你可以把他看作中央管理，好比你妈在厨房监工，哎，你妹妹切菜切完了，你可以把刀拿去杀鸡了。只要大家都服从你妈分配，那大家都能愉快滴烧菜。 你可以认为，大数据生态圈就是一个厨房工具生态圈。为了做不同的菜，中国菜，日本菜，法国菜，你需要各种不同的工具。而且客人的需求正在复杂化，你的厨具不断被发明，也没有一个万用的厨具可以处理所有情况，因此它会变的越来越复杂。 作者: xiaoyu Ma 学习很重要的是能将纷繁复杂的信息进行归类和抽象。对应到大数据技术体系，虽然各种技术百花齐放，层出不穷，但大数据技术本质上无非解决4个核心问题。 存储，海量的数据怎样有效的存储？主要包括hdfs、Kafka； 计算，海量的数据怎样快速计算？主要包括MapReduce、Spark、Flink等； 查询，海量数据怎样快速查询？主要为Nosql和Olap，Nosql主要包括Hbase、 Cassandra 等，其中olap包括kylin、impla等，其中Nosql主要解决随机查询，Olap技术主要解决关联查询； 挖掘，海量数据怎样挖掘出隐藏的知识？也就是当前火热的机器学习和深度学习等技术，包括TensorFlow、caffe、mahout等； 大数据技术生态其实是一个江湖…. 在一个夜黑风高的晚上，江湖第一大帮会Google三本阵法修炼秘籍流出，大数据技术江湖从此纷争四起、永无宁日… 这三本秘籍分别为： 《Google file system》：论述了怎样借助普通机器有效的存储海量的大数据； 《Google MapReduce》：论述了怎样快速计算海量的数据； 《Google BigTable》：论述了怎样实现海量数据的快速查询； 以上三篇论文秘籍是大数据入门的最好文章，通俗易懂，先看此三篇再看其它技术； 在Google三大秘籍流出之后，江湖上，致力于武学开放的apache根据这三本秘籍分别研究出了对应的武学巨著《hadoop》，并开放给各大门派研习，Hadoop包括三大部分，分别是hdfs、MapReduce和hbase：hdfs解决大数据的存储问题。mapreduce解决大数据的计算问题。hbase解决大数据量的查询问题。 之后，在各大门派的支持下，Hadoop不断衍生和进化各种分支流派，其中最激烈的当属计算技术，其次是查询技术。存储技术基本无太多变化，hdfs一统天下。 以下为大概的演进： 1，传统数据仓库派说你mapreduce修炼太复杂，老子不会编程，老子以前用sql吃遍天下，为了将这拨人收入门下，并降低大数据修炼难度，遂出了hive，pig、impla等SQL ON Hadoop的简易修炼秘籍； 2，伯克利派说你MapReduce只重招数，内力无法施展，且不同的场景需要修炼不同的技术，太过复杂，于是推出基于内力（内存）的《Spark》，意图解决所有大数据计算问题。 3，流式计算相关门派说你hadoop只能憋大招（批量计算），太麻烦，于是出了SparkStreaming、Storm，S4等流式计算技术，能够实现数据一来就即时计算。 4，apache看各大门派纷争四起，推出flink，想一统流计算和批量计算的修炼； 作者：有点文","link":"/2019/06/15/Hadoop生态圈一文概览/"},{"title":"HBase-API操作","text":"HBas是Hadoop数据库，是一个分布式，可扩展的大数据存储。 这一章博客不介绍如何搭建Hbase,只介绍API代码的编写 HBase官方网站: https://hbase.apache.org/ HBase中文文档: http://abloz.com/hbase/book.html 为什么要用Hbase?来看看官方解释: Apache HBase™ is the Hadoop database, a distributed, scalable, big data store. Use Apache HBase™ when you need random, realtime read/write access to your Big Data. This project’s goal is the hosting of very large tables – billions of rows X millions of columns – atop clusters of commodity hardware. Apache HBase is an open-source, distributed, versioned, non-relational database modeled after Google’s Bigtable: A Distributed Storage System for Structured Data by Chang et al. Just as Bigtable leverages the distributed data storage provided by the Google File System, Apache HBase provides Bigtable-like capabilities on top of Hadoop and HDFS. 大概意思是: 当你需要对大量数据进行随机,实时读/写的操作时,请使用HBase,该项目致力于非常量大的表-数十亿行&amp;百万列- 它是一个开源,面向列,分布式(包括高并发)的非关系数据库(NoSql),基于Hadoop,并存储在HDFS之上 这代表它能够运行在廉价的PC server上搭建大规模的结构化存储集群,关系型数据库无法满足数据疯狂增长的需求,但HBase可以! 我的开发环境 Linux-CentOs(VMware10虚拟机 3台) win10 idea 2019.1.1 jdk1.8 Maven 基本概念RowKey：是Byte array，是表中每条记录的“主键”，方便快速查找，Rowkey的设计非常重要，后面在重点讲讲我们在RowKey的设计上遇到过的坑。 Column Family：列族，拥有一个名称(string)，包含一个或者多个相关列 Column：属于某一个columnfamily，familyName:columnName，每条记录可动态添加 Version Number：类型为Long，默认值是系统时间戳，可由用户自定义 Value(Cell)：Byte array 创建HBase项目 创建一个普通的maven项目 导入依赖: 123456789101112131415&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt; &lt;artifactId&gt;hbase-client&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 创建类MyBaseAPI,编写代码,注意看注释 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176package com.ujiuye;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.hbase.*;import org.apache.hadoop.hbase.client.*;import org.apache.hadoop.hbase.util.Bytes;import org.junit.Before;import org.junit.Test;import java.util.ArrayList;import java.util.List;public class MyHBaseAPI { //此方法创建使用HBase的资源配置 private Configuration conf = null; @Before// 获取配置对象 public void getConfiguration() throws Exception { // 通过类提供的方法获取配置对象 conf = HBaseConfiguration.create(); conf.set(\"hbase.zookeeper.quorum\", \"hadoop101\"); conf.set(\"hbase.zookeeper.property.clientPort\", \"2181\"); } //判断表是否存在 @Test public void tableExist() throws Exception { // 1.拿到连接 Connection conn = ConnectionFactory.createConnection(conf); // 2.通过连接拿到hbase的客户端对象 HBaseAdmin admin = (HBaseAdmin) conn.getAdmin(); // 3.开始操作 boolean tableExist = admin.tableExists(\"user\"); if (tableExist) { System.out.println(\"表存在\"); } else { System.out.println(\"表不存在\"); } } //创建表 @Test public void createTable() throws Exception { // 1.拿到连接 Connection conn = ConnectionFactory.createConnection(conf); // 2.通过连接拿到 hbase 的客户端对象 HBaseAdmin admin = (HBaseAdmin) conn.getAdmin(); // 3.创建表描述器 HTableDescriptor tableDescriptor = new HTableDescriptor(TableName.valueOf(\"user\")); // 4.设置列族 tableDescriptor.addFamily(new HColumnDescriptor(\"info\")); // 5.执行 创建表 admin.createTable(tableDescriptor); System.out.println(\"表创建成功\"); } // 删除表 @Test public void deleteTable() throws Exception { // 1.拿到连接 Connection conn = ConnectionFactory.createConnection(conf); // 2.通过连接拿到 hbase 的客户端对象 HBaseAdmin admin = (HBaseAdmin) conn.getAdmin(); // 3,禁用表 admin.disableTable(\"user\"); // 4.删除表 admin.deleteTable(\"user\"); System.out.println(\"表删除成功\"); } //向表中插入数据 @Test public void insertData() throws Exception { // 1.拿到连接 Connection conn = ConnectionFactory.createConnection(conf); // 2.通过连接拿到 hbase 的客户端对象 HBaseAdmin admin = (HBaseAdmin) conn.getAdmin(); Table table = conn.getTable(TableName.valueOf(\"user\")); // 3. 封装数据,注意要用hbase提供的工具来转化为字节数组，不要用字符串的getBytes方法 Put put = new Put(Bytes.toBytes(\"1001\")); // 4.设置 列族 类名 值 put.addColumn(Bytes.toBytes(\"info\"), Bytes.toBytes(\"name\"), Bytes.toBytes(\"zhangsan\")); // 5. 向表中插入数据 table.put(put); } //批量插入数据 @Test public void insertDatas() throws Exception { // 拿到连接 Connection conn = ConnectionFactory.createConnection(conf); // 获取表 Table table = conn.getTable(TableName.valueOf(\"user\")); // 批量插入数据 Put put = new Put(Bytes.toBytes(\"1001\")); // 设置 列族 类名 值 put.addColumn(Bytes.toBytes(\"info\"), Bytes.toBytes(\"name\"), Bytes.toBytes(\"zhangsan\")); Put put2 = new Put(Bytes.toBytes(\"1002\")); // 设置 列族 类名 值 put2.addColumn(Bytes.toBytes(\"info\"), Bytes.toBytes(\"name\"), Bytes.toBytes(\"wangwu\")); List&lt;Put&gt; list = new ArrayList&lt;Put&gt;(); list.add(put); list.add(put2); table.put(list); // 关闭 table.close(); } // 删除一行数据 / 多行数据 @Test public void deleteData() throws Exception { // 1.拿到连接 Connection conn = ConnectionFactory.createConnection(conf); // 2.通过连接拿到 hbase 的客户端对象// HBaseAdmin admin = (HBaseAdmin) conn.getAdmin(); Table table = conn.getTable(TableName.valueOf(\"user\"));// Delete delete = new Delete(Bytes.toBytes(\"1002\"));// table.delete(delete); // 批量删除 Delete delete = new Delete(Bytes.toBytes(\"1001\")); Delete delete1 = new Delete(Bytes.toBytes(\"1002\")); List&lt;Delete&gt; list = new ArrayList&lt;Delete&gt;(); list.add(delete); list.add(delete1); table.delete(list); } // 获取所有数据 @Test public void getAllData() throws Exception { // 1.拿到连接 Connection conn = ConnectionFactory.createConnection(conf); // 2.获取表 Table table = conn.getTable(TableName.valueOf(\"user\")); // 3.构造一个 scan 对象 Scan scan = new Scan(Bytes.toBytes(\"\")); ResultScanner scanner = table.getScanner(scan); for (Result result : scanner) { Cell[] rawCells = result.rawCells();// 获取某一行数据 for (Cell cell : rawCells) { String row = Bytes.toString(CellUtil.cloneRow(cell)); String cf = Bytes.toString(CellUtil.cloneFamily(cell)); String cl = Bytes.toString(CellUtil.cloneQualifier(cell)); String va = Bytes.toString(CellUtil.cloneValue(cell)); System.out.println(row+\"---\"+cf+\"---\"+cl+\"---\"+va); } } } // 获取某一行数据,指定列族,列 @Test public void getSomeData() throws Exception{ // 1.拿到连接 和 表 Connection conn = ConnectionFactory.createConnection(conf); Table table = conn.getTable(TableName.valueOf(\"user\")); Get get = new Get(Bytes.toBytes(\"1001\")); Result result = table.get(get); Cell[] rawCells = result.rawCells();//获取某一行的所有数据 for (Cell cell : rawCells) { String row = Bytes.toString(CellUtil.cloneRow(cell)); String cf = Bytes.toString(CellUtil.cloneFamily(cell)); String cl = Bytes.toString(CellUtil.cloneQualifier(cell)); String va = Bytes.toString(CellUtil.cloneValue(cell)); System.out.println(row+\"---\"+cf+\"---\"+cl+\"---\"+va); } }} HBase Shell简单验证操作说几个HBase Shell的基本操作,不然都不知道怎么验证上面的代码 首先启动HBase [root@hadoop101 hbase] $ bin/start-hbase.sh 然后进入HBase Shell命令行操作 在Shell操作的时候如果需要后退直接按 Backspace 是不行的,必须Ctrl+Backspace [root@hadoop101 hbase]$ bin/hbase shell 查看当前数据库有哪些表 hbase(main):002:0&gt; list 查询表数据 scan+’表名’ STARTROW是开始行 到 STOPROW结束行,无STOPROW的话是到最后 hbase(main):008:0&gt; scan ‘student’ hbase(main):009:0&gt; scan ‘student’,{STARTROW =&gt; ‘1001’, STOPROW =&gt; ‘1002’} hbase(main):010:0&gt; scan ‘student’,{STARTROW =&gt; ‘1001’} 验证代码一个 scan 就够了, 内存优化HBase操作过程中需要大量的内存开销，毕竟Table是可以缓存在内存中的，一般会分配整个可用内存的70%给HBase的Java堆。但是不建议分配非常大的堆内存，因为GC过程持续太久会导致RegionServer处于长期不可用状态，一般16~48G内存就可以了，如果因为框架占用内存过高导致系统内存不足，框架一样会被系统服务拖死。 HBase在商业项目中的能力每天： 消息量：发送和接收的消息数超过60亿 将近1000亿条数据的读写 高峰期每秒150万左右操作 整体读取数据占有约55%，写入占有45% 超过2PB的数据，涉及冗余共6PB数据 数据每月大概增长300千兆字节。 我只是拿我自己的博客当一个笔记而已,如有类似,纯属雷同 关于我","link":"/2019/06/12/HBaseAPI/"},{"title":"Spring Boot深入系列--配置文件","text":"开发环境: win10 jdk1.8 idea2019 maven 3.2.5 Spring Boot v2.1.5.RELEASE (版本) 1. yml文件的语法概览:12345678910111213141516171819202122232425262728293031323334person: lastNAME: carson age: 18 boss: true birth: 1234/12/12 #map写法: {k: v,k2: v2} maps: {k1: v1,k2: v2} #数组写法: -值 lists: - lisi - zhangsan - wangwu - zhaoliu dog: name: 小狗 age: 3spring: mvc: view: prefix: /WEB-INF/views/ suffix: .jsp datasource: url: jdbc:mysql:///ssm username: root password: root driver-class-name: com.mysql.jdbc.Driver jpa: hibernate: ddl-auto: updateserver: port: 9090 2. @Value获取值和 @ConfigurationProperties获取值比较 @ConfigurationProperties @Value 功能 批量注入配置文件中的属性 一个个指定 松散绑定(松散语法)大小写 支持 不支持 SpEL表达式 不支持 支持 JSR303数据校验 支持 不支持 复杂类型封装 支持 不支持 这两种方式都能获取值: 如果,我们只是在某个业务逻辑中需要获取一下配置文件中的某项值,使用@Value 如果,我们专门编写了一个javaBean来和配置文件进行映射;@ConfigurationProperties @Validated @Value 12345678910111213141516171819@Getter@Setter@ToString@Component//@ConfigurationProperties (prefix = \"person\")@Validated // 来校验数据，如果数据异常则会统一抛出异常，方便异常中心统一处理。public class Person { // @Email @Value(\"${person.lastNAME}\") private String lastNAME; @Value(\"#{3*3}\") private Integer age; private Boolean boss; private Date birth; private Map&lt;String,Object&gt; maps; private List&lt;Object&gt; lists; private Dog dog;} 3. @PropertySource&amp;@ImportResource因为 @ConfigurationProperties 是全局注解,如果想指定的话 @PropertySource:可以指定某个文件 @PropertySource(“classpath: xxx.properties) @ImportResource: 导入Spring配置文件,让配置文件里面的内容生效 创建一个HelloService 类 如果没有注解情况下 1234567&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean id=\"helloService\" class=\"com.carson.springboot.service.impl.HelloService\"&gt;&lt;/bean&gt;&lt;/beans&gt; 123456789@Autowired ApplicationContext ioc; @Test public void testHelloService(){ // 是否是包含 这个 bean boolean b = ioc.containsBean(\"helloService\"); System.out.println(b);//false } false 说明Spring Boot 里面没有Spring的配置文件,我们自己编写的配置文件,也不能自动识别 如果想让Spring的配置文件生效,加载进来; 就 把@ImportResource标注在一个配置类上 主类 123456789@ImportResource(locations = {\"classpath:beans.xml\"})@SpringBootApplicationpublic class SpringbootApplication { public static void main(String[] args) { SpringApplication.run(SpringbootApplication.class, args); }} 123456789@Autowired ApplicationContext ioc; @Test public void testHelloService(){ // 是否是包含 这个 bean boolean b = ioc.containsBean(\"helloService\"); System.out.println(b);//true } SpringBoot推荐给容器中添加组件的方式: 使用 @Bean 1, 配置类======Spring配置文件 建一个包 config,专门放配置类:MyAppConfig123456789101112131415/** * @Configuration: 指明当前类是一个配置类;就是来代替之前的Spring配置文件 * * 以前配置文件总 用 &lt;bean&gt;&lt;/bean&gt; 标签添加组件 */@Configurationpublic class MyAppConfig { // 将方法的返回值添加到容器中,容器中这几个组件默认的id就是方法名 @Bean public HelloService helloService(){ return new HelloService(); }} 记得把之前主类的@ImportResource注解 去掉! 12345678910111213141516输出结果: . ____ _ __ _ _ /\\\\ / ___&apos;_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | &apos;_ | &apos;_| | &apos;_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) &apos; |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.1.5.RELEASE)2019-06-29 16:53:48.081 INFO 11084 --- [ main] c.c.s.SpringbootApplicationTests : Starting SpringbootApplicationTests on DESKTOP-JBSD6AK with PID 11084 (started by My in F:\\code\\springboot)2019-06-29 16:53:48.083 INFO 11084 --- [ main] c.c.s.SpringbootApplicationTests : No active profile set, falling back to default profiles: default2019-06-29 16:53:52.689 INFO 11084 --- [ main] o.s.s.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService &apos;applicationTaskExecutor&apos;2019-06-29 16:53:53.988 INFO 11084 --- [ main] c.c.s.SpringbootApplicationTests : Started SpringbootApplicationTests in 7.259 seconds (JVM running for 10.759)true 2019-06-29 16:53:54.433 INFO 11084 --- [ Thread-3] o.s.s.concurrent.ThreadPoolTaskExecutor : Shutting down ExecutorService &apos;applicationTaskExecutor&apos; 也是 true 4. 配置文件里的 ${}random随机数12345${random.value}${random.int}${random.long}${random.int(10)}${random.int[1024,65536]} ${} 获取 之前配置的值1234567891011121314person: lastNAME: bob${random.uuid} age: ${random.int} boss: true birth: 1234/12/12 maps: {k1: v1,k2: v2} lists: - lisi - zhangsan - wangwu - zhaoliu dog: name: ${person.lastNAME}_dog age: 3 如果 12 dog:name: ${person.lastNAME}_dog 如果lastNAME没有的话, 那就 12 dog:name: ${person.lastNAME:hello}_dog 5. Profile5.1 多个Profile 文件 Profile是Spring对不同环境提供不同配置功能的支持,可以通过指定参数等方式快速切换环境 比如我配置3个端口,一个默认的,一个dev(开发),一个prod(测试) 主配置文件名可以是 application.yml/application.properties 默认使用application.yml的配置; 5.2 yml的多文档块以 — 分隔 文档快 123456789101112131415161718spring: profiles: active: dev server: port: 9090---server: port: 9091spring: profiles: dev ---server: port: 9092spring: profiles: prod active:是指定哪个文档快 profiles: 指定一个名称,让active识别的 5.3 激活指定profile1, 在配置文件中指定 spring.profiles.active=dev 2, 命令行: idea功能栏中的 run &gt; edit &gt; program arguments 添加上 –spring.profiles.active=prod –spring.profiles.active=dev 3,cmd中 将 项目打成 jar包 java -jar (jar包名) –spring.profiles.active=prod 4, 虚拟机 参数: idea功能栏中的 run &gt; edit &gt;VM options 添加上 -Dspring.profiles.active=prod/dev 6.Spring Boot配置文件的加载位置 Spring Boot 启动会扫描以下位置的application.yml或application.properties文件作为默认配置文件 file: ./config/ file: ./ classpath: ./config/ classpath: / 以上是按照优先级从高到低的顺序,所有的配置文件都会被加载,高优先级配置会覆盖 低优先级配置 file : 跟src平级的目录 classpath: resources目录下的 我们也可以通过配置spring.config.location来改变默认配置文件位置: 1.将项目打包 2.命令行格式: java -jar 包名 –spring.config.location= F:/app/application.properties(配置文件绝对路径) 项目打包之后可能后来会需要修改一些配置,就可以使用这种方式,并且旧配置还会存在,新配置也会应用上 7.外部配置加载顺序 SpringBoot也可以从以下位置加载配置,优先级从高到低,高优先级覆盖低优先级,如果有不同的配置,就会形成互补 命令行参数 java -jar xxx.jar –server.port=8081 –xxx 多个配置用空格分开: –xxx –xxx 来自java:comp/env的NDI属性 Java系统属性(System.getProperties()) 操作系统环境变量 RandomValuePropertySource配置的random.*属性值 由jar包外向jar包内进行寻找: 优先加载带profile的 jar包”外”部的application-{profile}.properties或application.yml(带spring.profile)的配置文件 jar包’’内’’部的application-{profile}.properties或application.yml(带spring.profile)的配置文件 再来加载不带profile的 jar包’’外’’部的application.properties或application.yml(不带spring.profile)的配置文件 jar包’’内’’部的application.properties或application.yml(不带spring.profile)的配置文件 还有其他的: @Configuration注解类上的@PropertySource 通过SrpingApplication.setDefaultProperties指定默认属性 详情参考官网文档的第 24章 8.自动配置原理(重点)自动配置到底能些什么?怎么写?自动配置原理: 文档地址 查看目录最后一章 X. Appendices 这里面说明了都有哪些配置项 其实: 1.SpringBoot启动会加载大量的自动配置类 2.我们看我们需要的功能有没有SpringBoot默认写好的自动配置类 3.我们再来看这个自动配置类到底配置了哪些组件(只要我们要用的组件有,我们就不需要再来配置了) 4.给容器中自动配置类添加组建的时候,会从properties类中获取某些属性,我们就可以在配置文件中指定这些属性的值 xxxxAutoConfigurartion: 自动配置类; 给容器中添加组件 xxxxProperties:封装配置文件中相关属性; 技巧: idea双击Shift,搜索 *AutoConfiguration 点开缓存相关的自动配置 我们将会看到以下源码: 123456@EnableConfigurationProperties({CacheProperties.class})@AutoConfigureAfter({CouchbaseAutoConfiguration.class, HazelcastAutoConfiguration.class, HibernateJpaAutoConfiguration.class, RedisAutoConfiguration.class})@Import({CacheAutoConfiguration.CacheConfigurationImportSelector.class})public class CacheAutoConfiguration { public CacheAutoConfiguration() { } ctrl+鼠标左键点击: 12@EnableConfigurationProperties({CacheProperties.class})//点击 CacheProperties 我们会看到在CacheProperties类上: 1234@ConfigurationProperties( prefix = \"spring.cache\")public class CacheProperties { prefix = “spring.cache” : 就是在yml/properties配置文件的语法前缀 至于能配置哪些具体东西? 就是这些 或者你可以利用idea的代码提示在配置文件里,比如我调用 第一个getType 这就是通过源码的方式,来了解到我们可以在配置文件里配置什么东西 比如我想连接数据库,我来搜索一下 我看到了我们的需要的字段,以及下面很多的方法(这里就不截图了) 接下来就是到配置文件配置了: 9.细节@Conditional派生注解 我发现源码中有很多的 @ConditionalOn*** 它其实就是利用Spring底层的 @Conditional注解 作用: 必须是 @Conditional 指定的条件成立,才给容器中添加组件,配置类里面的内容才会生效,如果返回false那么,你配的东西都不会生效的 SpringBoot 扩展了 @Conditional注解 比如: 所以其实自动配置类必须在一定的条件下才能生效 我们该怎么知道哪些类生效哪些没生效呢?很简单,在配置文件里添加: 1debug: true 然后运行我们的朱类: ​ 我们会看到: 还有: 都会在控制台打印输出","link":"/2019/06/30/boot2/"},{"title":"《大话数据结构》学习笔记-day01-数据结构","text":"程序设计 = 数据结构 + 算法 “巧妇难为无米之炊”,再强大的计算机,也是要有”米”下锅才可以干活,否则就是一堆破铜烂铁,这个”米”就是数据 一, 基本概念和术语1.1 数据 数据:是描述客观事物的符号,是计算机中可以操作的对象,是能被计算机识别,并输入给计算机处理的符号集合,数据不仅仅包括整型,实型等数值类型,还包括字符及声音,图像,视频等非数值类型 整型(int,Long….)：整形简单来说就是整数，比如1，2，3等。整形数据可以分为长整型和短整型。 实型(char,double….)：实际就是浮点数，分为 单精度浮点数 和 双精度浮点数 。通俗来说就是带有小数点的数字，比如1.12，2.0等。 字符型(String….)：字符型量包括字符常量和字符变量。字符常量通常用单引号标注，如‘a’,’’b’等。字符变量用char 说明。 ​ 其实数据,其实就是符号,而这些符号必须具备两个前提 可以输入到计算机中 能被计算机程序处理 对于整型,实型等数据类型,可以进行数值计算, 对于字符数据类型,就需要进行非数值的处理,而声音 图像 视频 等 其实是可以通过编码的手段变成字符数据来处理的 1.2 数据元素是组成数据的,有一定意义的基本单位,在计算机中通常作为整体处理,也被称为记录 比如,在人类中,什么是数据元素? 当然是人啊! 畜类呢? 牛 马 羊 鸡 猪 等动物都是禽类的数据元素 1.3 数据项 ​ 数据项 : 一个数据元素可以由若干数据项组成 数据元素 人 : 可以有 五官 这些数据项,也可以有 姓名 年龄 性别 出生地址 联系方式等数据项, 具体有哪些数据项,要看你的需求了 ​ 数据项是数据不可分割的最小单位,把它定义成最小单位,是有助于我们更好的解决问题,所以要记住,真正讨论问题时,数据元素才是数据结构中建立数据模型的着眼点,是讨论这部电影角色这样的”数据元素”,而不是针对这个角色的姓名 年龄这样的”数据项”去研究分析 1.4 数据对象 ​ 数据对象: 是性值相同的数据元素的集合,是数据的子集, 比如人有 名字 性别 爱好 身高 等数据项,在实际应用中,处理的数据元素通常具有相同性质,在不产生混淆的情况下,我们都将数据对象成为数据 1.4 数据结构 数据结构: 是相互之间存在一种或多种特定关系的数据元素的集合 结构是指各个组成部分相互搭配和排列的方式,现实世界中,不同数据元素之间不是独立的,而是存在特定关系,我们称这些关系为结构 计算机中,数据元素不是杂乱无序的,而是具有内在联系的数据集合,数据元素之间存在的一种或多种特定关系,也是数据的组织形式 二, 逻辑结构与物理结构1.逻辑结构数据对象中数据元素之间的相互关系 集合结构 集合结构中的数据元素除了同属于一个集合外,他们之间没有其他关系,各个数据元素是’平等’的,他们共同属性是”同属于一个集合”,数据结构中的集合关系,就类似于数据中的集合 线性结构 数据元素之间是一对一的关系 树性结构 数据元素之间存在一种一对多的层次关系 图形结构 对多关系 2.物理结构数据的逻辑结构再计算机中的存储形式 很多书中叫做存储结构,理解成一回事就行 ​ 数据是数据元素的集合,那么根据物理结构的定义,实际上就是如何把数据元素存储到计算机的存储器中,存储器主要针对内存而言, 像硬盘 软盘 光盘等外部存储的数据组织通常用文件结构来描述 ​ 数据的存储结构应正确的反应数据元素之间的逻辑关系,这才是最为关键的,如何存储数据元素之间的逻辑关系,是实现物理结构的重点和难点 数据元素的存储结构形式有两种: 顺序结构&amp;链式结构 顺序结构: 数据元素放在地址连续的存储单元里,其数据间的逻辑关系和物理关系是一致的 说白了,就是排队占位,大家都按顺序排好队,谁也不能插队,每个人有自己的空间 数组就是这样的顺序存储结构 链式存储结构:​ 事实上不是所有人都很有素质,有的人会喜欢插队,面对时常变化的结构,顺序存储是不科学的,怎么办? ​ 比如银行 医院设置了排队系统,给你一个号码,你愿意去哪就去哪,到时候叫你你就过去 链式存储结构: 是把数据元素存放在任意的存储单元里,这组存储单元可以是连续的,也可以是不连续的 ​ 链式存储灵活多了,数据在哪不重要,只需要一个指针存放了相应地址就可以找到它 三, 抽象数据类型1. 数据类型 数据类型: 是指一组性质相同的值的集合及定义在此集合上的一些操作的总称 ​ 在 C 语言中 , 按照取值的不同,数据类型可以分为两类: 原子类型: 是不可以再分解的基本类型,包括整型,实型,字符型等 结构类型: 由若干个类型组合而成,是可以再分解的,例如,整型数组是由若干整型数据组成的 抽象是指抽取出事务具有的普遍性的本质 抽象是一种思考问题的方式,它隐藏了繁杂的细节,只保留实现目标所必须的信息 2. 抽象数据类型 抽象数据类型(Abstract Data Type,ADT) : 是指一个数学模型及定义在该模型上的一组操作,抽象数据类型的定义仅仅取决于它的一组逻辑特性,而与其计算机内部如何表示和实现无关 ​ 电脑手机平板等都拥有 “整数”类型,尽管不同的计算机中实现方法不一样,但由于其定义的数学特性相同,在开发者看来,他们都是相同的,因此, “抽象”的意义在于数据类型的数学抽象特性 ​ 不仅仅是已经定义并实现的数据类型,还可以是开发者自己定义的类型,比如: 定义坐标 x,y,z 坐标中总会有成对的x,y出现,再3d中还会有z的出现,既然他们始终都会出现,那我就定义一个point的抽象数据类型,他有 x y z三个整型变量,这样我们很方便地操作一个 point 数据变量就能知道这一点地坐标了 比如 任天堂的 超级玛丽游戏里面的 马里奥有: 移动(前进,后退,上,下),跳,发射子弹等,一个抽象数据类型定义了: 一个数据对象 , 数据对象中各数据元素之间地关系及对数据元素的操作,至于,抽象类型到底需要哪些操作,这就由开发者决定 ​ 事实上,抽象数据类型体现了程序设计中 问题分解,抽象和信息隐藏 的特性,抽象数据类型把实际生活中的问题分解为多个规模小且容易处理的问题,然后简历一个计算机能处理的数据模型,并把每个功能模块的实现细节作为一个独立的单元,从而使具体实现过程隐藏起来 描述抽象数据类型的标准格式: 1234567891011121314ADT 抽象数据类型别名Data(数据) 数据元素之间逻辑关系的定义 Operation(操作) 操作1 初始条件 操作结果描述 操作2 .... 操作n .... endADT 总结回顾 数据(可以被计算机识别和处理) 数据对象 数据元素 数据元素 数据元素 数据元素 数据项1,数据项2 数据项1,数据项2 数据项1,数据项2 数据项1,数据项2 由于以上概念,给出了数据结构的定义: 数据结构是相互之间存在一种或多种特定关系的数据元素的集合 同样是结构,从不同的角度来讨论,会有不同的分类: 逻辑结构 物理结构 - 集合结构 - 顺序存储结构 - 线型结构 - 链式存储结构 - 树型结构 - 图型结构 下一章 : 算法","link":"/2019/06/24/dahua1/"},{"title":"Spring Boot--开发Web应用-Thymeleaf(二)","text":"以下文章大部分文字转自: 程序员DD 我会根据程序员DD的文章进行学习 如果你没有使用过Spring boot , 我的上一篇博客可能会更适合你 开发环境win10 idea 2019.1.1 jdk1.8 一双手 静态资源访问在我们开发Web应用的时候，需要引用大量的js、css、图片等静态资源。 默认配置Spring Boot默认提供静态资源目录位置需置于classpath下，目录名需符合如下规则： /static /public /resources /META-INF/resources 举例：我们可以在src/main/resources/目录下创建static，在该位置放置一个图片文件。启动程序后，尝试访问http://localhost:8080/D.jpg。如能显示图片，配置成功。 渲染Web页面在之前的示例中，我们都是通过@RestController来处理请求，所以返回的内容为json对象。那么如果需要渲染html页面的时候，要如何实现呢？ 模板引擎在动态HTML实现上Spring Boot依然可以完美胜任，并且提供了多种模板引擎的默认配置支持，所以在推荐的模板引擎下，我们可以很快的上手开发动态网站。 Spring Boot提供了默认配置的模板引擎主要有以下几种： Thymeleaf FreeMarker Velocity Groovy Mustache Spring Boot建议使用这些模板引擎，避免使用JSP，若一定要使用JSP将无法实现Spring Boot的多种特性(上一篇博客我加了一些东西,使spring boot支持了jsp) 当你使用上述模板引擎中的任何一个，它们默认的模板配置路径为：src/main/resources/templates。当然也可以修改这个路径，具体如何修改，可在后续各模板引擎的配置属性中查询并修改。 ThymeleafThymeleaf是一个XML/XHTML/HTML5模板引擎，可用于Web与非Web环境中的应用开发。它是一个开源的Java库，基于Apache License 2.0许可，由Daniel Fernández创建，该作者还是Java加密库Jasypt的作者。 Thymeleaf提供了一个用于整合Spring MVC的可选模块，在应用开发中，你可以使用Thymeleaf来完全代替JSP或其他模板引擎，如Velocity、FreeMarker等。Thymeleaf的主要目标在于提供一种可被浏览器正确显示的、格式良好的模板创建方式，因此也可以用作静态建模。你可以使用它创建经过验证的XML与HTML模板。相对于编写逻辑或代码，开发者只需将标签属性添加到模板中即可。接下来，这些标签属性就会在DOM（文档对象模型）上执行预先制定好的逻辑。 示例模板： 1234567891011121314&lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th th:text=\"#{msgs.headers.name}\"&gt;Name&lt;/td&gt; &lt;th th:text=\"#{msgs.headers.price}\"&gt;Price&lt;/td&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr th:each=\"prod : ${allProducts}\"&gt; &lt;td th:text=\"${prod.name}\"&gt;Oranges&lt;/td&gt; &lt;td th:text=\"${#numbers.formatDecimal(prod.price,1,2)}\"&gt;0.99&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; 可以看到Thymeleaf主要以属性的方式加入到html标签中，浏览器在解析html时，当检查到没有的属性时候会忽略，所以Thymeleaf的模板可以通过浏览器直接打开展现，这样非常有利于前后端的分离。 在Spring Boot中使用Thymeleaf，只需要引入下面依赖，并在默认的模板路径src/main/resources/templates下编写模板文件即可完成。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt; 在完成配置之后，举一个简单的例子，在快速入门工程的基础上，举一个简单的示例来通过Thymeleaf渲染一个页面。 controller里面加一个这个方法 1234567@RequestMapping(\"/\") public String index(ModelMap map){ // 加入一个属性,用来在模板中读取 map.addAttribute(\"host\",\"https://aaatao66.github.io/\"); // return模板文件的名称,对应 src/main/resources/templates/index.html return \"index\"; } HTML: 1234567891011&lt;!DOCTYPE html&gt;&lt;html lang=\"en\" xmlns:th=\"http://www.w3.org/1999/xhtml\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;/head&gt;&lt;body&gt;&lt;h1 th:text=\"${host}\"&gt;Hello World&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 如上页面，直接打开html页面展现Hello World，但是启动程序后，访问http://localhost:8080/，则是展示Controller中host的值：https://aaatao66.github.io/，做到了不破坏HTML自身内容的数据逻辑分离。 更多Thymeleaf的页面语法，还请访问Thymeleaf的官方文档查询使用:Thymeleaf官网 Thymeleaf的默认参数配置 如有需要修改默认配置的时候，只需复制下面要修改的属性到application.properties中，并修改成需要的值，如修改模板文件的扩展名，修改默认的模板路径等。 我使用的是 yml 方式,语法不同 ,如果你使用的是 properties 那么你可以参考一下: 123456789101112131415161718# Enable template caching.spring.thymeleaf.cache=true # Check that the templates location exists.spring.thymeleaf.check-template-location=true # Content-Type value.spring.thymeleaf.content-type=text/html # Enable MVC Thymeleaf view resolution.spring.thymeleaf.enabled=true # Template encoding.spring.thymeleaf.encoding=UTF-8 # Comma-separated list of view names that should be excluded from resolution.spring.thymeleaf.excluded-view-names= # Template mode to be applied to templates. See also StandardTemplateModeHandlers.spring.thymeleaf.mode=HTML5 # Prefix that gets prepended to view names when building a URL.spring.thymeleaf.prefix=classpath:/templates/ # Suffix that gets appended to view names when building a URL.spring.thymeleaf.suffix=.html spring.thymeleaf.template-resolver-order= # Order of the template resolver in the chain. spring.thymeleaf.view-names= # Comma-separated list of view names that can be resolved. 支持JSP的配置Spring Boot并不建议使用，但如果一定要使用,可以参考我上一篇文章","link":"/2019/05/26/springboot-web/"},{"title":"Spring Boot--日志框架的学习","text":"版本: Spring Boot 2.1.5.RELEASE maven 3.2.5 jdk1.8 1.我选用的日志框架: 日志门面(抽象层): SLF4J 日志实现: Logback Spring Boot: 底层是Spring框架,Spring框架默认是JCL; 而Spring Boot选用 SLF4j和Logback 2. SLF4j使用1) 如何在系统中使用SLF4jSLF4j的官方手册 开发的时候,日志记录方法的调用,不用改直接调用日志的实现类,而是调用日志抽象层里的方法; 导入slf4j的jar和 logback的实现jar 123456789import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class HelloWorld { public static void main(String[] args) { Logger logger = LoggerFactory.getLogger(HelloWorld.class); logger.info(\"Hello World\"); }} SLF4j与其他日志框架结合示意图: 2) 遗留问题虽然我使用的是(slf4j &amp; logback),但是其他的比如Spring框架用的commons-logging日志框架, Hibernate用的是jboss-logging日志框架,等等,太乱了了,所以我们要 统一日志记录,即使别的框架也要和我一起统一使用slf4j进行输出; 官方给出的示意图: 逻辑: 1.将系统其他的日志框架排除; 2.用中间包来替换原有的日志框架(红色框起来的就是中间包); 3.导入slf4j其他的实现 3. Spring Boot日志关系其实是这个依赖的这个包: 123456&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; 在 pom文件下鼠标右键点击: SpringBoot所有依赖关系图,我们只看logging相关的: 我用的是2.1.5版本的Spring Boot, 笔者在学习过程中发现我看的老师视频里跟我的版本不一样, 这是那位老师的版本: 很明显跟我不一样,不过Spring肯定对自己的底层进行了升级; 确切的说不是升级,而是剔除掉了jcl框架的转换,因为jcl框架最后更新日期是2014年,明显已经过时 但是基本推理的出来,slf4j的官网图确实是对SpringBoot1.x版本的示意,但是对我的2.x版本不符, 不过根据我的包名来看,他们的功能是差不多的,都是转成slf4j; 小总结: 1.SpringBoot底层也是 slf4j+logback的方式j进行日志记录; 2.SpringBoot也把其他日志都替换成了slf4j; 3.中间替换包; 中间替换包图示: 4) 如果我们要引入其他的框架,一定要把这个框架默认日志依赖移除掉!Spring框架默认的日志框架是: commons-logging; 但是Spring Boot引入spring核心jar包的时候去除了 日志jar包; Spring Boot能自动适配所有的日志,而且底层使用 slf4j+logback的方式记录日志,引入其他框架的时候,只需要把这个框架依赖的日志排除掉 4. 日志使用测试类: 12345678910111213141516171819202122232425import org.junit.Test;import org.junit.runner.RunWith;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit4.SpringRunner;@RunWith(SpringRunner.class)@SpringBootTestpublic class SpringBootLoggingApplicationTests { // 日志记录器记录器 Logger logger = LoggerFactory.getLogger(getClass()); @Test public void contextLoads() { // 日志的级别 // 由低到高 trace &lt; debug &lt; info &lt; warn &lt; error logger.trace(\"这是trace日志..\"); logger.debug(\"这是debug调试日志..\"); logger.info(\"这是info日志..\"); logger.warn(\"这是warn日志...\"); logger.error(\"这是error错误日志\"); }} 运行输出结果: 1232019-07-02 19:22:35.980 INFO 8404 --- [ main] c.c.s.SpringBootLoggingApplicationTests : 这是info日志..2019-07-02 19:22:35.981 WARN 8404 --- [ main] c.c.s.SpringBootLoggingApplicationTests : 这是warn日志...2019-07-02 19:22:35.981 ERROR 8404 --- [ main] c.c.s.SpringBootLoggingApplicationTests : 这是error错误日志 也就是说 SpringBoot默认的日志级别是 info,所以只输出了info 和 比info级别大的日志; 打开我的yml配置文件: 123logging: level: com.carson: trace 意思是把我 com.carson下的所有包都设置为 trace 日志级别 输出结果: 123452019-07-02 19:29:17.406 TRACE 7076 --- [ main] c.c.s.SpringBootLoggingApplicationTests : 这是trace日志..2019-07-02 19:29:17.407 DEBUG 7076 --- [ main] c.c.s.SpringBootLoggingApplicationTests : 这是debug调试日志..2019-07-02 19:29:17.407 INFO 7076 --- [ main] c.c.s.SpringBootLoggingApplicationTests : 这是info日志..2019-07-02 19:29:17.408 WARN 7076 --- [ main] c.c.s.SpringBootLoggingApplicationTests : 这是warn日志...2019-07-02 19:29:17.408 ERROR 7076 --- [ main] c.c.s.SpringBootLoggingApplicationTests : 这是error错误日志 4.1 配置文件详解:123456789logging.level.com.carson= trace# path: 只创建任意一个文件夹, SpringBoot会默认生成一个 spring.log 作为日志文件logging.path= F:/spring/log# file: 指定一个路径和文件把 日志输出到 指定文件里logging.file= F:/springboot.log# pattern.console: 控制台输出的日志格式logging.pattern.console= %d{yyyy‐MM‐dd} === [%thread] === %‐5level === %logger{50} ==== %msg%n# pattern.file : 指定文件中日志的输出格式logging.pattern.file= %d{yyyy‐MM‐dd} === [%thread] === %‐5level === %logger{50} ==== %msg%n 4.2 指定配置 日志框架 文件命名 Logback logback-spring.xml, logback-spring.groovy, logback.xml, or logback.groovy Log4j2 log4j2-spring.xml or log4j2.xml JDK (Java Util Logging) logging.properties 以上来自SpringBoot的官方文档, 上面是他要求的命名,SpringBoot会读取的 logback-spring.xml : 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!--scan：当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true。scanPeriod：设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒当scan为true时，此属性生效。默认的时间间隔为1分钟。debug：当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。--&gt;&lt;configuration scan=\"false\" scanPeriod=\"60 seconds\" debug=\"false\"&gt; &lt;!-- 定义日志的根目录 --&gt; &lt;property name=\"LOG_HOME\" value=\"/app/log\" /&gt; &lt;!-- 定义日志文件名称 --&gt; &lt;property name=\"appName\" value=\"atguigu-springboot\"&gt;&lt;/property&gt; &lt;!-- ch.qos.logback.core.ConsoleAppender 表示控制台输出 --&gt; &lt;appender name=\"stdout\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;!-- 日志输出格式： %d表示日期时间， %thread表示线程名， %-5level：级别从左显示5个字符宽度 %logger{50} 表示logger名字最长50个字符，否则按照句点分割。 %msg：日志消息， %n是换行符 --&gt; &lt;layout class=\"ch.qos.logback.classic.PatternLayout\"&gt; &lt;springProfile name=\"dev\"&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} ----&gt; [%thread] ---&gt; %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;/springProfile&gt; &lt;springProfile name=\"!dev\"&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} ==== [%thread] ==== %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;/springProfile&gt; &lt;/layout&gt; &lt;/appender&gt; &lt;!-- 滚动记录文件，先将日志记录到指定文件，当符合某个条件时，将日志记录到其他文件 --&gt; &lt;appender name=\"appLogAppender\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 指定日志文件的名称 --&gt; &lt;file&gt;${LOG_HOME}/${appName}.log&lt;/file&gt; &lt;!-- 当发生滚动时，决定 RollingFileAppender 的行为，涉及文件移动和重命名 TimeBasedRollingPolicy： 最常用的滚动策略，它根据时间来制定滚动策略，既负责滚动也负责出发滚动。 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!-- 滚动时产生的文件的存放位置及文件名称 %d{yyyy-MM-dd}：按天进行日志滚动 %i：当文件大小超过maxFileSize时，按照i进行文件滚动 --&gt; &lt;fileNamePattern&gt;${LOG_HOME}/${appName}-%d{yyyy-MM-dd}-%i.log&lt;/fileNamePattern&gt; &lt;!-- 可选节点，控制保留的归档文件的最大数量，超出数量就删除旧文件。假设设置每天滚动， 且maxHistory是365，则只保存最近365天的文件，删除之前的旧文件。注意，删除旧文件是， 那些为了归档而创建的目录也会被删除。 --&gt; &lt;MaxHistory&gt;365&lt;/MaxHistory&gt; &lt;!-- 当日志文件超过maxFileSize指定的大小是，根据上面提到的%i进行日志文件滚动 注意此处配置SizeBasedTriggeringPolicy是无法实现按文件大小进行滚动的，必须配置timeBasedFileNamingAndTriggeringPolicy --&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;!-- 日志输出格式： --&gt; &lt;layout class=\"ch.qos.logback.classic.PatternLayout\"&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [ %thread ] - [ %-5level ] [ %logger{50} : %line ] - %msg%n&lt;/pattern&gt; &lt;/layout&gt; &lt;/appender&gt; &lt;!-- logger主要用于存放日志对象，也可以定义日志类型、级别 name：表示匹配的logger类型前缀，也就是包的前半部分 level：要记录的日志级别，包括 TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR additivity：作用在于children-logger是否使用 rootLogger配置的appender进行输出， false：表示只用当前logger的appender-ref，true： 表示当前logger的appender-ref和rootLogger的appender-ref都有效 --&gt; &lt;!-- hibernate logger --&gt; &lt;logger name=\"com.atguigu\" level=\"debug\" /&gt; &lt;!-- Spring framework logger --&gt; &lt;logger name=\"org.springframework\" level=\"debug\" additivity=\"false\"&gt;&lt;/logger&gt; &lt;!-- root与logger是父子关系，没有特别定义则默认为root，任何一个类只会和一个logger对应， 要么是定义的logger，要么是root，判断的关键在于找到这个logger，然后判断这个logger的appender和level。 --&gt; &lt;root level=\"info\"&gt; &lt;appender-ref ref=\"stdout\" /&gt; &lt;appender-ref ref=\"appLogAppender\" /&gt; &lt;/root&gt;&lt;/configuration&gt; 把上面配置复制一份,放到项目的 resources 里面,或者自定义配置,命名规范的区别: logback.xml: 直接被日志框架识别了 但是如果你以 logback-spring.xml 命名(推荐): 日志框架不直接加载日志的配置项了,由SpringBoot解析日志你就可以使用SpringBoot的一个高级功能 1234567891011&lt;springProfile name=\"prod\"&gt; &lt;!-- 是不是 prod 环境 --&gt;&lt;/springProfile&gt;&lt;springProfile name=\"dev | prod\"&gt; &lt;!-- dev 和 prod 都会执行 --&gt;&lt;/springProfile&gt;&lt;springProfile name=\"!dev\"&gt; &lt;!-- 如果不是 dev环境 --&gt;&lt;/springProfile&gt; 也就是刚才的配置文件里的: 12345678910111213141516171819&lt;appender name=\"stdout\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;!-- 日志输出格式： %d表示日期时间， %thread表示线程名， %-5level：级别从左显示5个字符宽度 %logger{50} 表示logger名字最长50个字符，否则按照句点分割。 %msg：日志消息， %n是换行符 --&gt; &lt;layout class=\"ch.qos.logback.classic.PatternLayout\"&gt; &lt;springProfile name=\"dev\"&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} ----&gt; [%thread] ---&gt; %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;/springProfile&gt; &lt;springProfile name=\"!dev\"&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} ==== [%thread] ==== %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;/springProfile&gt; &lt;/layout&gt; &lt;/appender&gt; 你可以在你的 yml或者properties里配置一条: 12&gt; spring.profiles.active= prod&gt; 来设置运行环境 4.3 使用 log4j其实SpringBoot官方为我们做了一些帮助: Name Description Pom spring-boot-starter-jetty Starter for using Jetty as the embedded servlet container. An alternative to spring-boot-starter-tomcat Pom spring-boot-starter-log4j2 Starter for using Log4j2 for logging. An alternative to spring-boot-starter-logging Pom spring-boot-starter-logging Starter for logging using Logback. Default logging starter Pom spring-boot-starter-reactor-netty Starter for using Reactor Netty as the embedded reactive HTTP server. Pom spring-boot-starter-tomcat Starter for using Tomcat as the embedded servlet container. Default servlet container starter used by spring-boot-starter-web Pom spring-boot-starter-undertow Starter for using Undertow as the embedded servlet container. An alternative to spring-boot-starter-tomcat Pom 想使用哪个日志框架就直接导入哪个包就好了, 比如我想使用 log4j2 我先把默认的 spring-boot-starter-logging 排除掉 , 排除方法如下: 然后再pom文件里: 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt; &lt;version&gt;2.1.1.RELEASE&lt;/version&gt;&lt;/dependency&gt; 导入log4j2的包; 然后在 resources 里 创建一个 log4j的配置文件,文件命名就以刚才说的: 内容: 123456789101112131415161718192021222324### set log levels ###log4j.rootLogger = debug , stdout , D , E### 输出到控制台 ###log4j.appender.stdout = org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.Target = System.outlog4j.appender.stdout.layout = org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern = %d{ABSOLUTE} ===== %5p %c{ 1 }:%L - %m%n#### 输出到日志文件 ####log4j.appender.D = org.apache.log4j.DailyRollingFileAppender#log4j.appender.D.File = logs/log.log#log4j.appender.D.Append = true#log4j.appender.D.Threshold = DEBUG ## 输出DEBUG级别以上的日志#log4j.appender.D.layout = org.apache.log4j.PatternLayout#log4j.appender.D.layout.ConversionPattern = %-d{yyyy-MM-dd HH:mm:ss} [ %t:%r ] - [ %p ] %m%n##### 保存异常信息到单独文件 ####log4j.appender.D = org.apache.log4j.DailyRollingFileAppender#log4j.appender.D.File = logs/error.log ## 异常日志文件名#log4j.appender.D.Append = true#log4j.appender.D.Threshold = ERROR ## 只输出ERROR级别以上的日志!!!#log4j.appender.D.layout = org.apache.log4j.PatternLayout#log4j.appender.D.layout.ConversionPattern = %-d{yyyy-MM-dd HH:mm:ss} [ %t:%r ] - [ %p ] %m%n 也就是说,如果像引入其他日志框架,只要把以前的框架排除,然后再引入新框架就ok了","link":"/2019/07/02/bootlog/"},{"title":"Hadoop--Hello,Hadoop!","text":"Hadoop是什么? Hadoop是一个由Apache基金会所开发的分布式系统基础架构 集群：多个机器共同完成一件事 分布式：多个机器共同完成一件事，然后不同机器作用不同，各司其职 集群不一定是分布式，分布式一定是集群 主要解决，海量数据的存储和海量数据的分析计算问题。 广义上来说，HADOOP通常是指一个更广泛的概念——HADOOP生态圈 Hadoop发展历史 Lucene–Doug Cutting开创的开源软件，用Java书写代码，实现与Google类似的全文搜索功能，它提供了全文检索引擎的架构，包括完整的查询引擎和索引引擎 2001年年底成为apache基金会的一个子项目 对于大数量的场景，Lucene面对与Google同样的困难 学习和模仿Google解决这些问题的办法 ：微型版Nutch 可以说Google是hadoop的思想之源(Google在大数据方面的三篇论文)谷歌的三驾马车 ​ GFS —&gt;HDFS google File System—&gt; hadoop distriduted file system ​ Map-Reduce —&gt;MR map reduce ​ BigTable —&gt;Hbase 2003-2004年，Google公开了部分GFS和Mapreduce思想的细节，以此为基础Doug Cutting等人用了2年业余时间实现了DFS和Mapreduce机制，使Nutch性能飙升 2005 年Hadoop 作为 Lucene的子项目 Nutch的一部分正式引入Apache基金会。2006 年 3 月份，Map-Reduce和Nutch Distributed File System (NDFS) 分别被纳入称为 Hadoop 的项目中 名字来源于Doug Cutting儿子的玩具大象 Hadoop就此诞生并迅速发展，标志这第三次信息化浪潮时代（大数据、云计算、物联网）来临 Hadoop三大发行版本Hadoop 三大发行版本: Apache、Cloudera、Hortonworks。 Apache版本最原始（最基础）的版本，对于入门学习最好。 Cloudera在大型互联网企业中用的较多。 Hortonworks文档较好。 Apache Hadoop 官网地址：http://hadoop.apache.org/releases.html 下载地址：https://archive.apache.org/dist/hadoop/common/ Cloudera Hadoop 官网地址：https://www.cloudera.com/downloads/cdh/5-10-0.html 下载地址：http://archive-primary.cloudera.com/cdh5/cdh/5/ （1）2008年成立的Cloudera是最早将Hadoop商用的公司，为合作伙伴提供Hadoop的商用解决方案，主要是包括支持、咨询服务、培训。 （2）2009年Hadoop的创始人Doug Cutting也加盟Cloudera公司。Cloudera产品主要为CDH，Cloudera Manager，Cloudera Support （3）CDH是Cloudera的Hadoop发行版，完全开源，比Apache Hadoop在兼容性，安全性，稳定性上有所增强。 （4）Cloudera Manager是集群的软件分发及管理监控平台，可以在几个小时内部署好一个Hadoop集群，并对集群的节点及服务进行实时监控。Cloudera Support即是对Hadoop的技术支持。 （5）Cloudera的标价为每年每个节点4000美元。Cloudera开发并贡献了可实时处理大数据的Impala项目。 Hortonworks Hadoop 官网地址：https://hortonworks.com/products/data-center/hdp/ 下载地址：https://hortonworks.com/downloads/#data-platform （1）2011年成立的Hortonworks是雅虎与硅谷风投公司Benchmark Capital合资组建。 （2）公司成立之初就吸纳了大约25名至30名专门研究Hadoop的雅虎工程师，上述工程师均在2005年开始协助雅虎开发Hadoop，贡献了Hadoop80%的代码。 （3）雅虎工程副总裁、雅虎Hadoop开发团队负责人Eric Baldeschwieler出任Hortonworks的首席执行官。 （4）Hortonworks的主打产品是Hortonworks Data Platform（HDP），也同样是100%开源的产品，HDP除常见的项目外还包括了Ambari，一款开源的安装和管理系统。 （5）HCatalog，一个元数据管理系统，HCatalog现已集成到Facebook开源的Hive中。Hortonworks的Stinger开创性的极大的优化了Hive项目。Hortonworks为入门提供了一个非常好的，易于使用的沙盒。 （6）Hortonworks开发了很多增强特性并提交至核心主干，这使得Apache Hadoop能够在包括Window Server和Windows Azure在内的microsoft Windows平台上本地运行。定价以集群为基础，每10个节点每年为12500美元。 Hadoop的优势1）高可靠性：因为Hadoop假设计算元素和存储会出现故障，因为它维护多个工作数据副本，在出现故障时可以对失败的节点重新分布处理。 2）高扩展性：在集群间分配任务数据，可方便的扩展数以千计的节点。 3）高效性：在MapReduce的思想下，Hadoop是并行工作的，以加快任务处理速度。 4）高容错性：自动保存多份副本数据，并且能够自动将失败的任务重新分配。 Hadoop组成1）Hadoop HDFS：（hadoop distribute file system ）一个高可靠、高吞吐量的分布式文件系统。 2）Hadoop MapReduce：一个分布式的离线并行计算框架。 3）Hadoop YARN：作业调度与集群资源管理的框架。 4）Hadoop Common：支持其他模块的工具模块（Configuration、RPC、序列化机制、日志操作）。 HDFS架构概述 YARN架构概述 ResourceManager(rm)：处理客户端请求、启动/监控ApplicationMaster、监控NodeManager、资源分配与调度； NodeManager(nm)：单个节点上的资源管理、处理来自ResourceManager的命令、处理来自ApplicationMaster的命令； ApplicationMaster：数据切分、为应用程序申请资源，并分配给内部任务、任务监控与容错。 Container：对任务运行环境的抽象，封装了CPU、内存等多维资源以及环境变量、启动命令等任务运行相关的信息。 主从结构：master/slave MapReduce架构概述MapReduce将计算过程分为两个阶段：Map（映射）和Reduce（归约） Map阶段并行处理输入数据 Reduce阶段对Map结果进行汇总 大数据技术生态体系 图中涉及的技术名词解释如下： Sqoop：sqoop是一款开源的工具，主要用于在Hadoop(Hive)与传统的数据库(mysql)间进行数据的传递，可以将一个关系型数据库（例如 ： MySQL ,Oracle 等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。 Flume：Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。 Kafka：Kafka是一种高吞吐量的分布式发布订阅消息系统，有如下特性： （1）通过O(1)的磁盘数据结构提供消息的持久化，这种结构对于即使数以TB的消息存储也能够保持长时间的稳定性能。 （2）高吞吐量：即使是非常普通的硬件Kafka也可以支持每秒数百万的消息 （3）支持通过Kafka服务器和消费机集群来分区消息。 （4）支持Hadoop并行数据加载。 Storm：Storm为分布式实时计算提供了一组通用原语，可被用于“流处理”之中，实时处理消息并更新数据库。这是管理队列及工作者集群的另一种方式。 Storm也可被用于“连续计算”（continuous computation），对数据流做连续查询，在计算时就将结果以流的形式输出给用户。 Spark：Spark是当前最流行的开源大数据内存计算框架。可以基于Hadoop上存储的大数据进行计算。 Oozie：Oozie是一个管理Hadoop作业（job）的工作流程调度管理系统。Oozie协调作业就是通过时间（频率）和有效数据触发当前的Oozie工作流程。 Hbase：HBase是一个分布式的、面向列的开源数据库。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。 Hive：hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。 其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。 R语言：R是用于统计分析、绘图的语言和操作环境。R是属于GNU系统的一个自由、免费、源代码开放的软件，它是一个用于统计计算和统计制图的优秀工具。 Mahout: Apache Mahout是个可扩展的机器学习和数据挖掘库，当前Mahout支持主要的4个用例： 推荐挖掘：搜集用户动作并以此给用户推荐可能喜欢的事物。 聚集：收集文件并进行相关文件分组。 分类：从现有的分类文档中学习，寻找文档中的相似特征，并为无标签的文档进行正确的归类。 频繁项集挖掘：将一组项分组，并识别哪些个别项会经常一起出现。 ZooKeeper：Zookeeper是Google的Chubby一个开源的实现。它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、 分布式同步、组服务等。ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。 推荐系统框架图","link":"/2019/05/31/hadoop/"},{"title":"scala 入门","text":"可以用 简洁,优雅,美丽大方来形容scala语言的特点(或者说装逼,因为代码量少,很简洁) Java20行代码,可能用Scala只需一行,目前Java新版本正在模仿Scala语言的特性,可以说函数式编程在以后会越来越广泛 如果你在写Scala的时候忘记了Scala代码怎么写,你也可以在Scala的代码中写Java代码,毕竟都是运行在JVM之上的 Scala 概述1.什么是Scala?Scala官方网站 统计世界top100大学计算机系年级前三名，从初中开始编程，学过20多种语言，最后认为Scala最难。好了，我们开始享受这个过程吧 Scala是一种多范式的编程语言，其设计的初衷是要集成面向对象编程和函数式编程的各种特性。 Scala 产生于瑞士的洛桑联邦理工学院（EPFL），是“可扩展语言”（Scalable Language）的缩写， Sala 是一门静态类型语言，是一门以Java 虚拟机为目标运行环境并将面向对象和函数式编程语言的最佳特性结合在一起的编程语言。 你可以使用Scala 编写出更加精简的程序，也能用于构建大型复杂系统，并且他可以访问任何Java 类库并且与Java 框架进行互操作 Scala运行于Java平台（Java虚拟机），并兼容现有的Java程序。 2． 为什么要学Scala? 优雅：这是框架设计师第一个要考虑的问题，框架的用户是应用开发程序员，API是否优雅直接影响用户体验。 速度快：Scala语言表达能力强，一行代码抵得上Java多行，开发速度快；Scala是静态编译的，所以和JRuby,Groovy比起来速度会快很多。 能融合到Hadoop生态圈：Hadoop现在是大数据事实标准，Spark并不是要取代Hadoop，而是要完善Hadoop生态。JVM语言大部分可能会想到Java，但Java做出来的API太丑，或者想实现一个优雅的API太费劲。 3.Scala的特性 运行在JVM 和JavaScript 之上的语言 Scala 不仅利用了JVM 的高性能以及最优化性，Java 丰富的工具及类库生态系统也为其所用。不过Scala 并不是只能运行在JVM 之上！ Scala.js（http://www.scala-js.org）正在尝试将其迁移到JavaScript 世界。 静态类型 在Scala 语言中，静态类型（static typing）是构建健壮应用系统的一个工具。Scala 修正了Java 类型系统中的一些缺陷，此外通过类型推演（type inference）也免除了大量的冗余代码。 混合式编程范式——面向对象编程 Scala 完全支持面向对象编程（OOP）。Scala 引入特征（trait）改进了Java 的对象模型。trait 能通过使用混合结构（mixin composition）简洁地实现新的类型。在Scala 中，一切都是对象，即使是数值类型。对象的数据类型以及行为由类和特质描述。 类抽象机制的扩展有两种途径：一种途径是子类继承，另一种途径是灵活的混入机制。这两种途径能避免多重继承的种种问题。 混合式编程范式——函数式编程 Scala 完全支持函数式编程（FP），函数式编程已经被视为解决并发、大数据以及代码正确性问题的最佳工具。使用不可变值、被视为一等公民的函数、无副作用的函数、高阶函数以及函数集合，有助于编写出简洁、强大而又正确的代码。其函数也能当成值来使用。Scala提供了轻量级的语法用以定义匿名函数，支持高阶函数，允许嵌套多层函数，并支持柯里化。Scala的case class及其内置的模式匹配相当于函数式编程语言中常用的代数类型。 复杂的类型系统 Scala 对Java 类型系统进行了扩展，提供了更灵活的泛型以及一些有助于提高代码正确性的改进。通过使用类型推演，Scala 编写的代码能够和动态类型语言编写的代码一样精简。类型系统通过编译时检查，保证代码的安全性和一致性。类型系统具体支持以下特性： 泛型类 协变和逆变 标注 类型参数的上下限约束 把类别和抽象类型作为对象成员 复合类型 引用自己时显式指定类型 视图 多态方法 简洁、优雅、灵活的语法 使用Scala 之后，Java 中冗长的表达式不见了，取而代之的是简洁的Scala 方言。Scala 提供了一些工具，这些工具可用于构建领域特定语言（DSL），以及对用户友好的API 接口。 可扩展的架构 使用Scala，你能编写出简短的解释性脚本，并将其粘合成大型的分布式应用。 以下四种语言机制有助于提升系统的扩展性： 1) 使用trait 实现的混合结构； 2) 抽象类型成员和泛型； 3) 嵌套类； 4) 显式自类型（self type）。 Scala的设计秉承一项事实，即在实践中，某个领域特定的应用程序开发往往需要特定于该领域的语言扩展。Scala提供了许多独特的语言机制，可以以库的形式轻易无缝添加新的语言结构： 任何方法可用作前缀或后缀操作符 可以根据预期类型自动构造闭包。 并发性 Scala使用Actor作为其并发模型，Actor是类似线程的实体，通过邮箱发收消息。Actor可以复用线程，因此可以在程序中可以使用数百万个Actor,而线程只能创建数千个。在2.10之后的版本中，使用Akka作为其默认Actor实现。 4.Scala Web 框架以下列出了两个目前比较流行的 Scala 的 Web应用框架： Lift 框架 Play 框架 如果要使用Scala做Web开发可以学习这些框架，做大数据开发，得学习Spark框架，它的底层是使用Scala编写的 5.谁使用了 Scala2009年4月，Twitter宣布他们已经把大部分后端程序从Ruby迁移到Scala，其余部分也打算要迁移。 此外，Wattzon已经公开宣称，其整个平台都已经是基于Scala基础设施编写的。 瑞银集团把Scala用于一般产品中。 Coursera把Scala作为服务器语言使用。 6.扩展https://www.zhihu.com/question/19748408 https://www.zhihu.com/question/25679583?sort=created https://www.zhihu.com/question/26707124 http://www.mamicode.com/info-detail-663480.html 动态语言和静态语言1.动态类型语言：是指在运行期间才去做数据类型检查的语言。在用动态语言编程时，不用给变量指定数据类型，该语言会在你第一次赋值给变量时，在内部将数据类型记录下来。Python 和Ruby 就是一种典型的动态类型语言； 2.静态类型语言：与动态类型语言刚好相反，它的数据类型检查发生在在编译阶段，也就是说在写程序时要声明变量的数据类型。C/C++、C#、JAVA 都是静态类型语言的典型代表。注意:Scala是一门静态类型的语言,但是类型声明可以省略(有自动类型推断机制，Java10开始也有了自动类型推断机制) 动态语言和静态语言1.动态类型语言：是指在运行期间才去做数据类型检查的语言。在用动态语言编程时，不用给变量指定数据类型，该语言会在你第一次赋值给变量时，在内部将数据类型记录下来。Python 和Ruby 就是一种典型的动态类型语言； 2.静态类型语言：与动态类型语言刚好相反，它的数据类型检查发生在在编译阶段，也就是说在写程序时要声明变量的数据类型。C/C++、C#、JAVA 都是静态类型语言的典型代表。注意:Scala是一门静态类型的语言,但是类型声明可以省略(有自动类型推断机制，Java10开始也有了自动类型推断机制) 面向XX 编程：面向过程编程：整个程序按照步骤编写，程序更着重业务步骤的。 面向对象编程：提出对象封装概念，将业务修改成对象之间的关系处理。 面向接口编程：更高层次的抽象，将业务抽象成一些接口规则框架。 面向切面编程：另一个思考维度，着重于业务逻辑的动态组织。 命令式编程：关心解决问题的步骤 函数式编程：关心数据的映射，是数学函数，不是程序中的函数概念","link":"/2019/06/22/scala1/"},{"title":"浅谈ios/Android生态圈","text":"Hadoop生态圈 Spark生态圈 我是一个正在学习的开发者,上面两个生态圈是我正在接触的东西 什么是生态圈? 我理解的生态圈,好比我们地球,有水,空气,植物….等等,由这些东西组成的一个世界,就是一个大的生态圈,有这些东西我们会活下去,少一样东西都可能会造成整个地球的生态销毁 今天我不聊开发,不聊大数据,不聊这个地球,我是一个数码爱好者,今天我来谈一谈,关于ios和Android之前的小琐事 阅读指南1.你需要一首BGM,我推荐 《La Ciudad-ODESZA》 2.如果你是专业人士,那我这篇文章可能并不适合你,因为我本身就不是专业人士,业余爱好者而已 3.如果你也是数码爱好者(手机,电脑),那你可以花几分钟的时间来看完我的文章 4.这篇文章没有专业术语,很适合爱好者来观看,通俗易懂,但比较片面 5.如果你在上课,请你等下课再看,不要影响学习 此片文章用时一个周末的整个下午 首先介绍几个老朋友👇 Windows Apple Google Apple生态我们常说的苹果公司,都有哪些产品? pc Mac Os是一个很受开发者喜欢的系统 Mac系列的工业设计,我相信每个摸过的人,或者亲眼见过的的朋友,都会折服于苹果的这些优秀的工艺品 再加上黑苹果技术,哪怕买一个Air你也能享受到极致的体验 ipad 我相信好多人觉得平板电脑是一个鸡肋(实际上是钱包太小),但是实际上还是有很多人购入的 我们打开电商网站搜一下平板电脑 然后点击销量排名前十名的图片中全都印着Apple的图标标志,可以看出苹果公司在平板市场的占比了 iphone 穷人买iPhone,富人买Android,我们通常用这句话调侃自己,因为ios系统太稳定了,用3年不卡(不是绝对),但是至少我手里的iphone一直很稳定相比我用过的Android App Store 为什么你的ios耐用?很大功劳来自于这个商城,对于一个苹果小白白,想通过App Store以外的方式下载应用难的很,不像安卓,直接浏览器搜索下载,这样安全性很低,你不知道你下载的应用是否安全,是不是病毒,但是ios的App Store有着严格的软件把控,如果你这个软件商想瞎搞,那对不起,我就把你从App Store里干掉 Watch 穷玩车富玩表,不止适用于手表界,我们数码界也是可以用这句话来形容的,我一个穷学生,如果身边有人戴着Apple Watch, 我会投去羡慕嫉妒恨的眼光 Music 大家可能拥有最多的产品就是Iphone的,我们有网易云,qq音乐….各种免费音乐软件,为什么还有人需要去用收费的Apple Music? 我也有这个疑问 我们来看看知乎朋友是怎么说的: 你选择使用 Apple Music 而不是 QQ 音乐、网易云音乐、虾米音乐等的原因是什么? 有人说: 不会有各式各样的广告，不会到处显示小红点。我只想简简单单地听个歌。 还有人说: 云端使用 iTunes 资料库 曲库与听歌爱好重合大 界面和功能比较简单 学生价最低，收费体系简单 网易云：SVIP ¥12/M，VIP ¥8/M 虾米：SVIP ¥12/M，VIP ¥8/M QQ：绿钻豪华版 ¥18/M，付费音乐包 ¥8/M（可能还有其他 VIP 档次，没找到） Apple Music：不分档次，只要是学生，每月5元，无限 acces 链接：https://www.zhihu.com/question/36072058/answer/306595400 也有踩的声音: 网络状况不稳定 曲库小 歌手译名和英文名混乱 交互设计混乱 作者：Bryan Liu 链接：https://www.zhihu.com/question/36072058/answer/148406436 我的网易云会员一直是连续包月,我用的很舒服,想听的歌基本都有,除了一小部分歌没有 周杰伦版权事件 我就不详细说了,没了解的朋友可以去搜一下,我当时是周杰伦的忠实粉丝,结果他的歌一下子全没了,我差点就卸载了网易云,后来一直听Eason的歌,也渐渐不计较了,毕竟我还有其他的音乐软件 NCM事件 ncm是网易云独家格式,只能用网易云的播放器播放,手机铃声不兼容,不能放到mp3听 所以我停止续费了会员,然后更离谱的地方又来了 我的会员的歌全都没法听了,而且我下载到本地了,也不行 不止网易云,还有其他音乐软件也这样干,以后国内没有mp3格式的,全是ncm,cnm,nmb格式的 所以我选择Apple Music 我们看过了 PC&gt;ipad&gt;iphone&gt;iWatch 这4大产品 问题来了,我介绍了苹果的几大产品,可是你们并没有感受到苹果的生态圈啊!没错,单说产品,谁也不会感受到,所以我给你介绍一个视频 何同学的: 使用苹果全家桶是什么体验? 用文字你们是感受不到的,这个视频能让你感受到,并且是用羡慕嫉妒恨的眼光 Windows生态Windowns我们大家并不陌生,如果你用过电脑,你就绝对用过Windows系统 我们访问一下微软的官网,映入眼帘的是一张大图,大图里有一个游戏手柄,what?微软不就是个做系统的吗?xb&gt;win7&gt;win8&gt;win10,他居然还往游戏圈发展?(狗头滑稽) Xbox (微软自家生产的游戏机,类似ps3,ps4) Surface (美国微软公司推出的全新硬件品牌)什么鬼,你完全不知道这是什么?让我把百科搬过来: Surface是美国微软公司推出的全新硬件品牌，微软公司于2012年6月19日发布了Surface系列平板电脑。这款平板电脑采用镁合金机身10.6英寸显示屏，配备USB 2.0或3.0接口，使用Windows 8操作系统。微软官网将其称为“全高清显示屏”，屏幕比例为16:9。这款产品分为两个版本：一个使用Windows 8专为ARM设计的版本Windows RT；另一个使用英特尔Core i5 Ivy Bridge处理器，使用Windows 8 Pro 。2012年10月26日，中国市场由苏宁全球同步首发微软Surface。 微软Surface总经理帕诺斯·班乃介绍说: Surface2是个人用户兼顾娱乐与办公的首选平板电脑。它不仅提供用户希望从平板电脑中获得的娱乐和游戏功能，还能帮助用户轻松完成工作。Surface Pro2是Surface Pro的升级产品，与上一代产品一样，是真正的笔记本电脑的替代产品，能够运行几乎所有的Windows软件 微软自家的的PC 和 平板 Windows系统 Mac Os最大的对手Win10,称他们为对手有点不妥,因为他们没法比,他们俩和ios与Android是一样的存在,谁都不能替代谁 Office办公软件微软主页的第二张大图,就是我们的 office 365 , 可以看出微软还是很重视的(可能主要原因就是win10根本不需要再宣传了) Office365和Office201x的明显基本区别: 365为订阅制，每年都需要支付订阅费用才能使用（可以实时更新Office新功能）。而后者为买断制，一次购买终身使用（买定离手，不会进行后续功能更新）。 我这篇文章不详细介绍,如果你想了解具体,请利用搜索引擎 看完微软家的几大产品,我们来看看微软的服务 OneDrive 014年2月19日，微软正式宣布OneDrive云存储服务上线，支持100多种语言，面向全球替代微软SkyDrive。 使用的是Microsoft账户 对应苹果家的iCloud “给你一个好地方,来保存照片,文件等资料”这是iCloud,主页上宣传的一句话,同样也是一个云存储应用 它使用AppleID 苹果:”我们有iCloud,它可以在我们任何苹果设备上通用同步”; 微软:”我们也有OneDrive,它可以在我们的win系统上进行通用同步”; 可以看出来,两家在打造自己生态上,非常重视,一个账号可以通用我们所有产品,这是他们的理念 然后让我们看看跟我们中国没什么关系,但是又不得不提的一个公司 Google生态我的码字突然停了下来,因为我不知道Google生态有什么,好吧,我去搜一下 优质的生态服务 极致体验 体验相当好！！好到如果没有谷歌服务答主就不会再用安卓的地步！ 这是我看到的几个句子,无疑都是在说Google的安卓手机上的服务,不低于ios生态体验 我确实对google的服务孤陋寡闻了,我今年18岁,从我熟练使用电脑之后,google已经退出了中国市场,具体什么原因,我这里就不谈了 知乎链:Android 中 Google 服务包含什么，在国内的体验如何？ 我常用的除了google邮箱接受一下注册验证,就是搜索引擎了 baidu的搜索引擎 让我们搜索一下 Java 学习 看看结果 Google 搜索 同样输入 Java 学习 结果 谷歌总感觉有些时候懂我们想要什么 但百度抛去广告不谈,他可能有时候不知道我们需要什么 总结:大概了解了每个厂的生态圈了,基本只有一个理念,就是全方位服务,而不是依靠第三方软件,比如win10自带的Windows Defender杀毒软件 Android手机现在慢慢的,无论配置还是工艺,绝对能跟iphone持平,并且Android有更大的电池,更快的充电,更狠的骁龙处理器,几乎所有的手机商都在配置上进行堆积 我买Android手机看的是什么? 配置 美观度 品牌 几乎就这3大类,可能还会有 像素,以及系统美观度 那我那买iPhone会看什么? 美观度 内存 iphone就是这样,总是给用户更好的体验,包括选手机,只有一个系列,并且系统UI也很ok Android急需一个想Google全家桶那样的服务出现,当然可能咱们的厂商已经有了,可是我希望更优秀一点,现在整个Android市场都乱糟糟的,各种国产品牌摆在你眼前,还有各种高大上的配置,眼花缭乱 再说说软件方面作为一个软件应该老实一点,你询问我是否可以访问通讯录,我说不行就是不行,可是Android这边的软件都是爷,但是ios这边的软件一个个就成孙子的,我说点了不允许访问通讯录 ,软件就访问不到,这点ios做到了,我希望Android也尽量把控一下","link":"/2019/06/16/shengtaiquan/"},{"title":"《大话数据结构》学习笔记-day02-算法","text":"算法: 算法是解决特定问题求解步骤的描述,在计算机中表现为指令的有限序列,并且每条指令表示一个或多个操作 一, 两种算法的比较计算 1+2+3+4….+100 我们第一之间想到的写法是: 1234567int sum = 0;int n = 100;for (int i = 1;i &lt;= n; i++){ sum = sum + i;}System.out.println(sum); 1.1 高斯算法 sum = 1+2+3+4+…+100 sum = 100+99+98+…+2+1 2xsum = 101+101+101+…+101+101 所以 sum = 5050 代码实现: 123int i,sum = 0,n = 100sum = (1 + n) * n / 2println(sum)// 5050 ​ 高斯算法相当于另一种求等差数列的算法,不仅仅可以用 1 加到100,就是 一千,一万,也就是瞬间的事,如果用刚才的程序,就要循环 一千,一万次 1.3 算法定义如今普遍认可的对算法的定义事: 算法是解决特定问题求解步骤的描述,在计算机中表现为指令的有限序列,并且每条指令表示一个或多个操作 ​ 为了解决某个 或 某类问题, 需要把指令表示成一定的操作序列,操作序列包括一组操作,每一个操作都完成特定的功能,这就是算法了 1.4 算法的特性 算法的五个基本特性: **输入,输出,有穷性,确定性 和 可行性** 1.4.1 输入输出​ 算法具有零个或多个输入,大多数算法来说,输入参数都是必要的,但对于个别情况,比如打印Hello,World!这样的代码不需要任何输入参数,因此算法的输入可以是零个 ​ 算法至少有一个或多个输出,算法一定需要输出的,不需要输出,用算法的意义是什么?输出的形式可以是打印输出,也可以是返回一个或多个值等.. 1.4.2 有穷性 **有穷性: 指算法在执行完有限步骤之后,自动结束而不会出现死循环,并且每一个步骤在可接受的时间内完成** ​ 现实中经常写出死循环代码,这就是不满足穷性,这里的穷的概念并不是纯数学意义,而是在实际应用当中合理的,可以接受的 “有边界”,你说你写的算法,计算机需要运行二十年,一定会结束,它在数学意义上是有穷了,可是媳妇熬成婆了,算法意义就不大了 1.4.3 确定性 确定性: 算法的每一步骤具有确定的含义,不会出现二义性 ​ 算法的每个步骤被精确定义而无歧义 1.4.4 可行性 可行性: 算法的每一步都必须是可行的,也就是说,每一步都能够通过执行有限次数完成 ​ 意味着算法可以转换为程序上机运行,并得到正确结果 二, 算法设计的要求 ​ 算法不是唯一的,同一个问题,可以有多个解决问题的算法,尽管算法不唯一,但是相对好的算法是存在的,那么什么是好的算法? ​ 起码要正确,如果正确都谈不上,还谈什么性能 2.1 正确性 ​ 正确性: 算法的正确性是指算法至少应该具有输入,输出和加工处理无歧义性,能正确反映问题的需求,能够得到问题的正确答案 ​ 好的算法是容易理解的 2.2 可读性 ​ 可读性: 算法设计的另一目的是为了便于阅读,理解和交流 ​ 如果可读性不好,时间长了可能自己都不知道再写些什么,可读性是算法(也包括实现它的代码) 好坏很重要的标志 2.3 健壮性 ​ 健壮性: 但输入的数据不合法的时候,算法也能做出相关的处理,而不是产生异常或莫名其妙的结果 ​ 比如输入的时间或者距离不应该是负数等 2.4 时间效率高,和存储量低 对于同一个问题,如果有多个算法能够解决: 时间效率上 &gt; 执行时间最短的算法效率高,执行时间长的效率低 存储量 &gt; 算法在执行的过程中需要最大的存储空间,主要指程序运行时所占用的内存或外部硬盘存储空间 ​ 设计算法应尽量满足书简效率高,存储量低的需求 ​ 综上,好的算法,应该具有 正确性,可读性,健壮性,高效率和低存储量的特征 三, 算法效率的度量方法 我们通过对算法的数据测试,利用计算机的计时功能,来计算不同算法的效率高低 3.1 事后统计方法 **事后统计方法: 这种方法主要是通过设计好的测试程序和数据,利用计算机计时,对不同算法编制的程序的运行时间进行比较,从而确定算法效率的高低** 这种方法有很大的缺陷: 需要花费时间和精力去编写程序,如果写出来的是很糟糕的算法,那就是浪费时间了 比较依赖计算机硬件和软件等环境因素,有时候会掩盖算法本身的优劣 测试的数据的大小,比如10个和100万个数据,数据的多少会影响算法的优势,有可能A算法计算小数据的时候比B快,有可能到了100万个数据的话,B又比A快 3.2 事前分析估算方法​ 计算机前辈们为了对算法评判更加科学,研究了一种 事前分析估算的方法 ​ 事前分析估算方法: 程序编制前,依据统计方法对算法进行估算 算法采用的策略 , 方法 (算法好坏的根本) 编译产生的代码质量 (软件来支持) 问题输入的规模 机器执行指令的速度 (硬件性能) ​ 程序的运行时间,依赖于算法的好坏和问题输入的规模,所谓问题输入规模是指输入量的多少 再来看看刚才的两个例子: 第一种算法 第二种算法: ​ 第一种算法执行了 1+(n+1) + n+1刺 = 2n+3 次; ​ 第二种算法是 1+1+1=3次 ​ 两个算法其实是 n 次 与 1次的差距,算法的好坏显而易见 延伸一下 ​ i 从 1 到 100 ,每次都让 j 循环 100 次, 而当中的 x++和 sum = sum + x; ​ 其实就是 1+2+3…+10000,也就是100²次,所以这个算法当中,循环部分的代码整体需要执行 n² (忽略循环体头尾的开销)次 ​ 测试运行时间最可靠的方法就是计算对运行时间有小号的基本操作的执行次数,运行时间于这个计数成正比 ​ 最终,在分析程序的运行时间时,最重要的是把程序看成是独立于程序设计语言的算法或一系列步骤 ​ 同样输入规模 n : 第一种算法 就是 1+2+3…+n, 那么这个问题的输入规模使得操作数量是f(n) = n, 100次同一段代码规模,是运算10次的10倍; 而第二种算法,无论n为多少,运行次数都为 1 ,即 f(n) = 1; 第三种,运算 100 次 是运算10次的100倍, 因为他是 f(n) = n²; ​ 我们在分析一个算法的运行时间时,重要的是把基本操作的数量与输入规模关联起来,即基本操作的数量必须表示成输入规模的函数 四, 函数的渐近增长 (1) 判断算法A 和 算法B 哪个好,假设两个算法的输入规模都是 n ​ 算法A 要做 2n + 3 次操作,可以理解成先有一个 n 次循环,执行完成后,再有一个 n 次循环 , 最后有三次赋值或运算,共 2n+3次操作, ​ 算法B 要做 3n+1次操作, 请问它们谁更快 ​ 准确来说,答案是不一定的 次数 算法A (2n + 3) 算法A ‘(2n) 算法B (3n+1) 算法B’(3n) n = 1 5 2 4 3 n = 2 7 4 7 6 n = 3 9 6 10 9 n = 10 23 20 31 30 n = 100 203 200 301 300 ​ n = 1 时,算法A效率不如B (次数比算法B要多一次),而当 n=2时,两者效率相同;当 n&gt;2时,算法A就开始优于算法B了,随着n增加,算法A比 B越来越好了(执行的次数比B要少),结论是算法A总体比B好 ​ 此时我们给出这样的定义,输入规模n在没有限制的情况下,只要超过一个数值N,这个函数就总是大于另一个函数,我们称函数是渐近增长的 函数的渐近增长: 给定两个函数f(n)和g(n),如果存在一个整数N,使得对于所有的n&gt;N,f(n)总是比g(n)大,那么,我们说f(n)的增长渐近快于 g(n) ​ 从中可以发现,随着 n 的增大,后面的+3 还是 +1 其实是不影响最终的算法变化的,例如算法A 与 算法B , 所以, 我们可以忽略这些加法常数,后面的例子会更加明显 (2) 算法C 是 4n + 8, 算法D是 2n²+1 // n=3时,n²=9,9+9=18,18+1=19 ​ 当 n &lt;= 3 的时候,算法C要差于D (因为算法C次数比较多),但当 n&gt;3后,算法C的优势越来越大于D了,后面更是远远胜过,而把后面常数去掉后,我们发现结果没有变化,甚至再观察发现,哪怕去掉与n相乘的常数,这样的结果也没发生改变, 算法C’的次数随着从n 的增长,还是远小于算法D’,也就是说,与最高次项相乘的常数并不重要 (3) 算法E 是 2n² + 3n + 1, 算法F是 2n³ + 3n + 1 ​ n = 1的时候, 算法E 与 算法F 的结果相同 , 但当 n&gt;1后,算法E的优势就要开始优于算法F,随着n的增大,差异非常明显, 通过观察发现, 最高次项的指数大的,函数随着n的增长,结果也会变得增长的特别快 (4) 算法 G 是 2n²,算法H 是 3n + 1 , 算法I 是2n² + 3n + 1 ​ 根据这个例子,我们得出结论,判断一个算法的效率时,函数中的常数和其他次要项常常可以忽略,而更应该关注主项(最高阶项)的阶数 ​ 判断一个算法好不好,通过前几个例子,可以对比这几个算法的渐近增长性,基本可以分析出:某个算法,随着n的增大,它会越来越优于另一算法,或越来越差于另一算法,这其实就是事前估算方法的理论依据,通过算法的时间复杂度来估算算法时间效率 五, 算法时间复杂度5.1 算法时间复杂度定义 算法分析时,语句执行次数T(n) 是 关于问题规模 n 的函数,进而分析T(n) 随 n 的变化情况并确定T(n)的数量级,算法时间复杂度,也就是算法的时间量度,记作: T(n) = O(f(n)),他表示随问题规模n的增大,算法时间增长率和 f(n)的增长率相同,称作算法的渐近时间复杂度,简称为时间复杂度,其中 f(n)是问题规模n的某个函数 ​ 用大写的 O() 来体现算法时间复杂度的记法,我们称为 大O记法 ​ 一般来说,随着n的增大,T(n)增长最慢的算法成为最优算法 ​ 非官方名称: O(1)常数阶 , O(n)线性阶 , O(n²)平方阶 等等.. 5.2 推导大 O 阶方法 推导大O阶: 用常数 1 取代运行时间所有的加法常数 再修改后的运行次数函数中,只保留最高阶项 如果最高阶项存在且不是 1 , 则去除这个项相乘的常数 得到的结果就是大O阶 5.3 常数阶高斯算法: 123int sum = 0,n=100; //执行一次sum = (1+n)* n/2;//执行一次print(sum)//执行一次 ​ f(n) = 3, 根据推导大O阶的方法, 把 3 改为 1, 保留最高阶项时发现,它没有最高阶项,所以这个算法时间复杂度为 O(1) ​ 如果 sum = (1+n)* n/2;有10句: 123456789101112int sum = 0,n=100; //执行一次sum = (1+n)* n/2;//执行一次sum = (1+n)* n/2;//执行一次sum = (1+n)* n/2;//执行一次sum = (1+n)* n/2;//执行一次sum = (1+n)* n/2;//执行一次sum = (1+n)* n/2;//执行一次sum = (1+n)* n/2;//执行一次sum = (1+n)* n/2;//执行一次sum = (1+n)* n/2;//执行一次sum = (1+n)* n/2;//执行一次print(sum) //执行一次 ​ 时间复杂度还是 O(1) , 因为他俩的区别就是 3次 和 12次执行的差异,这种与问题的大小无关(n 的多少),执行时间恒定的算法,我们称之为具有 O(1)的时间复杂度,又叫常数阶 ​ 注意: 不能计为 O(3),O(12)等其他任何数字,只能是 O(1) 5.4 线性阶​ 线性阶循环结构要复杂很多,要确定某个算法的阶次,我们长长需要确定某个特定语句或某个语句集运行的次数,因此,我们要分析算法的复杂度,关键要分析循环结构的运行情况 ​ O(n)的算法: 1234int i;for (i = 0; i &lt; n; i++){ // 时间复杂度为 O(1)的程序步骤序列} 5.5 对数阶 ​ 由于每次 count 乘以2之后,就距离n更近了一分,也就是说,有多少个 2 相乘后大于 n,则退出循环,由 2^x = n 得到 x = log^2 n,所以这个算法时间复杂度为 O(logn) 5.6 平方阶 ​ 对于外循环,内循环这个时间复杂度为O(n)的语句,再循环n次,所有这段代码时间复杂度为O(n²) ​ 如果外循环的循环次数改为了 m,时间复杂度就变为了O(m ✖ n) 1234for (i = 0;i &lt; m; i ++){ for (j = 0;j &lt; n; i ++){ }} ​ 总结出: 循环的时间复杂度等于循环体的复杂度乘以该循环运行的次数 ​ 对于方法调用的时间复杂度该如何分析: 12345int i,j;for (i = 0; i &lt; n; i++){ function(i)} ​ 上面代码调用了 一个函数 function 1234void function (int count){ print(count)} ​ 函数体就是打印这个参数,其实这很好理解,function 函数的时间浮躁度是 O(1),所以整体的时间复杂度为O(n) ​ 假如 function 是下面这样的: 12345678void function(int count){ int j; for(j = count; j &lt; n; j++) { // 时间复杂度为 O(1)的程序步骤序列 }} ​ 这和刚才的例子一样,只不过把嵌套内循环放到了函数中,所以最终的时间复杂度为O(n²) ​ 下面这段相对复杂的语句: 1234567891011121314n++; // 执行次数为 1function(n); // 执行次数为 nint i,j for (i = 0;i &lt; n; i++) // 执行次数为 n² { function(i) }for (i = 0;i &lt; n; j++) // 执行次数为 n(n+1)/2 { for ( j = i; j &lt; n; j++) { // 时间复杂度为O(1)的程序步骤序列 } } ​ 它的执行次数: ​ 根据推导大O阶的方法,最终这段代码的时间复杂度为O(n²) 六, 常见的时间复杂度 七, 最坏情况与平均情况​ 如果我们想要查找 n 个元素的数组中某个数字,最好的情况第一个数字就是,那么算法的时间复杂度O(1),但也有可能这个数字在最后一个位置上待着,那么算法的时间复杂度就是O(n),这是最坏的一种情况了 ​ 最坏情况运行时间: 是一种保证,那就是运行时间不会再坏了,在应用中,这是一种最重要的需求,通常,除非特别指定,我们提到的运行时间都是基于最坏情况的运行时间 ​ 平均运行时间: 是所有情况中最有意义的,因为它是期望的运行时间 但是在没有特殊说明的情况下,都是指最坏时间复杂度 八, 算法空间复杂度​ 算法的空间复杂度通过计算算法所需的存储空间实现,算法空间复杂度的计算公式记作 : S(n)= O(f(n)), 其中 ,n为问题的规模,f(n)为语句关于 n 所占存储空间的函数 ​ 一般情况下,一个程序执行时,除了需要存储程序本身的指令,常数,变量和输入数据外,还需要存储对数据操作的存储单元,若输入数据所占空间只取决于问题本身,和算法无关,这样只需要分析该算法在时间时所需的辅助单元即可,若算法执行时所需的辅助空间相对于输入数据量而言是个常数,则称此算法为原地工作,空间复杂度为 O(1) ​ 通常我们都用 “时间复杂度” 来指运行时间的需求,使用”空间复杂度”指空间需求,当不用限定词地使用”复杂度”时,通常都是指时间复杂度 九, 总结​ 数据结构与算法关系是相互依赖不可分割的 ​ 算法的定义: ​ 算法是解决特定问题求解步骤的描述,在计算机中为指令的有限序列,并且每条指令表示一个或多个操作 算法的特性: 有穷性,确定性,可行性,输入,输出 算法的设计的要求: 正确性,可读性,健壮性,高效率和低存储量需求 算法特性与算法设计容易混,需要对比记忆 算法的度量方法: 事后统计方法(不科学,不准确),事前分析估算方法 ​ 在说如何用事前分析估算方法以前,我们先给出了函数渐近增长的定义 函数的渐近增长 : 给定两个函数 f(n) ,g(n), 如果存在一个整数N,使得对于所有的n&gt;N,f(n)总是比g(n)大,那么,我们说 f(n) 的增长渐近快于g(n), 判断算法的好不好,只通过少量的数据是不能做出准确判断的,如果我们可以对比算法的关键执行次数函数的渐近增长行,基本可以分析出:某个算法,随着问题规模n的扩大,越来越优于另一个算法,或者越来越差于另一个算法 ​ 然后给出了算法时间复杂度的定义和推导大O阶的步骤 推导大O阶: 用常数 1 取代运行时间中的所有加法常数 在修改后的运行次数函数中,只保留最高阶项 如果最高阶项存在且不是1,则去除与这个项相乘的常数 得到的结果就是大O阶 通过这个步骤,我们可以在得到算法的运行次数表达式后,很快得到它的时间复杂度,即大O阶,其实推导大O阶很容易,但如何得到运行次数的表达式却是需要数学功底的 常见时间复杂度所耗时间的大小排列: 最后,给出了算法最坏情况和平均情况的概念,以及空间复杂度的概念","link":"/2019/06/25/dahua2/"},{"title":"scala 环境搭建&基本语法","text":"0x00开始安装1. JVMScala是运行在JVM平台上的,所以你需要有JDK环境 2.安装ScalaWindows安装Scala编译器 点此下载 访问Scala官网http://www.scala-lang.org/下载Scala编译器安装包，目前最新版本是2.12.x 下载scala-2.11.8.msi后点击下一步就可以了（一般会自动配置上环境变量）。也可以下载scala-2.11.8.zip解压即可 检查环境变量是否成功,打开CMD(也可以去path里看有没有$SCALA_HONE$)输入scala Linux安装Scala编译器下载Scala地址https://www.scala-lang.org/download/2.11.8.html 然后解压Scala到指定目录 tar -zxvf scala-2.11.8.tgz -C /opt/soft 配置环境变量，将scala加入到PATH中 vim /etc/profile export JAVA_HOME=/opt/soft/jdk1.8 export PATH=$PATH:$JAVA_HOME/bin:/opt/soft/scala-2.11.8/bin Idea安装目前Scala的开发工具主要有两种：Eclipse和IDEA，这两个开发工具都有相应的Scala插件，如果使用Eclipse，直接到Scala官网下载即可http://scala-ide.org/download/sdk.html。 由于IDEA的Scala插件更优秀，大多数Scala程序员都选择IDEA，可以到http://www.jetbrains.com/idea/download/下载，点击下一步安装即可，安装时如果有网络可以选择在线安装Scala插件。 离线安装Scala插件： 1.安装IDEA，点击下一步即可。 2.下载IEDA的scala插件 插件地址： https://plugins.jetbrains.com/plugin/1347-scala 3.安装Scala插件：Configure -&gt; Plugins -&gt; Install plugin from disk -&gt; 选择Scala插件 -&gt; OK -&gt; 重启IDEA 在线安装Scala插件： idea打开: Settings -&gt; Plugins -&gt; 搜索Scala -&gt; lnstall -&gt;重启idea 记得设置补全变量类型: 0x01基本语法 Scala代码 123456object HelloScala { def main(args: Array[String]): Unit = { println(\"hello scala\") System.out.println(\"hello java\") }} 对比Java代码 123456public class HelloJava { public static void main(String[] args){ System.out.println(\"hello java\"); Console.print(\"hello scala\"); }} Scala易百教程 Scala菜鸟教程 0x01变量、类型、操作符1.变量声明Scala声明变量有两种方式，一个用val，一个用var。 val/var 变量名 : 变量类型 = 变量值。 val和var声明变量时都必须初始化。 val定义的值是不可变的，它不是一个常量，是不可变量，或称之为只读变量。相当于java里用final修饰的变量 val定义的变量虽然不能改变其引用的内存地址，但是可以改变其引用的对象的内部的其他属性值。 为了减少可变性引起的bug，应该尽可能地使用不可变变量。 变量类型可以省略，解析器会根据值进行推断。 关键字 是否可以更改 var 声明变量 可以 val 声明常量 不可以 Scala 语言鼓励程序员使用 val 来声明,因为Scala语言设计哲学中,认为流程中修改变量值,会造成程序逻辑复杂,不易维护,不易并行计算 1234567891011121314object VariableDemo { def main(args: Array[String]) { //使用val定义的变量值是不可变的，相当于java里用final修饰的变量 val i:Int = 1 //使用var定义的变量是可变得，在Scala中鼓励使用val var s1 = \"hello\" var s2 = \"hello\" //Scala编译器会自动推断变量的类型，必要的时候可以指定类型 //变量名在前，类型在后 //import java.lang._ val s3:String = \"bigdata\" val s4:java.lang.String = \"bigdata\" }} 2.常用数据类型Scala和Java一样，有多种数值类型Byte、Char、Short、Int、Long、Float、Double类型和1个Boolean类型。 Boolean true 或者 false Byte 8位, 有符号 Short 16位, 有符号 Int 32位, 有符号 Long 64位, 有符号 Char 16位, 无符号 Float 32位, 单精度浮点数 Double 64位, 双精度浮点数 String 其实就是由Char数组组成 Scala继承层级 统一类型，是Scala的又一大特点。 Any 在scala中，所有的类，包括值类型，都最终继承自一个统一的根类型Any，Any类是跟节点 Any中定义了isInstanceOf、asInstanceOf方法，以及哈希方法等。AnyVal和AnyRef都扩展自Any类。 AnyVal 所有的值都是类类型都是AnyVal的子类， AnyRef 所有其他类都是AnyRef的子类，类似Java的Object。 更特别的是，Scala中还定义了几个底层类（Bottom Class），比如Null和Nothing。 Null 是所有引用类型的子类型，Null类只有一个实例对象，null，类似于Java中的null引用。null可以赋值给任意引用类型，但是不能赋值给值类型。 Nothing 是所有类型的子类型。Nothing类型没有实例。它对于泛型结构是有用处的，举例： 空列表Nil的类型是List[Nothing]，它是List[T]的子类型，T可以是任何类。 Nothing可以作为没有正常返回值的方法的返回类型，非常直观的告诉你这个方法不会正常返回，而且由于Nothing是其他任意类型的子类，他还能跟要求返回值的方法兼容。 Unit 用来标识过程，也就是没有明确返回值的函数。由此可见，Unit类似于Java里的void。Unit只有一个 对象实例，()，这个实例也没有实质的意义。 Any 在scala中，Any类是所有类的超类，Any有两个子类：AnyVal和AnyRef AnyVal- 所有值类型的基类， 它描述的是值，而不是代表一个对象。 它包括 9个AnyVal 子类型： - scala.Double - scala.Float - scala.Long - scala.Int - scala.Char - scala.Short - scala.Byte 上面是数字类型。 还包括scala.Unit 和 scala.Boolean 是非数字类型。 AnyRef- 是所有引用类型的基类。除了值类型，所有类型都继承自AnyRef 。 注意: 与Java中的数据类型不同，Scala并不刻意区分基本类型和引用类型，所以这些类型都是对象，可以调用相对应的方法。 String直接使用的是java.lang.String. 不过，由于String实际是一系列Char的不可变的集合，Scala中大部分针对集合的操作，都可以用于String. 具体来说，String的这些方法存在于类scala.collection.immutable.StringOps中。 由于String在需要时能隐式转换为StringOps，因此不需要任何额外的转换，String就可以使用这些方法。 每一种数据类型都有对应的Rich* 类型，如RichInt、RichChar等，为基本类型提供了更多的有用操作。 3.操作符重载Scala中的+ - * / %等操作符的作用与Java一样，位操作符 &amp; | ^ &gt;&gt; &lt;&lt;也一样。但是有一点区别，这些操作符实际上是方法。 那么既然+ - * / %是方法,那么就可以进行操作符重载,完成特殊的运算 你几乎可以用任何符号来为方法命名。 注意：Scala中没有++、–操作符，需要通过+=、-=来实现同样的效果。 举例 123456789101112131415package com.bigdata.basicobject OperationDemo { def main(args: Array[String]): Unit = { var a = 1 + 2 var b = 1.+(2) println(a)//3 println(b)//3.0 //var c = a++ //错误 a += 1 a.+=(1) println(a)//5 }} 运算符重载 伪代码 操作符总结 1) 如果想在变量名、类名等定义中使用语法关键字（保留字），可以配合反引号反引号： 1val `val` = 123 2) 中置操作符，A操作符B等同于A.操作符(B) ==&gt; a + b ==&gt; a.+(b) 3) 后置操作符，A操作符等同于A.操作符，如果操作符定义的时候不带()则调用时不能加括号 4) 前置操作符，+、-、！、~等操作符A等同于A.unary_操作符。 5) 赋值操作符，A操作符=B等同于A=A操作符B 0x02判断和循环1.条件表达式Scala的的条件表达式比较简洁,且Scala中if else表达式是有返回值的，如果if或者else返回的类型不一样，就返回Any类型（所有类型的公共超类型）。 如果缺少一个判断，什么都没有返回，但是Scala认为任何表达式都会有值，对于没有返回值的，使用Unit类，写做()，叫做无用占位符，相当于java中的void 1234567891011121314151617181920212223242526272829package com.bigdata.basicobject ConditionDemo { def main(args: Array[String]) { val x = 1 //判断x的值，将结果赋给y val y = if (x &gt; 0) 1 else -1 //打印y的值 println(y) //支持混合类型表达式 val z: Any = if (x &gt; 1) 1 else \"error\" //打印z的值 println(z) //如果缺失else，相当于if (x &gt; 2) 1 else () val m = if (x &gt; 2) 1 println(m) //在scala中每个表达式都有值，scala中有个Unit类，用作不返回任何结果的方法的结果类型,相当于Java中的void，Unit只有一个实例值，写成()。 val n = if (x &gt; 2) 1 else () println(n) //if和else if val k = if (x &lt; 0) 0 else if (x &gt;= 1) 1 else -1 println(k) }} 2.块表达式定义变量时用{} 包含一系列表达式，其中块的最后一个表达式的值就是块的值。 12345678910111213141516171819package com.bigdata.basicobject BlockExpressionDemo { def main(args: Array[String]) { val x = 0 //在scala中{}中包含一系列表达式，块中最后一个表达式的值就是块的值 val result : Any= { if (x &lt; 0){ -1 } else if(x &gt;= 1) { 1 } else { \"error\" } } //result的值就是块表达式的结果 println(result) }} 1234567891011121314package com.bigdata.basicobject BlockExpressionDemo2 { def main(args: Array[String]): Unit = { val a = 1 val b = 2 val result = { val c = a + b val d = c + a d } println(result) }} 3.循环在scala中有for循环和while循环，用for循环比较多 while 1234567891011121314151617181920212223242526package com.bigdata.basicobject WhileDemo { def main(args: Array[String]): Unit = { var n = 1; val while1 = while(n &lt;= 10){ n += 1 } println(while1) println(n) println(\"===============\") import scala.util.control.Breaks val loop = new Breaks loop.breakable{ while(n &lt;= 20){ n += 1; if(n == 18){ loop.break() } } } println(n) }} 注意： 与If语句不同，While语句本身没有值，即整个While语句的结果是Unit类型的() scala并没有提供break和continue语句来退出循环，如果需要break，可以通过几种方法来做 1、使用Boolean型的控制变量 2、使用嵌套函数，从函数中return 3、使用Breaks对象的break方法。 for for循环语法结构： for (变量 &lt;- 表达式/数组/集合) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package com.bigdata.basicobject ForDemo { def main(args: Array[String]) { //1.for(i &lt;- 表达式),表达式1 to 10返回一个Range [] //to为[] until 为 [) //每次循环将区间中的一个值赋给i for (i &lt;- 1 to 10)//[1,10] println(i) println(\"==========\") for (i &lt;- 1 to 10 by 2)//[1,10]步长为2 println(i) println(\"==========\") for (i &lt;- 1 until 10)//[1,10) println(i) println(\"==========\") //2.for(i &lt;- 数组) val arr = Array(\"a\", \"b\", \"c\") for (i &lt;- arr) println(i) //总结: /*for(变量名 &lt;- 集合){ 循环体 }*/ //3.高级for循环 //每个生成器都可以带一个条件，注意：if前面没有分号 for(i &lt;- 1 to 3; j &lt;- 1 to 3 if i != j) print((10 * i + j) + \" \") println() //4.for推导式：如果for循环的循环体以yield开始，则该循环会构建出一个集合 //即将遍历过程中处理的结果返回到一个变量 //每次迭代生成集合中的一个值 val v = for (i &lt;- 1 to 10) yield i * 10 println(v) // 10,20,30..100 //也就是说:如果for循环的循环体以yield开始,for循环会返回一个集合 //5.{}和 ()都可以 //当for 推导式仅包含单一表达式时使用()括号，当其包含多个表达式时使用{}括号 for( i &lt;- 1 to 3; //[1,3] j = 4 - i//[3,1] ) print(i * j + \" \") println() for { i &lt;- 1 to 3; j = 4 - i } print(i * j + \" \") println() }} 0x03 方法和函数1.调用方法和函数在scala中，函数与方法是不同的东西。后面我们再详细探讨。首先我们要学会使用scala来调用函数与方法。 12345678910111213141516171819202122232425262728293031323334353637object MethodAndFunctionDemo { def main(args: Array[String]): Unit = { //1.静态方法（scala中没有静态方法这个概念，需要通过伴生类对象来实现） val a: Double = math.sqrt(100)//对象名.方法名 println(a) //2.非静态方法，使用对象调用 val s = \"HelloWorld\" val len: Int = s.length println(len) //3.apply方法是调用时可以省略方法名的方法。用于构造和获取元素： //Array(1,2,3) 等同于 Array.apply(1,2,3) val arr1 = Array(1,2,3) println(arr1.mkString(\",\")) val arr2 = Array.apply(1,2,3) println(arr2.mkString(\",\")) //\"Hello\"(1) 等同于 \"Hello\".apply(1) //输出e val c1: Char = \"Hello\"(1) println(c1) val c2 = \"Hello\".apply(1) println(c2) //4.update方法也是调用时可以省略方法名的方法，用于元素的更新 //arr1(1) = 5 等同于 arr2.update(1,5) arr1(1) = 5 println(arr1.mkString(\",\")) arr2.update(1,5) println(arr2.mkString(\",\")) //5.定义并调用函数 val fun = (x:Int) =&gt; x * 10 val arr3: Array[Int] = arr1.map(fun) println(arr3.mkString(\",\")) }} 2.定义方法def 方法名(参数名1: 参数类型1, 参数名2: 参数类型2) : 返回类型 = {方法体} 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162object MethodAndFunctionDemo2 { def main(args: Array[String]): Unit = { val a = m1(2,3) println(a) val b = factorial(4) println(b)//4*3*2*1==24 shout4(\"abc\") //\"abc4\" shout4(content=\"abc\")//\"abc4\" shout4(content=\"abc\",leg=3)//\"abc3\" shout4(leg=3,content=\"abc\")//\"abc3\" val s1: Int = sum(1,2) println(s1) val s2: Int = sum(1,2,3) println(s2) } //1.方法的返回值类型和return可以不写，编译器可以自动推断出来 //def 方法名(参数名:参数类型,参数名:参数类型):返回值类型={方法体} def m1(x:Int,y:Int):Int = { x*y } //2.对于递归方法，必须指定返回类型 def factorial(n: Int): Int = { if(n &lt;= 0) 1 else n * factorial(n - 1) } //f(3) --&gt; 3*f(2) --&gt;3*2*f(1) --&gt;3*2*1*f(0) --&gt;3*2*1*1 ==&gt; 6 //3.如果方法没有返回值,返回Unit类型(返回值为Unit的方法也叫过程) def shout1(content: String) : Unit = { println(content) } //4.返回Unit类型，类型也可以省略 def shout2(content: String) = { println(content) } //5.返回值类型有多种可能，此时为Any def shout3(content: String):Any = { if(content.length &gt;= 3) content + \"喵喵喵~\" else 3 } //6.带有默认值参数的方法，调用时，可以只给无默认值的参数传递值，也可以都传递，新值会覆盖默认值； //传递参数时如果不按照定义顺序，则可以通过参数名来指定 def shout4(content: String, leg: Int = 4) = { println(content + \",\" + leg) } //7.可变参使用 变量名:类型* （类似Java的...） def sum(args: Int*) = { var result = 0 for(arg &lt;- args) result += arg result }} 3.定义函数val函数名称 :(参数类型)=&gt;函数返回值类型 = (参数名称:参数类型)=&gt;函数体 或者简写 val函数名名称 = (参数名称:参数类型) =&gt; 函数体 带有一个参数的函数的类型是function1，带有两个是function2，以此类推 123456789101112131415object FunctionDemo { def main(args: Array[String]): Unit = { //定义函数方式1: //函数名称= (参数名:参数类型) =&gt; 函数体 val f1 = (x:Int,y:Int) =&gt; x + y val i1 = f1(1,2)//3 println(i1) //定义函数方式2:(了解) //函数名称:(参数类型) =&gt;函数返回值类型= (参数名称:参数类型) =&gt;函数体 val f2:(Int,Int) =&gt; Int = (x,y) =&gt; x + y val i2 = f2(1,2); println(i2) }} 4.方法和函数的区别方法:和之前理解的方法一样,是封装了完成某些功能的代码块,所属于某一个类或对象 函数:在Scala中,函数一个对象,那么既然是对象的话,函数就可以当作参数被传递,还可以使用函数打点调用方法 在函数式编程语言中，函数是“头等公民”，函数是一个对象，继承自FuctionN。它可以像任何其他数据类型一样被传递和操作 12345678def main(args: Array[String]): Unit = { val f1 = (x:Int) =&gt; x val f2 = (x:Int,y:Int) =&gt; x + y val f3 = (x:Int,y:Int,z:Int) =&gt; x + y + z println(f1) println(f2) println(f3)} 函数对象有apply、curried、toString、tupled这些方法。而方法不具有这些特性。 案例：首先定义一个方法，再定义一个函数，然后将函数传递到方法里面 123456789101112131415161718192021222324object MethodAndFunctionDemo3 { def main(args: Array[String]): Unit = { //定义了一个函数,参数是2个Int,返回值是 val f1 = (x:Int,y:Int) =&gt; x + y //或者这样定义: //函数名称:(参数类型) =&gt;函数返回值类型=(参数引用)=&gt;函数体 //val f1:(Int,Int)=&gt;Int=(x,y)=&gt;x+y val f2 = (x:Int,y:Int) =&gt; x * y //调用方法,并把函数作为参数传递给方法 val r1 = m1(f1) val r2 = m1(f2) println(r1)//8 println(r2)//12 } //定义了一个方法,参数是函数类型,方法的返回值是Int,而函数的参数是2个Int,返回值是Int def m1 (f:(Int,Int)=&gt;Int):Int={ //方法体中调用了函数,并传递了2个参数给函数, //并把函数的返回值,当作方法的返回值给方法的调用者返回 f(2,6) }} 5.将方法转换成函数（神奇的下划线)将方法转换成函数，只需要在方法的后面加上一个下划线 12345678def main(args: Array[String]): Unit = { val f1 = m1 _ println(f1)}def m1 (f:(Int,Int)=&gt;Int):Int={ f(2,6)} 6.总结 12345678910111213141516171819202122232425object FunctionDemo { def main(args: Array[String]): Unit = { //定义函数方式1: //函数名称=(参数名称:类型)=&gt;函数体 val f1 = (x:Int,y:Int) =&gt; x + y //定义函数方式2:(了解) //函数名称:(参数类型)=&gt;返回值类型 = (参数列表)=&gt;函数体 val f2:(Int,Int)=&gt;Int=(x,y)=&gt;x - y val r1 = m1(f1); println(r1)//4 val r2 = m1(f2); println(r2)//2 val r3 = m1((x:Int,y:Int)=&gt;x*y) println(r3)//3 } //定义一个方法,方法的参数接收一个函数 def m1(f:(Int,Int)=&gt;Int): Int ={ f(3,1) }} 0x04其他1.懒值当val被声明为lazy时，初始化将被推迟，直到我们首次对此取值，适用于初始化开销较大的场景。 123456789101112object LazyDemo { def main(args: Array[String]): Unit = { //使用lazy修饰变量,只有当这个变量被使用到的时候,变量的赋值代码才会真正的执行 lazy val msg = init() println(\"init方法调用了,但是没有执行\") println(msg) } def init(): String = { println(\"init方法执行\") \"嘿嘿嘿，我来了~\" }} 2.异常处理Scala的异常的工作机制和Java一样，但是Scala没有“checked”受检异常，你不需要声明函数或者方法可能会抛出某种异常。 (受检异常在编译器被检查，java必须声明方法所会抛出的异常类型) 抛出异常：用throw关键字，抛出一个异常对象。所有异常都是Throwable的子类型。throw表达式是有类型的，就是Nothing，因为Nothing是所有类型的子类型，所以throw表达式可以用在需要类型的地方。 捕捉异常：在catch的代码里，使用一系列case子句(借用了模式匹配的思想来做异常的匹配) 异常捕捉的机制与其他语言中一样，如果有异常发生，catch字句是按次序捕捉的。因此，在catch字句中，越具体的异常越要靠前，越普遍的异常越靠后。 如果抛出的异常不在catch字句中，该异常则无法处理，会被升级到调用者处。 finally字句用于执行不管是正常处理还是有异常发生时都需要执行的步骤，一般用于对象的清理工作。 12345678910111213141516object ExceptionDemo { def main(args: Array[String]): Unit = { try { println(divider(10, 0)) } catch { case ex: Exception =&gt; println(\"捕获了异常：\" + ex) } finally { println(\"释放资源\") } } def divider(x: Int, y: Int): Float = { if (y == 0) throw new Exception(\"0作为了除数\") else x / y }}","link":"/2019/06/23/scala基本语法/"},{"title":"Spring Boot快速入门--你好Spring Boot(一)","text":"spring boot可以让你的开发更甜蜜~~** Build Anything with Spring Boot： Spring Boot is the starting point for building all Spring-based applications. Spring Boot is designed to get you up and running as quickly as possible, with minimal upfront nfiguration of Spring. Spring Boot 简化了 spring 应用开发的框架 官方文档: 世界上最好的文档来自官方 一.使用 Spring Boot有什么好处?以及简单的搭建过程其实就是简单、快速、方便！平时如果我们需要搭建一个 Spring Web 项目的时候需要怎么做呢？ 1）配置 web.xml，加载 Spring 和 Spring mvc 2）配置数据库连接、配置 Spring 事务 3）配置加载配置文件的读取，开启注解 4）配置日志文件 … 配置完成之后部署 Tomcat 调试 … 现在非常流行微服务，如果我这个项目仅仅只是需要发送一个邮件，如果我的项目仅仅是生产一个积分；我都需要这样折腾一遍! 但是如果使用 Spring Boot 呢？很简单，我仅仅只需要非常少的几个配置就可以迅速方便的搭建起来一套 Web 项目或者是构建一个微服务！ 1.开发环境:idea jdk1.8 windows 10 Mysql 2.创建项目使用idea new一个 Spring Lnitializr &gt; 设置group Artifact &gt;选择web&gt;勾选web&gt;设置项目路径还有名称&gt;Finish 第一次创建会有点慢,它需要下载很多依赖 创建好之后的包默认生成了以下&gt; SpringbootApplication： 一个带有 main() 方法的类，用于启动应用程序 SpringbootApplicationTests：一个空的 Junit 测试了，它加载了一个使用 Spring Boot 字典配置功能的 Spring 应用程序上下文 application.properties：一个空的 properties 文件，可以根据需要添加配置属性 pom.xml： Maven 构建说明文件 3.创建一个controller包,再创建HelloController类:1234567891011121314package com.carson.springboot.controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class HelloController { @RequestMapping(\"hello\") public String hello(){ return \"Spring boot!\"; }} @RestController 注解： 该注解是 @Controller 和 @ResponseBody 注解的合体版 4.启动SpringbootApplication:人家启动成功的图标: 再看看我的😭: 有可能是分辨率还是什么关系? 启动SpringbootApplication: SpringbootApplication启动后,它内置了tomcat ,不需要我们另外进行配置,我们可以直接访问 controller 中的 方法 端口号默认是 8080 可能你的不是,但是他会再控制台输出: 这是页面: 5.解析以下 Spring Boot 项目pom.xml: 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.carson&lt;/groupId&gt; &lt;artifactId&gt;springboot&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;springboot&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; &lt;parent&gt; :这个标签是在配置 Spring Boot 的父级依赖： 123456&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; spring-boot-starter-parent 是一个特殊的 starter ，它用来提供相关的 Maven 默认依赖，使用它之后，常用的包依赖就可以省去 version 标签。 &gt;应用入口类Spring Boot 项目通常有一个名为 *Application 的入口类，入口类里有一个 main 方法， 这个 main 方法其实就是一个标准的 Javay 应用的入口方法。 @SpringBootApplication 是 Spring Boot 的核心注解，它是一个组合注解，该注解组合了： @Configuration、@EnableAutoConfiguration、@ComponentScan； 若不是用 @SpringBootApplication 注解也可以使用这三个注解代替。 其中，@EnableAutoConfiguration 让 Spring Boot 根据类路径中的 jar 包依赖为当前项目进行自动配置，例如，添加了 spring-boot-starter-web 依赖，会自动添加 Tomcat 和 Spring MVC 的依赖，那么 Spring Boot 会对 Tomcat 和 Spring MVC 进行自动配置。 Spring Boot 还会自动扫描 @SpringBootApplication 所在类的同级包以及下级包里的 Bean ，所以入口类建议就配置在 grounpID + arctifactID 组合的包名下（这里为 cn.wmyskxz.springboot 包） &gt;Spring Boot 的配置文件Spring Boot 使用一个全局的配置文件 application.properties 或 application.yml，放置在【src/main/resources】目录或者类路径的 /config 下。 Spring Boot 不仅支持常规的 properties 配置文件，还支持 yaml 语言的配置文件。yaml 是以数据为中心的语言，在配置数据的时候具有面向对象的特征。 Spring Boot 的全局配置文件的作用是对一些默认配置的配置值进行修改。 我把 application.properties 删掉了,我创建了 application.yml , 因为我感觉yml的语法更加的适合我 我这里使用 application.yml 进行配置(两者在语法上不同): 1234567serber: port: 8080 servlet: context-path: /hellostudent: name: carson age: 18 我们同样的将 Tomcat 默认端口设置为 8080 ，并将默认的访问路径从 “/” 修改为 “/hello”,并设置自己的信息 pom.xml:123456&lt;!-- 配置文件 处理器--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; 导入配置文件处理器,写yml会有提示 先去创建一个类 StudentProperties : 1234567891011121314151617181920212223242526272829package com.carson.springboot.domain;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.stereotype.Component;@Component@ConfigurationProperties(prefix = \"student\")public class StudentProperties { private String name; private Integer age; public String getName() { return name; } public void setName(String name) { this.name = name; } public Integer getAge() { return age; } public void setAge(Integer age) { this.age = age; }} 我们可以把配置信息封装成一个类，首先在我们的 name 和 age 前加一个 student 前缀，然后新建一个 StudentProperties 的类用来封装这些信息，并用上两个注解： @Component：表明当前类是一个 Java Bean/放在容器里,和配置文件相关配置进行绑定 @ConfigurationProperties(prefix = “student”)：表示获取前缀为 sutdent 的配置信息,默认从全局配置文件中获取 我们的Controller修改成以下: 12345678@Autowired private StudentProperties studentProperties; @RequestMapping(\"/hello\") public String hello(){ return studentProperties.getName() + studentProperties.getAge(); //会在页面显示我们的信息 } &gt;Spring Boot 热部署在目前的 Spring Boot 项目中，当发生了任何修改之后我们都需要重新启动才能够正确的得到效果，这样会略显麻烦，Spring Boot 提供了热部署的方式，当发现任何类发生了改变，就会通过 JVM 类加载的方式，加载最新的类到虚拟机中，这样就不需要重新启动也能看到修改后的效果了。 做法也很简单，修改 pom.xml 即可！ 我们往 pom.xml 中添加一个依赖就可以了： 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;!-- 这个需要为 true 热部署才有效 --&gt;&lt;/dependency&gt; 重新启动 Spring Boot ，然后修改任意代码，就能观察到控制台的自动重启现象 关于idea Spring Boot 项目的简单搭建 已经结束 二.Spring Boot 使用上面已经完成了 Spring Boot 项目的简单搭建，我们仅仅需要进行一些简单的设置，写一个 HelloController 就能够直接运行了，不要太简单…接下来我们再深入了解一下 Spring Boot 的使用。 1.使Spring Boot 支持 JSPSpring Boot 的默认视图支持是 Thymeleaf 模板引擎，但是这个我们不熟悉啊，我们还是想要使用 JSP 怎么办呢？ 第一步：修改 pom.xml 增加对 JSP 文件的支持 1234567891011121314151617&lt;!-- servlet依赖. --&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- tomcat的支持.--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 第二步：配置试图重定向 JSP 文件的位置 修改 application.yml 文件，将我们的 JSP 文件重定向到 /WEB-INF/views/ 目录下(设置前缀和后缀)： 123456spring: mvc: view: prefix: /WEB-INF/views/ suffix: .jsp //如果你学过ssm 那么你能感觉出来这是 前缀 和 后缀 第三步：修改 HelloController 修改 @RestController 注解为 @Controller ，然后将 hello 方法修改为： 1234567891011121314151617181920212223242526272829package com.carson.springboot.controller;import com.carson.springboot.domain.StudentProperties;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import java.text.DateFormat;import java.util.Date;/** * @RestController 注解： 该注解是 @Controller 和 @ResponseBody 注解的合体版 * * */@Controllerpublic class HelloController {// @Autowired// private StudentProperties studentProperties; @RequestMapping(\"/hello\") public String hello(Model model){ model.addAttribute(\"now\", DateFormat.getDateTimeInstance().format(new Date())); return \"hello\"; }} 第四步：新建 hello.jsp 文件 在【src/main】目录下依次创建 webapp&gt;WEB-INF&gt;views 目录，并创建一个 hello.jsp 文件： hello.jsp 1234567891011&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;login&lt;/title&gt;&lt;/head&gt;&lt;body&gt;hello jsp! 现在时间是 ${now}&lt;/body&gt;&lt;/html&gt; 第五步：刷新网页 因为我们部署了热部署功能，所以只需要等待控制台重启信息完成之后再刷新网页就可以看到正确效果了： 2.集成 MyBatis 第一步：修改 pom.xml 增加对 MySql和 MyBatis 的支持 12345678910111213&lt;!-- mybatis --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt;&lt;/dependency&gt;&lt;!-- mysql --&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.21&lt;/version&gt;&lt;/dependency&gt; 第二步：新增数据库链接参数 我这里使用我之前 ssm 整合时的 user 表: yml文件&gt; 1234567891011121314151617181920serber: port: 8080 servlet: context-path: /liststudent: name: carson age: 18spring: mvc: view: prefix: /WEB-INF/views/ suffix: .jsp datasource: url: jdbc:mysql:///ssm username: root password: root driver-class-name: com.mysql.jdbc.Driver jpa: hibernate: ddl-auto: update url中的localhost ,可以用/// 代替 hibernate下面有几个参数: validate 加载 Hibernate 时，验证创建数据库表结构 create 每次加载 Hibernate ，重新创建数据库表结构，这就是导致数据库表数据丢失的原因。 create-drop 加载 Hibernate 时创建，退出是删除表结构 update 加载 Hibernate 自动更新数据库结构 如果你想保留表结构的数据，使用 update 即可。 第三步：创建 Student 实体类和 StudentMapper 映射类 在【com.carson.springboot】下的【domain】包，然后在其下创建一个 User 类： 123456789101112131415161718192021package com.carson.springboot.domain;import lombok.*;import java.math.BigDecimal;@Getter@Setter@AllArgsConstructor@NoArgsConstructor@ToStringpublic class User { private Long id; private String username; private String password; private int age; private BigDecimal salary; /*各种 setter getter tostring 全参,无参构造*/} 在【com.carson.springboot】下创建mapper包，然后在其下创建一个 UserMapper映射类： 1234567891011121314package com.carson.springboot.mapper;import com.carson.springboot.domain.User;import org.apache.ibatis.annotations.Mapper;import org.apache.ibatis.annotations.Select;import java.util.List;@Mapperpublic interface UserMapper { //sql语句直接写在注解上 @Select(\"select * from user\") List&lt;User&gt; list();} 第四步：编写 StudentController 在【com.carson.springboot】下新建一个【controller】包，然后在其下创建一个UserController ： 1234567891011121314151617181920212223package com.carson.springboot.controller;import com.carson.springboot.domain.User;import com.carson.springboot.mapper.UserMapper;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;import java.util.List;@Controllerpublic class UserController { @Autowired private UserMapper userMapper; @RequestMapping(\"list\") public String list(Model model){ List&lt;User&gt; users = userMapper.list(); model.addAttribute(\"users\",users); return \"list\"; }} 第五步：编写 listStudent.jsp 文件 我们简化一下 JSP 的文件，仅显示两个字段的数据： 123456789101112131415161718192021222324252627282930&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;%@ taglib uri=\"http://java.sun.com/jsp/jstl/core\" prefix=\"c\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;list&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;table align='center' border='1' cellspacing='0'&gt; &lt;tr&gt; &lt;td&gt;id&lt;/td&gt; &lt;td&gt;name&lt;/td&gt; &lt;td&gt;age&lt;/td&gt; &lt;td&gt;salary&lt;/td&gt; &lt;td&gt;password&lt;/td&gt; &lt;/tr&gt; &lt;c:forEach items=\"${users}\" var=\"s\" varStatus=\"st\"&gt; &lt;tr&gt; &lt;td&gt;${s.id}&lt;/td&gt; &lt;td&gt;${s.username}&lt;/td&gt; &lt;td&gt;${s.age}&lt;/td&gt; &lt;td&gt;${s.salary}&lt;/td&gt; &lt;td&gt;${s.password}&lt;/td&gt; &lt;/tr&gt; &lt;/c:forEach&gt;&lt;/table&gt;&lt;/body&gt;&lt;/html&gt; 第六步：重启服务器运行 因为往 pom.xml 中新增加了依赖的包，所以自动重启服务器没有作用，我们需要手动重启一次， 然后在地址输入：localhost:8080/list查看效果： 总结以下我遇到的错误: 这里说我的数据源有问题👇 我的yml配置文件之前是这样的: 12345678910111213spring: mvc: view: prefix: /WEB-INF/views/ suffix: .jsp datasource: url: jdbc:mysql:///ssm username: root password: root driver-class-name: com.mysql.jdbc.Driverjpa: 这里 hibernate: ddl-auto: update jpa这个字段单独出来了,它应该是跟 datasource和mvc字段 同级, 而不是跟spring同级, yml的空格是严格的 改正: 12345678910111213spring: mvc: view: prefix: /WEB-INF/views/ suffix: .jsp datasource: url: jdbc:mysql:///ssm username: root password: root driver-class-name: com.mysql.jdbc.Driver jpa: hibernate: ddl-auto: update 这次的spring boot学习过程,还算顺利,终究要感谢网路上这么多优秀的前辈,他们写的博客非常优秀,以至于给我的学习过程给予很大的帮助 终于知道了spring boot的强大,相对我的上一篇博客写的ssm框架整合,少了很多配置文件,看起来很清爽","link":"/2019/05/25/springboot/"},{"title":"SSM框架整合回顾(一)","text":"Spring + springMVC + MyBatis 实现 登录+增删改查+分页查询 开发环境:win10 , jdk1.8 , idea 2019.1.1 , tomcat 8.5.38 , maven , pageHelp 以上工具一定要有 pom.xml 文件:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140&lt;properties&gt; &lt;project.srping.version&gt;5.0.0.RELEASE&lt;/project.srping.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--Spring的依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;${project.srping.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;${project.srping.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;${project.srping.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;${project.srping.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;${project.srping.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;${project.srping.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 德鲁伊连接池 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.9&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.38&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.5&lt;/version&gt; &lt;/dependency&gt; &lt;!--mybatis和Spring的整合--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;!--日志--&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.20&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.8.13&lt;/version&gt; &lt;/dependency&gt; &lt;!--PageHelper分页插件--&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;5.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt; Mybatis于Spring的整合 applicationContext.xml:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd\"&gt; &lt;!--引入属性配置文件--&gt; &lt;context:property-placeholder location=\"classpath:db.properties\" system-properties-mode=\"NEVER\"/&gt; &lt;!--德鲁伊连接池--&gt; &lt;bean id=\"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"${driverClassName}\"/&gt; &lt;property name=\"url\" value=\"${url}\"/&gt; &lt;property name=\"username\" value=\"${username}\"/&gt; &lt;property name=\"password\" value=\"${password}\"/&gt; &lt;/bean&gt; &lt;!--sqlsessionfactory对象--&gt; &lt;bean id=\"sqlSessionFactoryBean\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;!--配置连接池--&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;!--关联mybatis主配置文件--&gt; &lt;property name=\"configLocation\" value=\"classpath:mybatis.xml\"/&gt; &lt;!--配置别名--&gt; &lt;property name=\"typeAliasesPackage\" value=\"com.ujiuye.domain\"/&gt; &lt;!--关联mapper映射文件--&gt; &lt;property name=\"mapperLocations\" value=\"classpath:com/ujiuye/mapper/*.xml\"/&gt; &lt;/bean&gt; &lt;!--配置mapper接口的扫描器--&gt; &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;!--从哪个包扫描mapper接口--&gt; &lt;property name=\"basePackage\" value=\"com.ujiuye.mapper\"/&gt; &lt;/bean&gt; &lt;!-- ioc 注解扫描器--&gt; &lt;context:component-scan base-package=\"com.ujiuye\"/&gt; &lt;!--配置事务管理器--&gt; &lt;tx:annotation-driven /&gt; &lt;bean id=\"txManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;/bean&gt; &lt;!--配置事务--&gt; &lt;aop:config&gt; &lt;!--配置where--&gt; &lt;aop:pointcut id=\"txPointcut\" expression=\"execution(* com.ujiuye.service..*.*(..))\"/&gt; &lt;!--切面--&gt; &lt;aop:advisor advice-ref=\"txAdvice\" pointcut-ref=\"txPointcut\"/&gt; &lt;/aop:config&gt; &lt;!--增强器--&gt; &lt;tx:advice id=\"txAdvice\" transaction-manager=\"txManager\"&gt; &lt;tx:attributes&gt; &lt;tx:method name=\"list*\" read-only=\"true\"/&gt; &lt;tx:method name=\"get*\" read-only=\"true\"/&gt; &lt;tx:method name=\"select*\" read-only=\"true\"/&gt; &lt;tx:method name=\"find*\" read-only=\"true\"/&gt; &lt;tx:method name=\"query*\" read-only=\"true\"/&gt; &lt;tx:method name=\"*\"/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt;&lt;/beans&gt; applicationCoutext.xml文件总结: 事务中我给查询的方法加上了 read-only=”true”,只读状态可以提高性能 没有配置read-only的method默认非只读 SpringMVC.xml的配置:1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd\"&gt; &lt;!--引入后台的spring的配置文件--&gt; &lt;import resource=\"classpath:applicationContext.xml\"/&gt; &lt;!--视图解析器--&gt; &lt;bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"&gt; &lt;!--配置前缀--&gt; &lt;property name=\"prefix\" value=\"/WEB-INF/views/\"/&gt; &lt;!--配置后缀--&gt; &lt;property name=\"suffix\" value=\".jsp\"/&gt; &lt;/bean&gt; &lt;!--SpringMVC注解解析器--&gt; &lt;mvc:annotation-driven/&gt; &lt;!--拦截器--&gt; &lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;!--拦截的路径/*一级路径 /**所有路径--&gt; &lt;mvc:mapping path=\"/**\"/&gt; &lt;!--排除登录页面--&gt; &lt;mvc:exclude-mapping path=\"/login.do\"/&gt; &lt;bean class=\"com.ujiuye.interceptor.LoginInterceptor\"&gt;&lt;/bean&gt; &lt;/mvc:interceptor&gt; &lt;/mvc:interceptors&gt;&lt;/beans&gt; 拦截器: 必须让用户登录才能进入到更深层的jsp,然后 /** 表示拦截所有,但是我们要排除login这个登录页面 等一下要配置一下拦截的类 MyBatis.xml:123456789101112131415&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;!-- pagehelp拦截器配置--&gt; &lt;plugins&gt; &lt;!-- com.github.pagehelper为PageHelper类所在包名 --&gt; &lt;plugin interceptor=\"com.github.pagehelper.PageInterceptor\"&gt; &lt;!-- 使用下面的方式配置参数，后面会有所有的参数介绍 --&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/configuration&gt; plugins在配置文件中的位置必须符合要求，否则会报错，顺序如下: properties?, settings?, typeAliases?, typeHandlers?, objectFactory?,objectWrapperFactory?, plugins?, environments?, databaseIdProvider?, mappers? web.xml:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd\" version=\"3.1\" metadata-complete=\"true\"&gt; &lt;!--前端控制器--&gt; &lt;servlet&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!--spring的配置文件--&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:SpringMVC.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;!--tomcat启动时初始化--&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;!--*.do意思是访问页面的时候后缀要加上 .do--&gt; &lt;url-pattern&gt;*.do&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!--请求编码过滤器--&gt; &lt;filter&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceRequestEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceResponseEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!--设置欢迎页,意思是登录页,以前默认index.jsp,现在是login.jsp--&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;login.jsp&lt;/welcome-file&gt; &lt;/welcome-file-list&gt;&lt;/web-app&gt; controller:LoginController&gt;1234567891011121314151617181920212223242526272829303132333435package com.ujiuye.controller;import com.ujiuye.domain.User;import com.ujiuye.service.IUserService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;import javax.servlet.http.HttpSession;@Controllerpublic class LoginController { @Autowired private IUserService userService; //登录方法 @RequestMapping(\"login\") public String login(String username, String password, HttpSession session, Model model){ User user = userService.selectLogin(username, password); if (user!=null){ //user对象放入session作用域 session.setAttribute(\"USER_IN_SESSION\",user); //跳转到用户列表页面 return \"redirect:/user/query.do\"; }else { //跳转到登录页面,提示用户名或密码错误 model.addAttribute(\"msg\",\"用户名或者密码错误\"); return \"forward:/login.jsp\"; } }} 如果登录密码是正确的,那么这里的 user 是不为 null的,他就会跳转到用户列表页面, 如果密码错误,还会跳的登录页, UserController&gt;1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package com.ujiuye.controller;import com.github.pagehelper.PageInfo;import com.ujiuye.domain.User;import com.ujiuye.qo.QueryObject;import com.ujiuye.result.PageResult;import com.ujiuye.service.IUserService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.ModelAttribute;import org.springframework.web.bind.annotation.RequestMapping;import java.util.List;@Controller@RequestMapping(\"user\")public class UserController { @Autowired private IUserService service; //多条件查询 + 分页 @RequestMapping(\"query\") public String query(@ModelAttribute(\"qo\") QueryObject qo,Model model){// PageResult result = service.query2(qo);// model.addAttribute(\"result\",result); PageInfo pageInfo = service.query3(qo); model.addAttribute(\"pageInfo\",pageInfo); return \"user/list\"; } //查询列表的方法 @RequestMapping(\"list\") public String list(Model model){ List&lt;User&gt; list = service.list(); model.addAttribute(\"list\",list); return \"user/list\"; } //跳转到用户编辑页面 @RequestMapping(\"edit\") public String edit(Long id,Model model){ if (id!=null){ User user = service.get(id); //往前台传数据 model.addAttribute(\"user\",user); } return \"user/edit\"; } //保存 @RequestMapping(\"saveOrUpdate\") public String saveOrUpdate(User user){ //判断user对象中的id的值,从而区分是在做新增还是修改 if (user.getId()==null){ service.save(user); }else { service.update(user); } return \"redirect:/user/list.do\"; } //删除 @RequestMapping(\"delete\") public String delete(Long id){ //删除操作 service.delete(id); return \"redirect:/user/list.do\"; }} domain 实体类:123456789101112131415161718192021package com.ujiuye.domain;import lombok.*;import java.math.BigDecimal;@Setter@Getter@AllArgsConstructor@NoArgsConstructor@ToStringpublic class User { private Long id; private String username; private String password; private Integer age; private BigDecimal salary;} interceptor登录检查&gt;LoginInterceptor:123456789101112131415161718192021222324package com.ujiuye.interceptor;import org.springframework.web.servlet.HandlerInterceptor;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import javax.servlet.http.HttpSession;public class LoginInterceptor implements HandlerInterceptor { //登录检查,实现接口里的这个方法 public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { //判断session中是否有\"USER_IN_SESSION\"的key HttpSession session = request.getSession(); Object user = session.getAttribute(\"USER_IN_SESSION\"); if (user == null){ //跳转到登录页面 response.sendRedirect(\"login.jsp\"); return false; } return true; }} 刚刚在LoginController定义了if else,如果登录 !=null 那么session里会有 USER_IN_SESSION 这个key,return ture 如果为null 就会跳转到登录页面; 实现HandlerInterceptor接口: HandlerInterceptor 接口中定义了三个方法，我们就是通过这三个方法来对用户的请求进行拦截处理的。 （1 ）preHandle (HttpServletRequest request, HttpServletResponse response, Object handle) 方法， 顾名思义，该方法将在请求处理之前进行调用。SpringMVC 中的Interceptor 是链式的调用的，在一个应用中或者说是在一个请求中可以同时存在多个Interceptor 。每个Interceptor 的调用会依据它的声明顺序依次执行，而且最先执行的都是Interceptor 中的preHandle 方法，所以可以在这个方法中进行一些前置初始化操作或者是对当前请求的一个预处理，也可以在这个方法中进行一些判断来决定请求是否要继续进行下去。该方法的返回值是布尔值Boolean 类型的，当它返回为false 时，表示请求结束，后续的Interceptor 和Controller 都不会再执行；当返回值为true 时就会继续调用下一个Interceptor 的preHandle 方法，如果已经是最后一个Interceptor 的时候就会是调用当前请求的Controller 方法。 （2 ）postHandle (HttpServletRequest request, HttpServletResponse response, Object handle, ModelAndView modelAndView) 方法， 由preHandle 方法的解释我们知道这个方法包括后面要说到的afterCompletion 方法都只能是在当前所属的Interceptor 的preHandle 方法的返回值为true 时才能被调用。postHandle 方法，顾名思义就是在当前请求进行处理之后，也就是Controller 方法调用之后执行，但是它会在DispatcherServlet 进行视图返回渲染之前被调用，所以我们可以在这个方法中对Controller 处理之后的ModelAndView 对象进行操作。postHandle 方法被调用的方向跟preHandle 是相反的，也就是说先声明的Interceptor 的postHandle 方法反而会后执行，这和Struts2 里面的Interceptor 的执行过程有点类型。Struts2 里面的Interceptor 的执行过程也是链式的，只是在Struts2 里面需要手动调用ActionInvocation 的invoke 方法来触发对下一个Interceptor 或者是Action 的调用，然后每一个Interceptor 中在invoke 方法调用之前的内容都是按照声明顺序执行的，而invoke 方法之后的内容就是反向的。 （3 ）afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handle, Exception ex) 方法， 该方法也是需要当前对应的Interceptor 的preHandle 方法的返回值为true时才会执行。顾名思义，该方法将在整个请求结束之后，也就是在DispatcherServlet 渲染了对应的视图之后执行。这个方法的主要作用是用于进行资源清理工作的。 mapper(dao):UserMapper.java&gt;12345678910111213141516171819202122232425262728293031package com.ujiuye.mapper;import com.ujiuye.domain.User;import com.ujiuye.qo.BaseQueryObject;import com.ujiuye.qo.QueryObject;import org.apache.ibatis.annotations.Param;import java.util.List;public interface UserMapper { //增删改查 void save(User user); void update(User user); void delete(Long id); //查单独一个 User get(Long id); //查询所有 List&lt;User&gt; list(); //登录查询 User selectLogin(@Param(\"username\") String username, @Param(\"password\") String password); List&lt;User&gt; query(QueryObject qo); //查询结果集中的数据 List&lt;User&gt; queryForList(BaseQueryObject qo); //查询总条数 int queryForCount(QueryObject qo);} UserMapper.xml&gt;1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" &gt;&lt;mapper namespace=\"com.ujiuye.mapper.UserMapper\"&gt; &lt;insert id=\"save\" useGeneratedKeys=\"true\" keyProperty=\"id\" keyColumn=\"id\"&gt; insert into user(username,password,age,salary) values (#{username},#{password},#{age},#{salary}) &lt;/insert&gt; &lt;update id=\"update\"&gt; update user set username=#{username},password=#{password},age=#{age}, salary=#{salary} where id =#{id} &lt;/update&gt; &lt;delete id=\"delete\"&gt; delete from user where id=#{id} &lt;/delete&gt; &lt;select id=\"get\" resultType=\"com.ujiuye.domain.User\"&gt; select * from user where id=#{id} &lt;/select&gt; &lt;select id=\"list\" resultType=\"User\"&gt; select * from user &lt;/select&gt; &lt;select id=\"selectLogin\" resultType=\"com.ujiuye.domain.User\"&gt; select id,username,password,age,salary from user where username=#{username} and password=#{password} &lt;/select&gt; &lt;select id=\"query\" resultType=\"com.ujiuye.domain.User\"&gt; select id,username,password,age,salary from user &lt;where&gt; &lt;if test=\"username!=null and username!='' \"&gt; and username like concat('%',#{username},'%') &lt;/if&gt; &lt;if test=\"salary!=null\"&gt; and salary = #{salary} &lt;/if&gt; &lt;/where&gt; &lt;/select&gt; &lt;select id=\"queryForCount\" resultType=\"int\"&gt; select count(*) from user &lt;where&gt; &lt;if test=\"username!=null and username!='' \"&gt; and username like concat('%',#{username},'%') &lt;/if&gt; &lt;if test=\"salary!=null\"&gt; and salary = #{salary} &lt;/if&gt; &lt;/where&gt; &lt;/select&gt; &lt;select id=\"queryForList\" resultType=\"User\"&gt; select * from user &lt;where&gt; &lt;if test=\"username!=null and username!='' \"&gt; and username like concat('%',#{username},'%') &lt;/if&gt; &lt;if test=\"salary!=null\"&gt; and salary = #{salary} &lt;/if&gt; &lt;/where&gt; limit #{start},#{pageSize} &lt;/select&gt;&lt;/mapper&gt; mapper映射文件可以跟java文件放在同一个目录下,因为pom里配置了: 12345678910&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt; qo(分页):BaseQueryObject&gt;1234567891011121314151617package com.ujiuye.qo;import lombok.Getter;import lombok.Setter;@Setter@Getterpublic class BaseQueryObject { private Integer currentPage = 1; private Integer pageSize = 3; public Integer getStart(){ return (this.currentPage-1)*this.pageSize; }} DepartmentQueryObject&gt;123456package com.ujiuye.qo;public class DepartemntQueryObject { private String deptName;} QueryObject&gt;12345678910111213package com.ujiuye.qo;import lombok.Getter;import lombok.Setter;import java.math.BigDecimal;@Getter@Setterpublic class QueryObject extends BaseQueryObject { private String username; private BigDecimal salary;} result:123456789101112131415161718192021222324252627282930313233343536package com.ujiuye.result;import lombok.Getter;import lombok.Setter;import java.util.Collections;import java.util.List;@Setter@Getterpublic class PageResult { //结果集 数据 private List&lt;?&gt; data; //总的条数 private Integer totalCount; //计算出来 //上一页 private Integer prevPage; //下一页 private Integer nextPage; //尾页 private Integer endPage; //计算方法 public PageResult(List&lt;?&gt; data, Integer totalCount, Integer currentPage, Integer pageSize) { this.data = data; this.totalCount = totalCount; this.prevPage= currentPage-1&gt;1?currentPage-1:1; this.endPage=totalCount%pageSize == 0?totalCount/pageSize:totalCount/pageSize+1; this.nextPage = currentPage+1&lt;endPage?currentPage+1:endPage; } public static PageResult EMPTY_LIST = new PageResult(Collections.emptyList(),0,1,1);} service 层:接口&gt;12345678910111213141516171819202122232425262728293031package com.ujiuye.service;import com.alibaba.druid.sql.PagerUtils;import com.github.pagehelper.PageInfo;import com.ujiuye.domain.User;import com.ujiuye.qo.BaseQueryObject;import com.ujiuye.qo.QueryObject;import com.ujiuye.result.PageResult;import java.util.List;public interface IUserService { //增 void save(User user); //改 void update(User user); //删 void delete(Long id); //查单个 User get(Long id); //查询所有 List&lt;User&gt; list(); //登录方法 User selectLogin(String username,String password); List&lt;User&gt; query(QueryObject qo); PageResult query2(QueryObject qo); PageInfo query3(QueryObject qo);} UserServiceImpl 实现类&gt;12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576package com.ujiuye.service.impl;import com.github.pagehelper.PageHelper;import com.github.pagehelper.PageInfo;import com.ujiuye.domain.User;import com.ujiuye.mapper.UserMapper;import com.ujiuye.qo.BaseQueryObject;import com.ujiuye.qo.QueryObject;import com.ujiuye.result.PageResult;import com.ujiuye.service.IUserService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import java.util.Collections;import java.util.List;@Servicepublic class UserServiceImpl implements IUserService { private static PageResult EMPTY_LIST = new PageResult(Collections.emptyList(), 0, 1, 1); @Autowired private UserMapper userMapper; public void save(User user) { userMapper.save(user); } public void update(User user) { userMapper.update(user); } public void delete(Long id) { userMapper.delete(id); } public User get(Long id) { return userMapper.get(id); } public List&lt;User&gt; list() { return userMapper.list(); } public User selectLogin(String username, String password) { return userMapper.selectLogin(username, password); } public List&lt;User&gt; query(QueryObject qo) { return userMapper.query(qo); } public PageResult query2(QueryObject qo) { //查询总的条数qo int totlaCount = userMapper.queryForCount(qo); if(totlaCount == 0){ //返回空结果集 return PageResult.EMPTY_LIST; } //查询结果集数据 List&lt;User&gt; data = userMapper.queryForList(qo); return new PageResult(data,totlaCount,qo.getCurrentPage(),qo.getPageSize()); } public PageInfo query3(QueryObject qo) { PageHelper.startPage(qo.getCurrentPage(),qo.getPageSize()); List&lt;User&gt; list = userMapper.query(qo); return new PageInfo(list); }} Test:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182package com.ujiuye.test;import com.github.pagehelper.PageHelper;import com.github.pagehelper.PageInfo;import com.ujiuye.domain.User;import com.ujiuye.mapper.UserMapper;import com.ujiuye.service.IUserService;import org.apache.ibatis.session.SqlSessionFactory;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;import java.math.BigDecimal;import java.util.List;@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(\"classpath:applicationContext.xml\")public class App { @Autowired private SqlSessionFactory sqlSessionFactory; @Autowired private UserMapper userMapper; @Autowired private IUserService service; private User user = null; @Test public void testSave(){ user = new User(null,\"特朗普\",\"123\",30,new BigDecimal(\"1.00\")); service.save(user); } @Test public void testUpdate(){ user = new User(2L,\"奥巴马\",\"123\",12,new BigDecimal(\"2000.00\")); service.update(user); } @Test public void testDelete(){ service.delete(9L); } @Test public void testGet(){ System.out.println(service.get(7L)); } @Test public void testList(){ System.out.println(service.list()); } @Test public void testLogin(){ user = service.selectLogin(\"扎克伯格\",\"456\"); System.out.println(user); } @Test public void testPageHelper(){ PageHelper.startPage(2,3); List&lt;User&gt; list = userMapper.list(); PageInfo pageInfo = new PageInfo(list); System.out.println(pageInfo.getList().get(0)); System.out.println(pageInfo.getList().get(1)); System.out.println(pageInfo.getList().get(2)); System.out.println(\"上一页:\"+pageInfo.getPrePage()); System.out.println(\"下一页:\"+pageInfo.getNextPage()); System.out.println(\"总页数:\"+pageInfo.getSize()); System.out.println(\"首页:\"+pageInfo.getNavigateFirstPage()); System.out.println(\"尾页:\"+pageInfo.getNavigateLastPage()); }} 前台:我的前台很丑不过还是放一下吧&gt; edit.jsp 用户编辑页面&gt;1234567891011121314151617&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;用户编辑页面&lt;/h1&gt;&lt;form action=\"/user/saveOrUpdate.do\" method=\"post\"&gt; &lt;input type=\"hidden\" value=\"${user.id}\" name=\"id\"&gt; 姓名:&lt;input type=\"text\" name=\"username\" value=\"${user.username}\"&gt;&lt;br&gt; 密码:&lt;input type=\"text\" name=\"password\" value=\"${user.password}\"&gt;&lt;br&gt; 年龄:&lt;input type=\"text\" name=\"age\" value=\"${user.age}\"&gt;&lt;br&gt; 月薪:&lt;input type=\"text\" name=\"salary\" value=\"${user.salary}\"&gt;&lt;br&gt; &lt;input type=\"submit\" value=\"ok!~\"&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; list.jsp 主页面&gt;123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;%@taglib prefix=\"c\" uri=\"http://java.sun.com/jsp/jstl/core\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script&gt; function goPage(page) { //修改currentPage文本框的值 if(page != undefined){ document.getElementById(\"currentPage\").value = page; } //提交分页查询的表单 var pageForm = document.getElementById(\"pageForm\"); pageForm.submit(); } &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;form id=\"pageForm\" action=\"/user/query.do\" method=\"post\"&gt; &lt;h1&gt;用户列表&lt;/h1&gt; &lt;table&gt; &lt;tr&gt; 姓名:&lt;input type=\"text\" name=\"username\" value=\"${qo.username}\"&gt; 工资:&lt;input type=\"text\" name=\"salary\" value=\"${qo.salary}\"&gt; &lt;input type=\"submit\" value=\"查询\"&gt; &lt;/tr&gt; &lt;/table&gt; &lt;a href=\"/user/edit.do\"&gt;新增&lt;/a&gt; &lt;br/&gt; &lt;table border=\"1\" width=\"60%\"&gt; &lt;tr&gt; &lt;th&gt;编号&lt;/th&gt; &lt;th&gt;姓名&lt;/th&gt; &lt;th&gt;年龄&lt;/th&gt; &lt;th&gt;工资&lt;/th&gt; &lt;th&gt;操作&lt;/th&gt; &lt;/tr&gt; &lt;c:forEach items=\"${pageInfo.list}\" var=\"user\"&gt; &lt;tr&gt; &lt;td&gt;${user.id}&lt;/td&gt; &lt;td&gt;${user.username}&lt;/td&gt; &lt;td&gt;${user.age}&lt;/td&gt; &lt;td&gt;${user.salary}&lt;/td&gt; &lt;td&gt; &lt;a href=\"/user/edit.do?id=${user.id}\"&gt;修改&lt;/a&gt; &lt;a href=\"/user/delete.do?id=${user.id}\"&gt;删除&lt;/a&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/c:forEach&gt; &lt;tr&gt; &lt;td colspan=\"5\"&gt; &lt;a href=\"javascript:void(0);\" onclick=\"goPage(1)\"&gt;首页&lt;/a&gt; &lt;a href=\"javascript:void(0);\" onclick=\"goPage(${pageInfo.prePage})\"&gt;上一页&lt;/a&gt; &lt;a href=\"javascript:void(0);\" onclick=\"goPage(${pageInfo.nextPage})\"&gt;下一页&lt;/a&gt; &lt;a href=\"javascript:void(0);\" onclick=\"goPage(${pageInfo.navigateLastPage})\"&gt;尾页&lt;/a&gt; 每个显示 &lt;select name=\"pageSize\" onchange=\"goPage(1)\"&gt; &lt;option value=\"3\" ${qo.pageSize == 3?\"selected\":\"\"}&gt;3&lt;/option&gt; &lt;option value=\"5\" ${qo.pageSize == 5?\"selected\":\"\"}&gt;5&lt;/option&gt; &lt;option value=\"10\" ${qo.pageSize == 10?\"selected\":\"\"}&gt;10&lt;/option&gt; &lt;/select&gt; 条 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;input type=\"text\" id=\"currentPage\" name=\"currentPage\" style=\"width: 50px\" value=\"${qo.currentPage}\"&gt; &lt;button onclick=\"goPage()\"&gt;跳转&lt;/button&gt; 总共${pageInfo.total}条/共${pageInfo.navigateLastPage}页 &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; login.jsp&gt;12345678910111213141516&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;login&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;登录&lt;/h1&gt;&lt;%--如果获取到msg说明密码错误--%&gt;&lt;font color=\"red\"&gt;${msg}&lt;/font&gt; &lt;form action=\"/login.do\" method=\"post\"&gt; 账号:&lt;input type=\"text\" name=\"username\"&gt; &lt;br&gt; 密码:&lt;input type=\"text\" name=\"password\"&gt;&lt;br&gt; &lt;input type=\"submit\" value=\"登录\"&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt;","link":"/2019/05/24/ssm/"}],"tags":[{"name":"我的博客搭建过程","slug":"我的博客搭建过程","link":"/tags/我的博客搭建过程/"},{"name":"Hbase","slug":"Hbase","link":"/tags/Hbase/"},{"name":"Spring Boot","slug":"Spring-Boot","link":"/tags/Spring-Boot/"},{"name":"数据结构","slug":"数据结构","link":"/tags/数据结构/"},{"name":"Hadoop","slug":"Hadoop","link":"/tags/Hadoop/"},{"name":"Scala","slug":"Scala","link":"/tags/Scala/"},{"name":"闲聊","slug":"闲聊","link":"/tags/闲聊/"},{"name":"算法","slug":"算法","link":"/tags/算法/"},{"name":"SSM框架","slug":"SSM框架","link":"/tags/SSM框架/"}],"categories":[{"name":"博客搭建","slug":"博客搭建","link":"/categories/博客搭建/"},{"name":"Hadoop生态圈","slug":"Hadoop生态圈","link":"/categories/Hadoop生态圈/"},{"name":"Spring Boot","slug":"Spring-Boot","link":"/categories/Spring-Boot/"},{"name":"《大话数据结构》","slug":"《大话数据结构》","link":"/categories/《大话数据结构》/"},{"name":"Scala","slug":"Scala","link":"/categories/Scala/"},{"name":"浅谈ios/Android(非技术)","slug":"浅谈ios-Android-非技术","link":"/categories/浅谈ios-Android-非技术/"},{"name":"Spring-SpringMVC-MyBatis","slug":"Spring-SpringMVC-MyBatis","link":"/categories/Spring-SpringMVC-MyBatis/"}]}