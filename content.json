{"pages":[{"title":"404","text":"&lt;!DOCTYPE html&gt; 404 &lt;!DOCTYPE html&gt; 404","link":"/404/index.html"},{"title":"开发者以技术为中心","text":"如果你想联系我微信: 17663083790 邮箱: 17663083790@163.com QQ: 3230452986","link":"/about/index.html"},{"title":"分类","text":"","link":"/categories/index.html"}],"posts":[{"title":"Hexo+GitHub搭建个人博客  for Windows","text":"hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 绑定一下github,就可以让别人通过你自定义的域名来访问你的博客, 我使用的正是Hexo的框架,我的博客地址 : https://aaatao66.github.io/ 1.安装 node.jsnode.js 官方网站: https://nodejs.org/zh-cn/ node是我们搭建博客必须的一个插件,下载长期支持版就ok了,安装很简单,与其他软件没区别,一直点下一步就好了 安装完成后除了node.js本身,还有npm管理器 1cmd输入 npm -v 查看一下版本,我这里用的6.4.1版本 2.安装 gitgit 官方网站 git官网：https://git-scm.com/ 这个我就不发图了,你如果不会用的话,可以去这个廖雪峰老师的网站: https://www.liaoxuefeng.com/wiki/896043488029600&gt; 廖雪峰老师讲的很详细,百万级别的阅读量不是闹着玩的 现在你的输入 node -v npm -v git –version看一下版本号说明成功了 12345678C:\\Users\\My&gt;node -vv10.15.3C:\\Users\\My&gt;npm -v6.4.1C:\\Users\\My&gt;git --versiongit version 2.21.0.windows.1 3.github我们需要一个github的账号,如果你没有,那就去注册个 鼠标右键&gt;打开Git Bash(接下来的命令基于这里面运行) 这里👇输入你自己的用户名和邮箱(不要输错) 12git config --global user.name \"GitHub 用户名\"git config --global user.email \"GitHub 邮箱\" 👇创建一个SSH密匙 1ssh-keygen -t rsa -C \"GitHub 邮箱\" 目录是自动生成的,可以看一下我的目录,id_rsa.pub里面就是你的密匙,复制它 进入你的github选择&gt;setting 4.创建 GitHub Pages (仓库)在你的github主页, ​ 点击右上角 + 号 &gt; New repository ​ Repository name 中输入 用户名.github.io ​ 勾选 “Initialize this repository with a README” ​ Description 选填 点Create repository后你的博客地址就生成了 地址为: https://用户名.github.io 5.修改一下hexo目录下的config.yml文件 repo输入你自己的地址,地址就是你刚才建的pages里 6.本地安装 Hexo 博客程序新建一个文件夹,专门存放hexo以及你的博客文章的,参考我的这个也行 重点 : 如果你想对hexo进行操作,无论是Git Bash 还是 CMD ,都必须再这个目录下进行 安装Hexo命令👇 1npm install -g hexo-cli 这应该是从国外进行下载过来的,有点慢,你可以等待下载过程,不然你也知道该怎么做 初始化and安装组件 12hexo init 初始化npm install 安装组件 完成后输入下面命令👇 hexo g 就是生成静态页面 hexo s 就是 server的意思 启动你的本地服务器(类似tomcat启动) 12hexo g hexo s 启动后访问:http://localhost:4000,希望你可以访问成功,没成功也没关系,hexo这个框架非常的火,以至于网上有关于它的各种解决方案,如果你遇到了什么问题,可以通过搜索引擎解决你的问题 123hexo clean 清理一下缓存,如果你修改的主题或上传文章什么的,刷新网页不管用,那你可以clean一下hexo g 生成静态页面hexo d 上传github 执行好上面的命令你就可以访问真正的域名: 用户名.github.io 例如我的 : https://aaatao66.github.io/ 什么?你说自带的主题太丑了?好吧! 打开github &gt; 搜索 hexo theme &gt;下载一个自己喜欢的风格&gt;把下载好的文件夹放在你刚刚建立的hexo文件夹里的 ..:.….\\Hexo\\themes文件夹里 然后回到hexo文件夹 用文本方式打开 _config.yml &gt;找到 theme : XXX &gt;xxx就是你刚刚下载的主题的文件夹名字 再次 hexo clean 一下 然后 hexo s进入预览一下,有可能会很慢,稍等再shift+f5刷新一下","link":"/2019/05/20/Hexo+GitHub-for-Windows/"},{"title":"你好","text":"我的朋友你觉得凭我的资质可不可以成为一个一线男模?","link":"/2019/05/18/my-first-blogs/"},{"title":"Spring Boot--开发Web应用-Thymeleaf(二)","text":"以下文章大部分文字转自: 程序员DD 我会根据程序员DD的文章进行学习 如果你没有使用过Spring boot , 我的上一篇博客可能会更适合你 开发环境win10 idea 2019.1.1 jdk1.8 一双手 静态资源访问在我们开发Web应用的时候，需要引用大量的js、css、图片等静态资源。 默认配置Spring Boot默认提供静态资源目录位置需置于classpath下，目录名需符合如下规则： /static /public /resources /META-INF/resources 举例：我们可以在src/main/resources/目录下创建static，在该位置放置一个图片文件。启动程序后，尝试访问http://localhost:8080/D.jpg。如能显示图片，配置成功。 渲染Web页面在之前的示例中，我们都是通过@RestController来处理请求，所以返回的内容为json对象。那么如果需要渲染html页面的时候，要如何实现呢？ 模板引擎在动态HTML实现上Spring Boot依然可以完美胜任，并且提供了多种模板引擎的默认配置支持，所以在推荐的模板引擎下，我们可以很快的上手开发动态网站。 Spring Boot提供了默认配置的模板引擎主要有以下几种： Thymeleaf FreeMarker Velocity Groovy Mustache Spring Boot建议使用这些模板引擎，避免使用JSP，若一定要使用JSP将无法实现Spring Boot的多种特性(上一篇博客我加了一些东西,使spring boot支持了jsp) 当你使用上述模板引擎中的任何一个，它们默认的模板配置路径为：src/main/resources/templates。当然也可以修改这个路径，具体如何修改，可在后续各模板引擎的配置属性中查询并修改。 ThymeleafThymeleaf是一个XML/XHTML/HTML5模板引擎，可用于Web与非Web环境中的应用开发。它是一个开源的Java库，基于Apache License 2.0许可，由Daniel Fernández创建，该作者还是Java加密库Jasypt的作者。 Thymeleaf提供了一个用于整合Spring MVC的可选模块，在应用开发中，你可以使用Thymeleaf来完全代替JSP或其他模板引擎，如Velocity、FreeMarker等。Thymeleaf的主要目标在于提供一种可被浏览器正确显示的、格式良好的模板创建方式，因此也可以用作静态建模。你可以使用它创建经过验证的XML与HTML模板。相对于编写逻辑或代码，开发者只需将标签属性添加到模板中即可。接下来，这些标签属性就会在DOM（文档对象模型）上执行预先制定好的逻辑。 示例模板： 1234567891011121314&lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th th:text=\"#{msgs.headers.name}\"&gt;Name&lt;/td&gt; &lt;th th:text=\"#{msgs.headers.price}\"&gt;Price&lt;/td&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr th:each=\"prod : ${allProducts}\"&gt; &lt;td th:text=\"${prod.name}\"&gt;Oranges&lt;/td&gt; &lt;td th:text=\"${#numbers.formatDecimal(prod.price,1,2)}\"&gt;0.99&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; 可以看到Thymeleaf主要以属性的方式加入到html标签中，浏览器在解析html时，当检查到没有的属性时候会忽略，所以Thymeleaf的模板可以通过浏览器直接打开展现，这样非常有利于前后端的分离。 在Spring Boot中使用Thymeleaf，只需要引入下面依赖，并在默认的模板路径src/main/resources/templates下编写模板文件即可完成。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt; 在完成配置之后，举一个简单的例子，在快速入门工程的基础上，举一个简单的示例来通过Thymeleaf渲染一个页面。 controller里面加一个这个方法 1234567@RequestMapping(\"/\") public String index(ModelMap map){ // 加入一个属性,用来在模板中读取 map.addAttribute(\"host\",\"https://aaatao66.github.io/\"); // return模板文件的名称,对应 src/main/resources/templates/index.html return \"index\"; } HTML: 1234567891011&lt;!DOCTYPE html&gt;&lt;html lang=\"en\" xmlns:th=\"http://www.w3.org/1999/xhtml\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;/head&gt;&lt;body&gt;&lt;h1 th:text=\"${host}\"&gt;Hello World&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 如上页面，直接打开html页面展现Hello World，但是启动程序后，访问http://localhost:8080/，则是展示Controller中host的值：https://aaatao66.github.io/，做到了不破坏HTML自身内容的数据逻辑分离。 更多Thymeleaf的页面语法，还请访问Thymeleaf的官方文档查询使用:Thymeleaf官网 Thymeleaf的默认参数配置 如有需要修改默认配置的时候，只需复制下面要修改的属性到application.properties中，并修改成需要的值，如修改模板文件的扩展名，修改默认的模板路径等。 我使用的是 yml 方式,语法不同 ,如果你使用的是 properties 那么你可以参考一下: 123456789101112131415161718# Enable template caching.spring.thymeleaf.cache=true # Check that the templates location exists.spring.thymeleaf.check-template-location=true # Content-Type value.spring.thymeleaf.content-type=text/html # Enable MVC Thymeleaf view resolution.spring.thymeleaf.enabled=true # Template encoding.spring.thymeleaf.encoding=UTF-8 # Comma-separated list of view names that should be excluded from resolution.spring.thymeleaf.excluded-view-names= # Template mode to be applied to templates. See also StandardTemplateModeHandlers.spring.thymeleaf.mode=HTML5 # Prefix that gets prepended to view names when building a URL.spring.thymeleaf.prefix=classpath:/templates/ # Suffix that gets appended to view names when building a URL.spring.thymeleaf.suffix=.html spring.thymeleaf.template-resolver-order= # Order of the template resolver in the chain. spring.thymeleaf.view-names= # Comma-separated list of view names that can be resolved. 支持JSP的配置Spring Boot并不建议使用，但如果一定要使用,可以参考我上一篇文章","link":"/2019/05/26/springboot-web/"},{"title":"数据结构与算法(一) --初识数据结构","text":"你当然可以不用学习数据结构与算法这种麻烦的东西,你完全可以用别人已经封装好的工具拿来用, 但是,如果你只会使用工具,那注定这辈子只是个”码农”,所以我将在今天开始,陆陆续续补充自己的数据结构与算法知识, 可能节奏很慢,但是成功不是一夜暴富,而是每天都在循环渐进 一、 概述 数据结构l 什么是数据结构？​ 数据结构是指相互之间存在着一种或多种关系的数据元素的集合和该集合中数据元素之间的关系组成。 l 数据的存储结构顺序存储结构&gt;顺序存储结构：是把数据元素存放在地址连续的存储单元里，其数据间的逻辑关系和物理关系是一致的。数组就是顺序存储结构的典型代表。 链式存储结构&gt;链式存储结构：是把数据元素存放在内存中的任意存储单元里，也就是可以把数据存放在内存的各个位置。这些数据在内存中的地址可以是连续的，也可以是不连续的。 和顺序存储结构不同的是，链式存储结构的数据元素之间是通过指针来连接的，我们可以通使用指针来找到某个数据元素的位置，然后对这个数据元素进行一些操作。 顺序存储结构和链式存储结构的区别 l 数据的逻辑结构指反映数据元素之间的逻辑关系的数据结构，其中的逻辑关系是指数据元素之间的前后关系，而与他们在计算机中的存储位置无关。逻辑结构分为以下四类： 1.集合结构集合结构中的数据元素同属于一个集合，他们之间是并列的关系，除此之外没有其他关系。如下图，可以很好的表示集合结构中的元素之间的关系： 2.线性结构线性结构中的元素存在一对一的相互关系。 3.树形结构树形结构中的元素存在一对多的相互关系。 4.图形结构图形结构中的元素存在多对多的相互关系。","link":"/2019/05/23/数据结构与算法1/"},{"title":"HBase-API操作","text":"HBas是Hadoop数据库，是一个分布式，可扩展的大数据存储。 这一章博客不介绍如何搭建Hbase,只介绍API代码的编写 HBase官方网站: https://hbase.apache.org/ HBase中文文档: http://abloz.com/hbase/book.html 为什么要用Hbase?来看看官方解释: Apache HBase™ is the Hadoop database, a distributed, scalable, big data store. Use Apache HBase™ when you need random, realtime read/write access to your Big Data. This project’s goal is the hosting of very large tables – billions of rows X millions of columns – atop clusters of commodity hardware. Apache HBase is an open-source, distributed, versioned, non-relational database modeled after Google’s Bigtable: A Distributed Storage System for Structured Data by Chang et al. Just as Bigtable leverages the distributed data storage provided by the Google File System, Apache HBase provides Bigtable-like capabilities on top of Hadoop and HDFS. 大概意思是: 当你需要对大量数据进行随机,实时读/写的操作时,请使用HBase,该项目致力于非常量大的表-数十亿行&amp;百万列- 它是一个开源,面向列,分布式(包括高并发)的非关系数据库(NoSql),基于Hadoop,并存储在HDFS之上 这代表它能够运行在廉价的PC server上搭建大规模的结构化存储集群,关系型数据库无法满足数据疯狂增长的需求,但HBase可以! 我的开发环境 Linux-CentOs(VMware10虚拟机 3台) win10 idea 2019.1.1 jdk1.8 Maven 基本概念RowKey：是Byte array，是表中每条记录的“主键”，方便快速查找，Rowkey的设计非常重要，后面在重点讲讲我们在RowKey的设计上遇到过的坑。 Column Family：列族，拥有一个名称(string)，包含一个或者多个相关列 Column：属于某一个columnfamily，familyName:columnName，每条记录可动态添加 Version Number：类型为Long，默认值是系统时间戳，可由用户自定义 Value(Cell)：Byte array 创建HBase项目 创建一个普通的maven项目 导入依赖: 123456789101112131415&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt; &lt;artifactId&gt;hbase-client&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 创建类MyBaseAPI,编写代码,注意看注释 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176package com.ujiuye;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.hbase.*;import org.apache.hadoop.hbase.client.*;import org.apache.hadoop.hbase.util.Bytes;import org.junit.Before;import org.junit.Test;import java.util.ArrayList;import java.util.List;public class MyHBaseAPI { //此方法创建使用HBase的资源配置 private Configuration conf = null; @Before// 获取配置对象 public void getConfiguration() throws Exception { // 通过类提供的方法获取配置对象 conf = HBaseConfiguration.create(); conf.set(\"hbase.zookeeper.quorum\", \"hadoop101\"); conf.set(\"hbase.zookeeper.property.clientPort\", \"2181\"); } //判断表是否存在 @Test public void tableExist() throws Exception { // 1.拿到连接 Connection conn = ConnectionFactory.createConnection(conf); // 2.通过连接拿到hbase的客户端对象 HBaseAdmin admin = (HBaseAdmin) conn.getAdmin(); // 3.开始操作 boolean tableExist = admin.tableExists(\"user\"); if (tableExist) { System.out.println(\"表存在\"); } else { System.out.println(\"表不存在\"); } } //创建表 @Test public void createTable() throws Exception { // 1.拿到连接 Connection conn = ConnectionFactory.createConnection(conf); // 2.通过连接拿到 hbase 的客户端对象 HBaseAdmin admin = (HBaseAdmin) conn.getAdmin(); // 3.创建表描述器 HTableDescriptor tableDescriptor = new HTableDescriptor(TableName.valueOf(\"user\")); // 4.设置列族 tableDescriptor.addFamily(new HColumnDescriptor(\"info\")); // 5.执行 创建表 admin.createTable(tableDescriptor); System.out.println(\"表创建成功\"); } // 删除表 @Test public void deleteTable() throws Exception { // 1.拿到连接 Connection conn = ConnectionFactory.createConnection(conf); // 2.通过连接拿到 hbase 的客户端对象 HBaseAdmin admin = (HBaseAdmin) conn.getAdmin(); // 3,禁用表 admin.disableTable(\"user\"); // 4.删除表 admin.deleteTable(\"user\"); System.out.println(\"表删除成功\"); } //向表中插入数据 @Test public void insertData() throws Exception { // 1.拿到连接 Connection conn = ConnectionFactory.createConnection(conf); // 2.通过连接拿到 hbase 的客户端对象 HBaseAdmin admin = (HBaseAdmin) conn.getAdmin(); Table table = conn.getTable(TableName.valueOf(\"user\")); // 3. 封装数据,注意要用hbase提供的工具来转化为字节数组，不要用字符串的getBytes方法 Put put = new Put(Bytes.toBytes(\"1001\")); // 4.设置 列族 类名 值 put.addColumn(Bytes.toBytes(\"info\"), Bytes.toBytes(\"name\"), Bytes.toBytes(\"zhangsan\")); // 5. 向表中插入数据 table.put(put); } //批量插入数据 @Test public void insertDatas() throws Exception { // 拿到连接 Connection conn = ConnectionFactory.createConnection(conf); // 获取表 Table table = conn.getTable(TableName.valueOf(\"user\")); // 批量插入数据 Put put = new Put(Bytes.toBytes(\"1001\")); // 设置 列族 类名 值 put.addColumn(Bytes.toBytes(\"info\"), Bytes.toBytes(\"name\"), Bytes.toBytes(\"zhangsan\")); Put put2 = new Put(Bytes.toBytes(\"1002\")); // 设置 列族 类名 值 put2.addColumn(Bytes.toBytes(\"info\"), Bytes.toBytes(\"name\"), Bytes.toBytes(\"wangwu\")); List&lt;Put&gt; list = new ArrayList&lt;Put&gt;(); list.add(put); list.add(put2); table.put(list); // 关闭 table.close(); } // 删除一行数据 / 多行数据 @Test public void deleteData() throws Exception { // 1.拿到连接 Connection conn = ConnectionFactory.createConnection(conf); // 2.通过连接拿到 hbase 的客户端对象// HBaseAdmin admin = (HBaseAdmin) conn.getAdmin(); Table table = conn.getTable(TableName.valueOf(\"user\"));// Delete delete = new Delete(Bytes.toBytes(\"1002\"));// table.delete(delete); // 批量删除 Delete delete = new Delete(Bytes.toBytes(\"1001\")); Delete delete1 = new Delete(Bytes.toBytes(\"1002\")); List&lt;Delete&gt; list = new ArrayList&lt;Delete&gt;(); list.add(delete); list.add(delete1); table.delete(list); } // 获取所有数据 @Test public void getAllData() throws Exception { // 1.拿到连接 Connection conn = ConnectionFactory.createConnection(conf); // 2.获取表 Table table = conn.getTable(TableName.valueOf(\"user\")); // 3.构造一个 scan 对象 Scan scan = new Scan(Bytes.toBytes(\"\")); ResultScanner scanner = table.getScanner(scan); for (Result result : scanner) { Cell[] rawCells = result.rawCells();// 获取某一行数据 for (Cell cell : rawCells) { String row = Bytes.toString(CellUtil.cloneRow(cell)); String cf = Bytes.toString(CellUtil.cloneFamily(cell)); String cl = Bytes.toString(CellUtil.cloneQualifier(cell)); String va = Bytes.toString(CellUtil.cloneValue(cell)); System.out.println(row+\"---\"+cf+\"---\"+cl+\"---\"+va); } } } // 获取某一行数据,指定列族,列 @Test public void getSomeData() throws Exception{ // 1.拿到连接 和 表 Connection conn = ConnectionFactory.createConnection(conf); Table table = conn.getTable(TableName.valueOf(\"user\")); Get get = new Get(Bytes.toBytes(\"1001\")); Result result = table.get(get); Cell[] rawCells = result.rawCells();//获取某一行的所有数据 for (Cell cell : rawCells) { String row = Bytes.toString(CellUtil.cloneRow(cell)); String cf = Bytes.toString(CellUtil.cloneFamily(cell)); String cl = Bytes.toString(CellUtil.cloneQualifier(cell)); String va = Bytes.toString(CellUtil.cloneValue(cell)); System.out.println(row+\"---\"+cf+\"---\"+cl+\"---\"+va); } }} HBase Shell简单验证操作说几个HBase Shell的基本操作,不然都不知道怎么验证上面的代码 首先启动HBase [root@hadoop101 hbase] $ bin/start-hbase.sh 然后进入HBase Shell命令行操作 在Shell操作的时候如果需要后退直接按 Backspace 是不行的,必须Ctrl+Backspace [root@hadoop101 hbase]$ bin/hbase shell 查看当前数据库有哪些表 hbase(main):002:0&gt; list 查询表数据 scan+’表名’ STARTROW是开始行 到 STOPROW结束行,无STOPROW的话是到最后 hbase(main):008:0&gt; scan ‘student’ hbase(main):009:0&gt; scan ‘student’,{STARTROW =&gt; ‘1001’, STOPROW =&gt; ‘1002’} hbase(main):010:0&gt; scan ‘student’,{STARTROW =&gt; ‘1001’} 验证代码一个 scan 就够了, 内存优化HBase操作过程中需要大量的内存开销，毕竟Table是可以缓存在内存中的，一般会分配整个可用内存的70%给HBase的Java堆。但是不建议分配非常大的堆内存，因为GC过程持续太久会导致RegionServer处于长期不可用状态，一般16~48G内存就可以了，如果因为框架占用内存过高导致系统内存不足，框架一样会被系统服务拖死。 HBase在商业项目中的能力每天： 消息量：发送和接收的消息数超过60亿 将近1000亿条数据的读写 高峰期每秒150万左右操作 整体读取数据占有约55%，写入占有45% 超过2PB的数据，涉及冗余共6PB数据 数据每月大概增长300千兆字节。 我只是拿我自己的博客当一个笔记而已,如有类似,纯属雷同 关于我","link":"/2019/06/12/HBaseAPI/"},{"title":"Hadoop生态圈一文概览","text":"转自知乎: 如何形象的比喻大数据技术生态? 这些回答太好了,以致于我不禁想放到自己的博客上,文章末尾有原地址 有大数据,不得不提Google的3篇论文,大数据江湖因为这三篇论文兴起! 《Google file system》：论述了怎样借助普通机器有效的存储海量的大数据； 《Google MapReduce》：论述了怎样快速计算海量的数据； 《Google BigTable》：论述了怎样实现海量数据的快速查询； 中文版 大数据本身是个很宽泛的概念，Hadoop生态圈（或者泛生态圈）基本上都是为了处理超过单机尺度的数据处理而诞生的。你可以把它比作一个厨房所以需要的各种工具。锅碗瓢盆，各有各的用处，互相之间又有重合。你可以用汤锅直接当碗吃饭喝汤，你可以用小刀或者刨子去皮。但是每个工具有自己的特性，虽然奇怪的组合也能工作，但是未必是最佳选择。 大数据，首先你要能存的下大数据。传统的文件系统是单机的，不能横跨不同的机器。HDFS（Hadoop Distributed FileSystem）的设计本质上是为了大量的数据能横跨成百上千台机器，但是你看到的是一个文件系统而不是很多文件系统。比如你说我要获取/hdfs/tmp/file1的数据，你引用的是一个文件路径，但是实际的数据存放在很多不同的机器上。你作为用户，不需要知道这些，就好比在单机上你不关心文件分散在什么磁道什么扇区一样。HDFS为你管理这些数据。 存的下数据之后，你就开始考虑怎么处理数据。虽然HDFS可以为你整体管理不同机器上的数据，但是这些数据太大了。一台机器读取成T上P的数据（很大的数据哦，比如整个东京热有史以来所有高清电影的大小甚至更大），一台机器慢慢跑也许需要好几天甚至好几周。对于很多公司来说，单机处理是不可忍受的，比如微博要更新24小时热博，它必须在24小时之内跑完这些处理。那么我如果要用很多台机器处理，我就面临了如何分配工作，如果一台机器挂了如何重新启动相应的任务，机器之间如何互相通信交换数据以完成复杂的计算等等。这就是MapReduce / Tez / Spark的功能。MapReduce是第一代计算引擎，Tez和Spark是第二代。MapReduce的设计，采用了很简化的计算模型，只有Map和Reduce两个计算过程（中间用Shuffle串联），用这个模型，已经可以处理大数据领域很大一部分问题了。那什么是Map什么是Reduce？考虑如果你要统计一个巨大的文本文件存储在类似HDFS上，你想要知道这个文本里各个词的出现频率。你启动了一个MapReduce程序。Map阶段，几百台机器同时读取这个文件的各个部分，分别把各自读到的部分分别统计出词频，产生类似（hello, 12100次），（world，15214次）等等这样的Pair（我这里把Map和Combine放在一起说以便简化）；这几百台机器各自都产生了如上的集合，然后又有几百台机器启动Reduce处理。Reducer机器A将从Mapper机器收到所有以A开头的统计结果，机器B将收到B开头的词汇统计结果（当然实际上不会真的以字母开头做依据，而是用函数产生Hash值以避免数据串化。因为类似X开头的词肯定比其他要少得多，而你不希望数据处理各个机器的工作量相差悬殊）。然后这些Reducer将再次汇总，（hello，12100）＋（hello，12311）＋（hello，345881）= （hello，370292）。每个Reducer都如上处理，你就得到了整个文件的词频结果。这看似是个很简单的模型，但很多算法都可以用这个模型描述了。Map＋Reduce的简单模型很黄很暴力，虽然好用，但是很笨重。第二代的Tez和Spark除了内存Cache之类的新feature，本质上来说，是让Map/Reduce模型更通用，让Map和Reduce之间的界限更模糊，数据交换更灵活，更少的磁盘读写，以便更方便地描述复杂算法，取得更高的吞吐量。 有了MapReduce，Tez和Spark之后，程序员发现，MapReduce的程序写起来真麻烦。他们希望简化这个过程。这就好比你有了汇编语言，虽然你几乎什么都能干了，但是你还是觉得繁琐。你希望有个更高层更抽象的语言层来描述算法和数据处理流程。于是就有了Pig和Hive。Pig是接近脚本方式去描述MapReduce，Hive则用的是SQL。它们把脚本和SQL语言翻译成MapReduce程序，丢给计算引擎去计算，而你就从繁琐的MapReduce程序中解脱出来，用更简单更直观的语言去写程序了。 有了Hive之后，人们发现SQL对比Java有巨大的优势。一个是它太容易写了。刚才词频的东西，用SQL描述就只有一两行，MapReduce写起来大约要几十上百行。而更重要的是，非计算机背景的用户终于感受到了爱：我也会写SQL！于是数据分析人员终于从乞求工程师帮忙的窘境解脱出来，工程师也从写奇怪的一次性的处理程序中解脱出来。大家都开心了。Hive逐渐成长成了大数据仓库的核心组件。甚至很多公司的流水线作业集完全是用SQL描述，因为易写易改，一看就懂，容易维护。 自从数据分析人员开始用Hive分析数据之后，它们发现，Hive在MapReduce上跑，真鸡巴慢！流水线作业集也许没啥关系，比如24小时更新的推荐，反正24小时内跑完就算了。但是数据分析，人们总是希望能跑更快一些。比如我希望看过去一个小时内多少人在充气娃娃页面驻足，分别停留了多久，对于一个巨型网站海量数据下，这个处理过程也许要花几十分钟甚至很多小时。而这个分析也许只是你万里长征的第一步，你还要看多少人浏览了跳蛋多少人看了拉赫曼尼诺夫的CD，以便跟老板汇报，我们的用户是猥琐男闷骚女更多还是文艺青年／少女更多。你无法忍受等待的折磨，只能跟帅帅的工程师蝈蝈说，快，快，再快一点！于是Impala，Presto，Drill诞生了（当然还有无数非著名的交互SQL引擎，就不一一列举了）。三个系统的核心理念是，MapReduce引擎太慢，因为它太通用，太强壮，太保守，我们SQL需要更轻量，更激进地获取资源，更专门地对SQL做优化，而且不需要那么多容错性保证（因为系统出错了大不了重新启动任务，如果整个处理时间更短的话，比如几分钟之内）。这些系统让用户更快速地处理SQL任务，牺牲了通用性稳定性等特性。如果说MapReduce是大砍刀，砍啥都不怕，那上面三个就是剔骨刀，灵巧锋利，但是不能搞太大太硬的东西。 这些系统，说实话，一直没有达到人们期望的流行度。因为这时候又两个异类被造出来了。他们是Hive on Tez / Spark和SparkSQL。它们的设计理念是，MapReduce慢，但是如果我用新一代通用计算引擎Tez或者Spark来跑SQL，那我就能跑的更快。而且用户不需要维护两套系统。这就好比如果你厨房小，人又懒，对吃的精细程度要求有限，那你可以买个电饭煲，能蒸能煲能烧，省了好多厨具。 上面的介绍，基本就是一个数据仓库的构架了。底层HDFS，上面跑MapReduce／Tez／Spark，在上面跑Hive，Pig。或者HDFS上直接跑Impala，Drill，Presto。这解决了中低速数据处理的要求。 那如果我要更高速的处理呢？如果我是一个类似微博的公司，我希望显示不是24小时热博，我想看一个不断变化的热播榜，更新延迟在一分钟之内，上面的手段都将无法胜任。于是又一种计算模型被开发出来，这就是Streaming（流）计算。Storm是最流行的流计算平台。流计算的思路是，如果要达到更实时的更新，我何不在数据流进来的时候就处理了？比如还是词频统计的例子，我的数据流是一个一个的词，我就让他们一边流过我就一边开始统计了。流计算很牛逼，基本无延迟，但是它的短处是，不灵活，你想要统计的东西必须预先知道，毕竟数据流过就没了，你没算的东西就无法补算了。因此它是个很好的东西，但是无法替代上面数据仓库和批处理系统。 还有一个有些独立的模块是KV Store，比如Cassandra，HBase，MongoDB以及很多很多很多很多其他的（多到无法想象）。所以KV Store就是说，我有一堆键值，我能很快速滴获取与这个Key绑定的数据。比如我用身份证号，能取到你的身份数据。这个动作用MapReduce也能完成，但是很可能要扫描整个数据集。而KV Store专用来处理这个操作，所有存和取都专门为此优化了。从几个P的数据中查找一个身份证号，也许只要零点几秒。这让大数据公司的一些专门操作被大大优化了。比如我网页上有个根据订单号查找订单内容的页面，而整个网站的订单数量无法单机数据库存储，我就会考虑用KV Store来存。KV Store的理念是，基本无法处理复杂的计算，大多没法JOIN，也许没法聚合，没有强一致性保证（不同数据分布在不同机器上，你每次读取也许会读到不同的结果，也无法处理类似银行转账那样的强一致性要求的操作）。但是丫就是快。极快。每个不同的KV Store设计都有不同取舍，有些更快，有些容量更高，有些可以支持更复杂的操作。必有一款适合你。 除此之外，还有一些更特制的系统／组件，比如Mahout是分布式机器学习库，Protobuf是数据交换的编码和库，ZooKeeper是高一致性的分布存取协同系统，等等。 有了这么多乱七八糟的工具，都在同一个集群上运转，大家需要互相尊重有序工作。所以另外一个重要组件是，调度系统。现在最流行的是Yarn。你可以把他看作中央管理，好比你妈在厨房监工，哎，你妹妹切菜切完了，你可以把刀拿去杀鸡了。只要大家都服从你妈分配，那大家都能愉快滴烧菜。 你可以认为，大数据生态圈就是一个厨房工具生态圈。为了做不同的菜，中国菜，日本菜，法国菜，你需要各种不同的工具。而且客人的需求正在复杂化，你的厨具不断被发明，也没有一个万用的厨具可以处理所有情况，因此它会变的越来越复杂。 作者: xiaoyu Ma 学习很重要的是能将纷繁复杂的信息进行归类和抽象。对应到大数据技术体系，虽然各种技术百花齐放，层出不穷，但大数据技术本质上无非解决4个核心问题。 存储，海量的数据怎样有效的存储？主要包括hdfs、Kafka； 计算，海量的数据怎样快速计算？主要包括MapReduce、Spark、Flink等； 查询，海量数据怎样快速查询？主要为Nosql和Olap，Nosql主要包括Hbase、 Cassandra 等，其中olap包括kylin、impla等，其中Nosql主要解决随机查询，Olap技术主要解决关联查询； 挖掘，海量数据怎样挖掘出隐藏的知识？也就是当前火热的机器学习和深度学习等技术，包括TensorFlow、caffe、mahout等； 大数据技术生态其实是一个江湖…. 在一个夜黑风高的晚上，江湖第一大帮会Google三本阵法修炼秘籍流出，大数据技术江湖从此纷争四起、永无宁日… 这三本秘籍分别为： 《Google file system》：论述了怎样借助普通机器有效的存储海量的大数据； 《Google MapReduce》：论述了怎样快速计算海量的数据； 《Google BigTable》：论述了怎样实现海量数据的快速查询； 以上三篇论文秘籍是大数据入门的最好文章，通俗易懂，先看此三篇再看其它技术； 在Google三大秘籍流出之后，江湖上，致力于武学开放的apache根据这三本秘籍分别研究出了对应的武学巨著《hadoop》，并开放给各大门派研习，Hadoop包括三大部分，分别是hdfs、MapReduce和hbase：hdfs解决大数据的存储问题。mapreduce解决大数据的计算问题。hbase解决大数据量的查询问题。 之后，在各大门派的支持下，Hadoop不断衍生和进化各种分支流派，其中最激烈的当属计算技术，其次是查询技术。存储技术基本无太多变化，hdfs一统天下。 以下为大概的演进： 1，传统数据仓库派说你mapreduce修炼太复杂，老子不会编程，老子以前用sql吃遍天下，为了将这拨人收入门下，并降低大数据修炼难度，遂出了hive，pig、impla等SQL ON Hadoop的简易修炼秘籍； 2，伯克利派说你MapReduce只重招数，内力无法施展，且不同的场景需要修炼不同的技术，太过复杂，于是推出基于内力（内存）的《Spark》，意图解决所有大数据计算问题。 3，流式计算相关门派说你hadoop只能憋大招（批量计算），太麻烦，于是出了SparkStreaming、Storm，S4等流式计算技术，能够实现数据一来就即时计算。 4，apache看各大门派纷争四起，推出flink，想一统流计算和批量计算的修炼； 作者：有点文","link":"/2019/06/15/Hadoop生态圈一文概览/"},{"title":"Hadoop--Hello,Hadoop!","text":"Hadoop是什么? Hadoop是一个由Apache基金会所开发的分布式系统基础架构 集群：多个机器共同完成一件事 分布式：多个机器共同完成一件事，然后不同机器作用不同，各司其职 集群不一定是分布式，分布式一定是集群 主要解决，海量数据的存储和海量数据的分析计算问题。 广义上来说，HADOOP通常是指一个更广泛的概念——HADOOP生态圈 Hadoop发展历史 Lucene–Doug Cutting开创的开源软件，用Java书写代码，实现与Google类似的全文搜索功能，它提供了全文检索引擎的架构，包括完整的查询引擎和索引引擎 2001年年底成为apache基金会的一个子项目 对于大数量的场景，Lucene面对与Google同样的困难 学习和模仿Google解决这些问题的办法 ：微型版Nutch 可以说Google是hadoop的思想之源(Google在大数据方面的三篇论文)谷歌的三驾马车 ​ GFS —&gt;HDFS google File System—&gt; hadoop distriduted file system ​ Map-Reduce —&gt;MR map reduce ​ BigTable —&gt;Hbase 2003-2004年，Google公开了部分GFS和Mapreduce思想的细节，以此为基础Doug Cutting等人用了2年业余时间实现了DFS和Mapreduce机制，使Nutch性能飙升 2005 年Hadoop 作为 Lucene的子项目 Nutch的一部分正式引入Apache基金会。2006 年 3 月份，Map-Reduce和Nutch Distributed File System (NDFS) 分别被纳入称为 Hadoop 的项目中 名字来源于Doug Cutting儿子的玩具大象 Hadoop就此诞生并迅速发展，标志这第三次信息化浪潮时代（大数据、云计算、物联网）来临 Hadoop三大发行版本Hadoop 三大发行版本: Apache、Cloudera、Hortonworks。 Apache版本最原始（最基础）的版本，对于入门学习最好。 Cloudera在大型互联网企业中用的较多。 Hortonworks文档较好。 Apache Hadoop 官网地址：http://hadoop.apache.org/releases.html 下载地址：https://archive.apache.org/dist/hadoop/common/ Cloudera Hadoop 官网地址：https://www.cloudera.com/downloads/cdh/5-10-0.html 下载地址：http://archive-primary.cloudera.com/cdh5/cdh/5/ （1）2008年成立的Cloudera是最早将Hadoop商用的公司，为合作伙伴提供Hadoop的商用解决方案，主要是包括支持、咨询服务、培训。 （2）2009年Hadoop的创始人Doug Cutting也加盟Cloudera公司。Cloudera产品主要为CDH，Cloudera Manager，Cloudera Support （3）CDH是Cloudera的Hadoop发行版，完全开源，比Apache Hadoop在兼容性，安全性，稳定性上有所增强。 （4）Cloudera Manager是集群的软件分发及管理监控平台，可以在几个小时内部署好一个Hadoop集群，并对集群的节点及服务进行实时监控。Cloudera Support即是对Hadoop的技术支持。 （5）Cloudera的标价为每年每个节点4000美元。Cloudera开发并贡献了可实时处理大数据的Impala项目。 Hortonworks Hadoop 官网地址：https://hortonworks.com/products/data-center/hdp/ 下载地址：https://hortonworks.com/downloads/#data-platform （1）2011年成立的Hortonworks是雅虎与硅谷风投公司Benchmark Capital合资组建。 （2）公司成立之初就吸纳了大约25名至30名专门研究Hadoop的雅虎工程师，上述工程师均在2005年开始协助雅虎开发Hadoop，贡献了Hadoop80%的代码。 （3）雅虎工程副总裁、雅虎Hadoop开发团队负责人Eric Baldeschwieler出任Hortonworks的首席执行官。 （4）Hortonworks的主打产品是Hortonworks Data Platform（HDP），也同样是100%开源的产品，HDP除常见的项目外还包括了Ambari，一款开源的安装和管理系统。 （5）HCatalog，一个元数据管理系统，HCatalog现已集成到Facebook开源的Hive中。Hortonworks的Stinger开创性的极大的优化了Hive项目。Hortonworks为入门提供了一个非常好的，易于使用的沙盒。 （6）Hortonworks开发了很多增强特性并提交至核心主干，这使得Apache Hadoop能够在包括Window Server和Windows Azure在内的microsoft Windows平台上本地运行。定价以集群为基础，每10个节点每年为12500美元。 Hadoop的优势1）高可靠性：因为Hadoop假设计算元素和存储会出现故障，因为它维护多个工作数据副本，在出现故障时可以对失败的节点重新分布处理。 2）高扩展性：在集群间分配任务数据，可方便的扩展数以千计的节点。 3）高效性：在MapReduce的思想下，Hadoop是并行工作的，以加快任务处理速度。 4）高容错性：自动保存多份副本数据，并且能够自动将失败的任务重新分配。 Hadoop组成1）Hadoop HDFS：（hadoop distribute file system ）一个高可靠、高吞吐量的分布式文件系统。 2）Hadoop MapReduce：一个分布式的离线并行计算框架。 3）Hadoop YARN：作业调度与集群资源管理的框架。 4）Hadoop Common：支持其他模块的工具模块（Configuration、RPC、序列化机制、日志操作）。 HDFS架构概述 YARN架构概述 ResourceManager(rm)：处理客户端请求、启动/监控ApplicationMaster、监控NodeManager、资源分配与调度； NodeManager(nm)：单个节点上的资源管理、处理来自ResourceManager的命令、处理来自ApplicationMaster的命令； ApplicationMaster：数据切分、为应用程序申请资源，并分配给内部任务、任务监控与容错。 Container：对任务运行环境的抽象，封装了CPU、内存等多维资源以及环境变量、启动命令等任务运行相关的信息。 主从结构：master/slave MapReduce架构概述MapReduce将计算过程分为两个阶段：Map（映射）和Reduce（归约） Map阶段并行处理输入数据 Reduce阶段对Map结果进行汇总 大数据技术生态体系 图中涉及的技术名词解释如下： Sqoop：sqoop是一款开源的工具，主要用于在Hadoop(Hive)与传统的数据库(mysql)间进行数据的传递，可以将一个关系型数据库（例如 ： MySQL ,Oracle 等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。 Flume：Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。 Kafka：Kafka是一种高吞吐量的分布式发布订阅消息系统，有如下特性： （1）通过O(1)的磁盘数据结构提供消息的持久化，这种结构对于即使数以TB的消息存储也能够保持长时间的稳定性能。 （2）高吞吐量：即使是非常普通的硬件Kafka也可以支持每秒数百万的消息 （3）支持通过Kafka服务器和消费机集群来分区消息。 （4）支持Hadoop并行数据加载。 Storm：Storm为分布式实时计算提供了一组通用原语，可被用于“流处理”之中，实时处理消息并更新数据库。这是管理队列及工作者集群的另一种方式。 Storm也可被用于“连续计算”（continuous computation），对数据流做连续查询，在计算时就将结果以流的形式输出给用户。 Spark：Spark是当前最流行的开源大数据内存计算框架。可以基于Hadoop上存储的大数据进行计算。 Oozie：Oozie是一个管理Hadoop作业（job）的工作流程调度管理系统。Oozie协调作业就是通过时间（频率）和有效数据触发当前的Oozie工作流程。 Hbase：HBase是一个分布式的、面向列的开源数据库。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。 Hive：hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。 其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。 R语言：R是用于统计分析、绘图的语言和操作环境。R是属于GNU系统的一个自由、免费、源代码开放的软件，它是一个用于统计计算和统计制图的优秀工具。 Mahout: Apache Mahout是个可扩展的机器学习和数据挖掘库，当前Mahout支持主要的4个用例： 推荐挖掘：搜集用户动作并以此给用户推荐可能喜欢的事物。 聚集：收集文件并进行相关文件分组。 分类：从现有的分类文档中学习，寻找文档中的相似特征，并为无标签的文档进行正确的归类。 频繁项集挖掘：将一组项分组，并识别哪些个别项会经常一起出现。 ZooKeeper：Zookeeper是Google的Chubby一个开源的实现。它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、 分布式同步、组服务等。ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。 推荐系统框架图","link":"/2019/05/31/hadoop/"},{"title":"Spring Boot--你好Spring Boot(一)","text":"spring boot可以让你的开发更甜蜜~~ Build Anything with Spring Boot： Spring Boot is the starting point for building all Spring-based applications. Spring Boot is designed to get you up and running as quickly as possible, with minimal upfront nfiguration of Spring. Spring Boot 简化了 spring 应用开发的框架 官方文档: 世界上最好的文档来自官方 一.使用 Spring Boot有什么好处?以及简单的搭建过程其实就是简单、快速、方便！平时如果我们需要搭建一个 Spring Web 项目的时候需要怎么做呢？ 1）配置 web.xml，加载 Spring 和 Spring mvc 2）配置数据库连接、配置 Spring 事务 3）配置加载配置文件的读取，开启注解 4）配置日志文件 … 配置完成之后部署 Tomcat 调试 … 现在非常流行微服务，如果我这个项目仅仅只是需要发送一个邮件，如果我的项目仅仅是生产一个积分；我都需要这样折腾一遍! 但是如果使用 Spring Boot 呢？很简单，我仅仅只需要非常少的几个配置就可以迅速方便的搭建起来一套 Web 项目或者是构建一个微服务！ 1.开发环境:idea jdk1.8 windows 10 Mysql 2.创建项目使用idea new一个 Spring Lnitializr &gt; 设置group Artifact &gt;选择web&gt;勾选web&gt;设置项目路径还有名称&gt;Finish 第一次创建会有点慢,它需要下载很多依赖 创建好之后的包默认生成了以下&gt; SpringbootApplication： 一个带有 main() 方法的类，用于启动应用程序 SpringbootApplicationTests：一个空的 Junit 测试了，它加载了一个使用 Spring Boot 字典配置功能的 Spring 应用程序上下文 application.properties：一个空的 properties 文件，可以根据需要添加配置属性 pom.xml： Maven 构建说明文件 3.创建一个controller包,再创建HelloController类:1234567891011121314package com.carson.springboot.controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class HelloController { @RequestMapping(\"hello\") public String hello(){ return \"Spring boot!\"; }} @RestController 注解： 该注解是 @Controller 和 @ResponseBody 注解的合体版 4.启动SpringbootApplication:人家启动成功的图标: 再看看我的😭: 有可能是分辨率还是什么关系? 启动SpringbootApplication: SpringbootApplication启动后,它内置了tomcat ,不需要我们另外进行配置,我们可以直接访问 controller 中的 方法 端口号默认是 8080 可能你的不是,但是他会再控制台输出: 这是页面: 5.解析以下 Spring Boot 项目pom.xml: 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.carson&lt;/groupId&gt; &lt;artifactId&gt;springboot&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;springboot&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; &lt;parent&gt; :这个标签是在配置 Spring Boot 的父级依赖： 123456&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; spring-boot-starter-parent 是一个特殊的 starter ，它用来提供相关的 Maven 默认依赖，使用它之后，常用的包依赖就可以省去 version 标签。 &gt;应用入口类Spring Boot 项目通常有一个名为 *Application 的入口类，入口类里有一个 main 方法， 这个 main 方法其实就是一个标准的 Javay 应用的入口方法。 @SpringBootApplication 是 Spring Boot 的核心注解，它是一个组合注解，该注解组合了： @Configuration、@EnableAutoConfiguration、@ComponentScan； 若不是用 @SpringBootApplication 注解也可以使用这三个注解代替。 其中，@EnableAutoConfiguration 让 Spring Boot 根据类路径中的 jar 包依赖为当前项目进行自动配置，例如，添加了 spring-boot-starter-web 依赖，会自动添加 Tomcat 和 Spring MVC 的依赖，那么 Spring Boot 会对 Tomcat 和 Spring MVC 进行自动配置。 Spring Boot 还会自动扫描 @SpringBootApplication 所在类的同级包以及下级包里的 Bean ，所以入口类建议就配置在 grounpID + arctifactID 组合的包名下（这里为 cn.wmyskxz.springboot 包） &gt;Spring Boot 的配置文件Spring Boot 使用一个全局的配置文件 application.properties 或 application.yml，放置在【src/main/resources】目录或者类路径的 /config 下。 Spring Boot 不仅支持常规的 properties 配置文件，还支持 yaml 语言的配置文件。yaml 是以数据为中心的语言，在配置数据的时候具有面向对象的特征。 Spring Boot 的全局配置文件的作用是对一些默认配置的配置值进行修改。 我把 application.properties 删掉了,我创建了 application.yml , 因为我感觉yml的语法更加的适合我 我这里使用 application.yml 进行配置(两者在语法上不同): 1234567serber: port: 8080 servlet: context-path: /hellostudent: name: carson age: 18 我们同样的将 Tomcat 默认端口设置为 8080 ，并将默认的访问路径从 “/” 修改为 “/hello”,并设置自己的信息 先去创建一个类 StudentProperties : 1234567891011121314151617181920212223242526272829package com.carson.springboot.domain;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.stereotype.Component;@Component@ConfigurationProperties(prefix = \"student\")public class StudentProperties { private String name; private Integer age; public String getName() { return name; } public void setName(String name) { this.name = name; } public Integer getAge() { return age; } public void setAge(Integer age) { this.age = age; }} 我们可以把配置信息封装成一个类，首先在我们的 name 和 age 前加一个 student 前缀，然后新建一个 StudentProperties 的类用来封装这些信息，并用上两个注解： @Component：表明当前类是一个 Java Bean @ConfigurationProperties(prefix = “student”)：表示获取前缀为 sutdent 的配置信息 我们的Controller修改成以下: 12345678@Autowired private StudentProperties studentProperties; @RequestMapping(\"/hello\") public String hello(){ return studentProperties.getName() + studentProperties.getAge(); //会在页面显示我们的信息 } &gt;Spring Boot 热部署在目前的 Spring Boot 项目中，当发生了任何修改之后我们都需要重新启动才能够正确的得到效果，这样会略显麻烦，Spring Boot 提供了热部署的方式，当发现任何类发生了改变，就会通过 JVM 类加载的方式，加载最新的类到虚拟机中，这样就不需要重新启动也能看到修改后的效果了。 做法也很简单，修改 pom.xml 即可！ 我们往 pom.xml 中添加一个依赖就可以了： 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;!-- 这个需要为 true 热部署才有效 --&gt;&lt;/dependency&gt; 重新启动 Spring Boot ，然后修改任意代码，就能观察到控制台的自动重启现象 关于idea Spring Boot 项目的简单搭建 已经结束 二.Spring Boot 使用上面已经完成了 Spring Boot 项目的简单搭建，我们仅仅需要进行一些简单的设置，写一个 HelloController 就能够直接运行了，不要太简单…接下来我们再深入了解一下 Spring Boot 的使用。 1.使Spring Boot 支持 JSPSpring Boot 的默认视图支持是 Thymeleaf 模板引擎，但是这个我们不熟悉啊，我们还是想要使用 JSP 怎么办呢？ 第一步：修改 pom.xml 增加对 JSP 文件的支持 1234567891011121314151617&lt;!-- servlet依赖. --&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- tomcat的支持.--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 第二步：配置试图重定向 JSP 文件的位置 修改 application.yml 文件，将我们的 JSP 文件重定向到 /WEB-INF/views/ 目录下(设置前缀和后缀)： 123456spring: mvc: view: prefix: /WEB-INF/views/ suffix: .jsp //如果你学过ssm 那么你能感觉出来这是 前缀 和 后缀 第三步：修改 HelloController 修改 @RestController 注解为 @Controller ，然后将 hello 方法修改为： 1234567891011121314151617181920212223242526272829package com.carson.springboot.controller;import com.carson.springboot.domain.StudentProperties;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import java.text.DateFormat;import java.util.Date;/** * @RestController 注解： 该注解是 @Controller 和 @ResponseBody 注解的合体版 * * */@Controllerpublic class HelloController {// @Autowired// private StudentProperties studentProperties; @RequestMapping(\"/hello\") public String hello(Model model){ model.addAttribute(\"now\", DateFormat.getDateTimeInstance().format(new Date())); return \"hello\"; }} 第四步：新建 hello.jsp 文件 在【src/main】目录下依次创建 webapp&gt;WEB-INF&gt;views 目录，并创建一个 hello.jsp 文件： hello.jsp 1234567891011&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;login&lt;/title&gt;&lt;/head&gt;&lt;body&gt;hello jsp! 现在时间是 ${now}&lt;/body&gt;&lt;/html&gt; 第五步：刷新网页 因为我们部署了热部署功能，所以只需要等待控制台重启信息完成之后再刷新网页就可以看到正确效果了： 2.集成 MyBatis 第一步：修改 pom.xml 增加对 MySql和 MyBatis 的支持 12345678910111213&lt;!-- mybatis --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt;&lt;/dependency&gt;&lt;!-- mysql --&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.21&lt;/version&gt;&lt;/dependency&gt; 第二步：新增数据库链接参数 我这里使用我之前 ssm 整合时的 user 表: yml文件&gt; 1234567891011121314151617181920serber: port: 8080 servlet: context-path: /liststudent: name: carson age: 18spring: mvc: view: prefix: /WEB-INF/views/ suffix: .jsp datasource: url: jdbc:mysql:///ssm username: root password: root driver-class-name: com.mysql.jdbc.Driver jpa: hibernate: ddl-auto: update url中的localhost ,可以用/// 代替 hibernate下面有几个参数: validate 加载 Hibernate 时，验证创建数据库表结构 create 每次加载 Hibernate ，重新创建数据库表结构，这就是导致数据库表数据丢失的原因。 create-drop 加载 Hibernate 时创建，退出是删除表结构 update 加载 Hibernate 自动更新数据库结构 如果你想保留表结构的数据，使用 update 即可。 第三步：创建 Student 实体类和 StudentMapper 映射类 在【com.carson.springboot】下的【domain】包，然后在其下创建一个 User 类： 123456789101112131415161718192021package com.carson.springboot.domain;import lombok.*;import java.math.BigDecimal;@Getter@Setter@AllArgsConstructor@NoArgsConstructor@ToStringpublic class User { private Long id; private String username; private String password; private int age; private BigDecimal salary; /*各种 setter getter tostring 全参,无参构造*/} 在【com.carson.springboot】下创建mapper包，然后在其下创建一个 UserMapper映射类： 1234567891011121314package com.carson.springboot.mapper;import com.carson.springboot.domain.User;import org.apache.ibatis.annotations.Mapper;import org.apache.ibatis.annotations.Select;import java.util.List;@Mapperpublic interface UserMapper { //sql语句直接写在注解上 @Select(\"select * from user\") List&lt;User&gt; list();} 第四步：编写 StudentController 在【com.carson.springboot】下新建一个【controller】包，然后在其下创建一个UserController ： 1234567891011121314151617181920212223package com.carson.springboot.controller;import com.carson.springboot.domain.User;import com.carson.springboot.mapper.UserMapper;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;import java.util.List;@Controllerpublic class UserController { @Autowired private UserMapper userMapper; @RequestMapping(\"list\") public String list(Model model){ List&lt;User&gt; users = userMapper.list(); model.addAttribute(\"users\",users); return \"list\"; }} 第五步：编写 listStudent.jsp 文件 我们简化一下 JSP 的文件，仅显示两个字段的数据： 123456789101112131415161718192021222324252627282930&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;%@ taglib uri=\"http://java.sun.com/jsp/jstl/core\" prefix=\"c\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;list&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;table align='center' border='1' cellspacing='0'&gt; &lt;tr&gt; &lt;td&gt;id&lt;/td&gt; &lt;td&gt;name&lt;/td&gt; &lt;td&gt;age&lt;/td&gt; &lt;td&gt;salary&lt;/td&gt; &lt;td&gt;password&lt;/td&gt; &lt;/tr&gt; &lt;c:forEach items=\"${users}\" var=\"s\" varStatus=\"st\"&gt; &lt;tr&gt; &lt;td&gt;${s.id}&lt;/td&gt; &lt;td&gt;${s.username}&lt;/td&gt; &lt;td&gt;${s.age}&lt;/td&gt; &lt;td&gt;${s.salary}&lt;/td&gt; &lt;td&gt;${s.password}&lt;/td&gt; &lt;/tr&gt; &lt;/c:forEach&gt;&lt;/table&gt;&lt;/body&gt;&lt;/html&gt; 第六步：重启服务器运行 因为往 pom.xml 中新增加了依赖的包，所以自动重启服务器没有作用，我们需要手动重启一次， 然后在地址输入：localhost:8080/list查看效果： 总结以下我遇到的错误: 这里说我的数据源有问题👇 ​ ​ 我的yml配置文件之前是这样的: 12345678910111213spring: mvc: view: prefix: /WEB-INF/views/ suffix: .jsp datasource: url: jdbc:mysql:///ssm username: root password: root driver-class-name: com.mysql.jdbc.Driverjpa: hibernate: ddl-auto: update jpa这个字段单独出来了,它应该是跟 datasource和mvc字段 同级, 而不是跟spring同级 改正: 12345678910111213spring: mvc: view: prefix: /WEB-INF/views/ suffix: .jsp datasource: url: jdbc:mysql:///ssm username: root password: root driver-class-name: com.mysql.jdbc.Driver jpa: hibernate: ddl-auto: update 这次的spring boot学习过程,还算顺利,终究要感谢网路上这么多优秀的前辈,他们写的博客非常优秀,以至于给我的学习过程给予很大的帮助 终于知道了spring boot的强大,相对我的上一篇博客写的ssm框架整合,少了很多配置文件,看起来很清爽","link":"/2019/05/25/springboot/"},{"title":"SSM框架整合回顾(一)","text":"Spring + springMVC + MyBatis 实现 登录+增删改查+分页查询 开发环境:win10 , jdk1.8 , idea 2019.1.1 , tomcat 8.5.38 , maven , pageHelp 以上工具一定要有 pom.xml 文件:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140&lt;properties&gt; &lt;project.srping.version&gt;5.0.0.RELEASE&lt;/project.srping.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--Spring的依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;${project.srping.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;${project.srping.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;${project.srping.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;${project.srping.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;${project.srping.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;${project.srping.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 德鲁伊连接池 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.9&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.38&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.5&lt;/version&gt; &lt;/dependency&gt; &lt;!--mybatis和Spring的整合--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;!--日志--&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.20&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.8.13&lt;/version&gt; &lt;/dependency&gt; &lt;!--PageHelper分页插件--&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;5.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt; Mybatis于Spring的整合 applicationContext.xml:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd\"&gt; &lt;!--引入属性配置文件--&gt; &lt;context:property-placeholder location=\"classpath:db.properties\" system-properties-mode=\"NEVER\"/&gt; &lt;!--德鲁伊连接池--&gt; &lt;bean id=\"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"${driverClassName}\"/&gt; &lt;property name=\"url\" value=\"${url}\"/&gt; &lt;property name=\"username\" value=\"${username}\"/&gt; &lt;property name=\"password\" value=\"${password}\"/&gt; &lt;/bean&gt; &lt;!--sqlsessionfactory对象--&gt; &lt;bean id=\"sqlSessionFactoryBean\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;!--配置连接池--&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;!--关联mybatis主配置文件--&gt; &lt;property name=\"configLocation\" value=\"classpath:mybatis.xml\"/&gt; &lt;!--配置别名--&gt; &lt;property name=\"typeAliasesPackage\" value=\"com.ujiuye.domain\"/&gt; &lt;!--关联mapper映射文件--&gt; &lt;property name=\"mapperLocations\" value=\"classpath:com/ujiuye/mapper/*.xml\"/&gt; &lt;/bean&gt; &lt;!--配置mapper接口的扫描器--&gt; &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;!--从哪个包扫描mapper接口--&gt; &lt;property name=\"basePackage\" value=\"com.ujiuye.mapper\"/&gt; &lt;/bean&gt; &lt;!-- ioc 注解扫描器--&gt; &lt;context:component-scan base-package=\"com.ujiuye\"/&gt; &lt;!--配置事务管理器--&gt; &lt;tx:annotation-driven /&gt; &lt;bean id=\"txManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;/bean&gt; &lt;!--配置事务--&gt; &lt;aop:config&gt; &lt;!--配置where--&gt; &lt;aop:pointcut id=\"txPointcut\" expression=\"execution(* com.ujiuye.service..*.*(..))\"/&gt; &lt;!--切面--&gt; &lt;aop:advisor advice-ref=\"txAdvice\" pointcut-ref=\"txPointcut\"/&gt; &lt;/aop:config&gt; &lt;!--增强器--&gt; &lt;tx:advice id=\"txAdvice\" transaction-manager=\"txManager\"&gt; &lt;tx:attributes&gt; &lt;tx:method name=\"list*\" read-only=\"true\"/&gt; &lt;tx:method name=\"get*\" read-only=\"true\"/&gt; &lt;tx:method name=\"select*\" read-only=\"true\"/&gt; &lt;tx:method name=\"find*\" read-only=\"true\"/&gt; &lt;tx:method name=\"query*\" read-only=\"true\"/&gt; &lt;tx:method name=\"*\"/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt;&lt;/beans&gt; applicationCoutext.xml文件总结: 事务中我给查询的方法加上了 read-only=”true”,只读状态可以提高性能 没有配置read-only的method默认非只读 SpringMVC.xml的配置:1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd\"&gt; &lt;!--引入后台的spring的配置文件--&gt; &lt;import resource=\"classpath:applicationContext.xml\"/&gt; &lt;!--视图解析器--&gt; &lt;bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"&gt; &lt;!--配置前缀--&gt; &lt;property name=\"prefix\" value=\"/WEB-INF/views/\"/&gt; &lt;!--配置后缀--&gt; &lt;property name=\"suffix\" value=\".jsp\"/&gt; &lt;/bean&gt; &lt;!--SpringMVC注解解析器--&gt; &lt;mvc:annotation-driven/&gt; &lt;!--拦截器--&gt; &lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;!--拦截的路径/*一级路径 /**所有路径--&gt; &lt;mvc:mapping path=\"/**\"/&gt; &lt;!--排除登录页面--&gt; &lt;mvc:exclude-mapping path=\"/login.do\"/&gt; &lt;bean class=\"com.ujiuye.interceptor.LoginInterceptor\"&gt;&lt;/bean&gt; &lt;/mvc:interceptor&gt; &lt;/mvc:interceptors&gt;&lt;/beans&gt; 拦截器: 必须让用户登录才能进入到更深层的jsp,然后 /** 表示拦截所有,但是我们要排除login这个登录页面 等一下要配置一下拦截的类 MyBatis.xml:123456789101112131415&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;!-- pagehelp拦截器配置--&gt; &lt;plugins&gt; &lt;!-- com.github.pagehelper为PageHelper类所在包名 --&gt; &lt;plugin interceptor=\"com.github.pagehelper.PageInterceptor\"&gt; &lt;!-- 使用下面的方式配置参数，后面会有所有的参数介绍 --&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/configuration&gt; plugins在配置文件中的位置必须符合要求，否则会报错，顺序如下: properties?, settings?, typeAliases?, typeHandlers?, objectFactory?,objectWrapperFactory?, plugins?, environments?, databaseIdProvider?, mappers? web.xml:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd\" version=\"3.1\" metadata-complete=\"true\"&gt; &lt;!--前端控制器--&gt; &lt;servlet&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!--spring的配置文件--&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:SpringMVC.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;!--tomcat启动时初始化--&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;!--*.do意思是访问页面的时候后缀要加上 .do--&gt; &lt;url-pattern&gt;*.do&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!--请求编码过滤器--&gt; &lt;filter&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceRequestEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceResponseEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!--设置欢迎页,意思是登录页,以前默认index.jsp,现在是login.jsp--&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;login.jsp&lt;/welcome-file&gt; &lt;/welcome-file-list&gt;&lt;/web-app&gt; controller:LoginController&gt;1234567891011121314151617181920212223242526272829303132333435package com.ujiuye.controller;import com.ujiuye.domain.User;import com.ujiuye.service.IUserService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;import javax.servlet.http.HttpSession;@Controllerpublic class LoginController { @Autowired private IUserService userService; //登录方法 @RequestMapping(\"login\") public String login(String username, String password, HttpSession session, Model model){ User user = userService.selectLogin(username, password); if (user!=null){ //user对象放入session作用域 session.setAttribute(\"USER_IN_SESSION\",user); //跳转到用户列表页面 return \"redirect:/user/query.do\"; }else { //跳转到登录页面,提示用户名或密码错误 model.addAttribute(\"msg\",\"用户名或者密码错误\"); return \"forward:/login.jsp\"; } }} 如果登录密码是正确的,那么这里的 user 是不为 null的,他就会跳转到用户列表页面, 如果密码错误,还会跳的登录页, UserController&gt;1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package com.ujiuye.controller;import com.github.pagehelper.PageInfo;import com.ujiuye.domain.User;import com.ujiuye.qo.QueryObject;import com.ujiuye.result.PageResult;import com.ujiuye.service.IUserService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.ModelAttribute;import org.springframework.web.bind.annotation.RequestMapping;import java.util.List;@Controller@RequestMapping(\"user\")public class UserController { @Autowired private IUserService service; //多条件查询 + 分页 @RequestMapping(\"query\") public String query(@ModelAttribute(\"qo\") QueryObject qo,Model model){// PageResult result = service.query2(qo);// model.addAttribute(\"result\",result); PageInfo pageInfo = service.query3(qo); model.addAttribute(\"pageInfo\",pageInfo); return \"user/list\"; } //查询列表的方法 @RequestMapping(\"list\") public String list(Model model){ List&lt;User&gt; list = service.list(); model.addAttribute(\"list\",list); return \"user/list\"; } //跳转到用户编辑页面 @RequestMapping(\"edit\") public String edit(Long id,Model model){ if (id!=null){ User user = service.get(id); //往前台传数据 model.addAttribute(\"user\",user); } return \"user/edit\"; } //保存 @RequestMapping(\"saveOrUpdate\") public String saveOrUpdate(User user){ //判断user对象中的id的值,从而区分是在做新增还是修改 if (user.getId()==null){ service.save(user); }else { service.update(user); } return \"redirect:/user/list.do\"; } //删除 @RequestMapping(\"delete\") public String delete(Long id){ //删除操作 service.delete(id); return \"redirect:/user/list.do\"; }} domain 实体类:123456789101112131415161718192021package com.ujiuye.domain;import lombok.*;import java.math.BigDecimal;@Setter@Getter@AllArgsConstructor@NoArgsConstructor@ToStringpublic class User { private Long id; private String username; private String password; private Integer age; private BigDecimal salary;} interceptor登录检查&gt;LoginInterceptor:123456789101112131415161718192021222324package com.ujiuye.interceptor;import org.springframework.web.servlet.HandlerInterceptor;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import javax.servlet.http.HttpSession;public class LoginInterceptor implements HandlerInterceptor { //登录检查,实现接口里的这个方法 public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { //判断session中是否有\"USER_IN_SESSION\"的key HttpSession session = request.getSession(); Object user = session.getAttribute(\"USER_IN_SESSION\"); if (user == null){ //跳转到登录页面 response.sendRedirect(\"login.jsp\"); return false; } return true; }} 刚刚在LoginController定义了if else,如果登录 !=null 那么session里会有 USER_IN_SESSION 这个key,return ture 如果为null 就会跳转到登录页面; 实现HandlerInterceptor接口: HandlerInterceptor 接口中定义了三个方法，我们就是通过这三个方法来对用户的请求进行拦截处理的。 （1 ）preHandle (HttpServletRequest request, HttpServletResponse response, Object handle) 方法， 顾名思义，该方法将在请求处理之前进行调用。SpringMVC 中的Interceptor 是链式的调用的，在一个应用中或者说是在一个请求中可以同时存在多个Interceptor 。每个Interceptor 的调用会依据它的声明顺序依次执行，而且最先执行的都是Interceptor 中的preHandle 方法，所以可以在这个方法中进行一些前置初始化操作或者是对当前请求的一个预处理，也可以在这个方法中进行一些判断来决定请求是否要继续进行下去。该方法的返回值是布尔值Boolean 类型的，当它返回为false 时，表示请求结束，后续的Interceptor 和Controller 都不会再执行；当返回值为true 时就会继续调用下一个Interceptor 的preHandle 方法，如果已经是最后一个Interceptor 的时候就会是调用当前请求的Controller 方法。 （2 ）postHandle (HttpServletRequest request, HttpServletResponse response, Object handle, ModelAndView modelAndView) 方法， 由preHandle 方法的解释我们知道这个方法包括后面要说到的afterCompletion 方法都只能是在当前所属的Interceptor 的preHandle 方法的返回值为true 时才能被调用。postHandle 方法，顾名思义就是在当前请求进行处理之后，也就是Controller 方法调用之后执行，但是它会在DispatcherServlet 进行视图返回渲染之前被调用，所以我们可以在这个方法中对Controller 处理之后的ModelAndView 对象进行操作。postHandle 方法被调用的方向跟preHandle 是相反的，也就是说先声明的Interceptor 的postHandle 方法反而会后执行，这和Struts2 里面的Interceptor 的执行过程有点类型。Struts2 里面的Interceptor 的执行过程也是链式的，只是在Struts2 里面需要手动调用ActionInvocation 的invoke 方法来触发对下一个Interceptor 或者是Action 的调用，然后每一个Interceptor 中在invoke 方法调用之前的内容都是按照声明顺序执行的，而invoke 方法之后的内容就是反向的。 （3 ）afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handle, Exception ex) 方法， 该方法也是需要当前对应的Interceptor 的preHandle 方法的返回值为true时才会执行。顾名思义，该方法将在整个请求结束之后，也就是在DispatcherServlet 渲染了对应的视图之后执行。这个方法的主要作用是用于进行资源清理工作的。 mapper(dao):UserMapper.java&gt;12345678910111213141516171819202122232425262728293031package com.ujiuye.mapper;import com.ujiuye.domain.User;import com.ujiuye.qo.BaseQueryObject;import com.ujiuye.qo.QueryObject;import org.apache.ibatis.annotations.Param;import java.util.List;public interface UserMapper { //增删改查 void save(User user); void update(User user); void delete(Long id); //查单独一个 User get(Long id); //查询所有 List&lt;User&gt; list(); //登录查询 User selectLogin(@Param(\"username\") String username, @Param(\"password\") String password); List&lt;User&gt; query(QueryObject qo); //查询结果集中的数据 List&lt;User&gt; queryForList(BaseQueryObject qo); //查询总条数 int queryForCount(QueryObject qo);} UserMapper.xml&gt;1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" &gt;&lt;mapper namespace=\"com.ujiuye.mapper.UserMapper\"&gt; &lt;insert id=\"save\" useGeneratedKeys=\"true\" keyProperty=\"id\" keyColumn=\"id\"&gt; insert into user(username,password,age,salary) values (#{username},#{password},#{age},#{salary}) &lt;/insert&gt; &lt;update id=\"update\"&gt; update user set username=#{username},password=#{password},age=#{age}, salary=#{salary} where id =#{id} &lt;/update&gt; &lt;delete id=\"delete\"&gt; delete from user where id=#{id} &lt;/delete&gt; &lt;select id=\"get\" resultType=\"com.ujiuye.domain.User\"&gt; select * from user where id=#{id} &lt;/select&gt; &lt;select id=\"list\" resultType=\"User\"&gt; select * from user &lt;/select&gt; &lt;select id=\"selectLogin\" resultType=\"com.ujiuye.domain.User\"&gt; select id,username,password,age,salary from user where username=#{username} and password=#{password} &lt;/select&gt; &lt;select id=\"query\" resultType=\"com.ujiuye.domain.User\"&gt; select id,username,password,age,salary from user &lt;where&gt; &lt;if test=\"username!=null and username!='' \"&gt; and username like concat('%',#{username},'%') &lt;/if&gt; &lt;if test=\"salary!=null\"&gt; and salary = #{salary} &lt;/if&gt; &lt;/where&gt; &lt;/select&gt; &lt;select id=\"queryForCount\" resultType=\"int\"&gt; select count(*) from user &lt;where&gt; &lt;if test=\"username!=null and username!='' \"&gt; and username like concat('%',#{username},'%') &lt;/if&gt; &lt;if test=\"salary!=null\"&gt; and salary = #{salary} &lt;/if&gt; &lt;/where&gt; &lt;/select&gt; &lt;select id=\"queryForList\" resultType=\"User\"&gt; select * from user &lt;where&gt; &lt;if test=\"username!=null and username!='' \"&gt; and username like concat('%',#{username},'%') &lt;/if&gt; &lt;if test=\"salary!=null\"&gt; and salary = #{salary} &lt;/if&gt; &lt;/where&gt; limit #{start},#{pageSize} &lt;/select&gt;&lt;/mapper&gt; mapper映射文件可以跟java文件放在同一个目录下,因为pom里配置了: 12345678910&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt; qo(分页):BaseQueryObject&gt;1234567891011121314151617package com.ujiuye.qo;import lombok.Getter;import lombok.Setter;@Setter@Getterpublic class BaseQueryObject { private Integer currentPage = 1; private Integer pageSize = 3; public Integer getStart(){ return (this.currentPage-1)*this.pageSize; }} DepartmentQueryObject&gt;123456package com.ujiuye.qo;public class DepartemntQueryObject { private String deptName;} QueryObject&gt;12345678910111213package com.ujiuye.qo;import lombok.Getter;import lombok.Setter;import java.math.BigDecimal;@Getter@Setterpublic class QueryObject extends BaseQueryObject { private String username; private BigDecimal salary;} result:123456789101112131415161718192021222324252627282930313233343536package com.ujiuye.result;import lombok.Getter;import lombok.Setter;import java.util.Collections;import java.util.List;@Setter@Getterpublic class PageResult { //结果集 数据 private List&lt;?&gt; data; //总的条数 private Integer totalCount; //计算出来 //上一页 private Integer prevPage; //下一页 private Integer nextPage; //尾页 private Integer endPage; //计算方法 public PageResult(List&lt;?&gt; data, Integer totalCount, Integer currentPage, Integer pageSize) { this.data = data; this.totalCount = totalCount; this.prevPage= currentPage-1&gt;1?currentPage-1:1; this.endPage=totalCount%pageSize == 0?totalCount/pageSize:totalCount/pageSize+1; this.nextPage = currentPage+1&lt;endPage?currentPage+1:endPage; } public static PageResult EMPTY_LIST = new PageResult(Collections.emptyList(),0,1,1);} service 层:接口&gt;12345678910111213141516171819202122232425262728293031package com.ujiuye.service;import com.alibaba.druid.sql.PagerUtils;import com.github.pagehelper.PageInfo;import com.ujiuye.domain.User;import com.ujiuye.qo.BaseQueryObject;import com.ujiuye.qo.QueryObject;import com.ujiuye.result.PageResult;import java.util.List;public interface IUserService { //增 void save(User user); //改 void update(User user); //删 void delete(Long id); //查单个 User get(Long id); //查询所有 List&lt;User&gt; list(); //登录方法 User selectLogin(String username,String password); List&lt;User&gt; query(QueryObject qo); PageResult query2(QueryObject qo); PageInfo query3(QueryObject qo);} UserServiceImpl 实现类&gt;12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576package com.ujiuye.service.impl;import com.github.pagehelper.PageHelper;import com.github.pagehelper.PageInfo;import com.ujiuye.domain.User;import com.ujiuye.mapper.UserMapper;import com.ujiuye.qo.BaseQueryObject;import com.ujiuye.qo.QueryObject;import com.ujiuye.result.PageResult;import com.ujiuye.service.IUserService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import java.util.Collections;import java.util.List;@Servicepublic class UserServiceImpl implements IUserService { private static PageResult EMPTY_LIST = new PageResult(Collections.emptyList(), 0, 1, 1); @Autowired private UserMapper userMapper; public void save(User user) { userMapper.save(user); } public void update(User user) { userMapper.update(user); } public void delete(Long id) { userMapper.delete(id); } public User get(Long id) { return userMapper.get(id); } public List&lt;User&gt; list() { return userMapper.list(); } public User selectLogin(String username, String password) { return userMapper.selectLogin(username, password); } public List&lt;User&gt; query(QueryObject qo) { return userMapper.query(qo); } public PageResult query2(QueryObject qo) { //查询总的条数qo int totlaCount = userMapper.queryForCount(qo); if(totlaCount == 0){ //返回空结果集 return PageResult.EMPTY_LIST; } //查询结果集数据 List&lt;User&gt; data = userMapper.queryForList(qo); return new PageResult(data,totlaCount,qo.getCurrentPage(),qo.getPageSize()); } public PageInfo query3(QueryObject qo) { PageHelper.startPage(qo.getCurrentPage(),qo.getPageSize()); List&lt;User&gt; list = userMapper.query(qo); return new PageInfo(list); }} Test:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182package com.ujiuye.test;import com.github.pagehelper.PageHelper;import com.github.pagehelper.PageInfo;import com.ujiuye.domain.User;import com.ujiuye.mapper.UserMapper;import com.ujiuye.service.IUserService;import org.apache.ibatis.session.SqlSessionFactory;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;import java.math.BigDecimal;import java.util.List;@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(\"classpath:applicationContext.xml\")public class App { @Autowired private SqlSessionFactory sqlSessionFactory; @Autowired private UserMapper userMapper; @Autowired private IUserService service; private User user = null; @Test public void testSave(){ user = new User(null,\"特朗普\",\"123\",30,new BigDecimal(\"1.00\")); service.save(user); } @Test public void testUpdate(){ user = new User(2L,\"奥巴马\",\"123\",12,new BigDecimal(\"2000.00\")); service.update(user); } @Test public void testDelete(){ service.delete(9L); } @Test public void testGet(){ System.out.println(service.get(7L)); } @Test public void testList(){ System.out.println(service.list()); } @Test public void testLogin(){ user = service.selectLogin(\"扎克伯格\",\"456\"); System.out.println(user); } @Test public void testPageHelper(){ PageHelper.startPage(2,3); List&lt;User&gt; list = userMapper.list(); PageInfo pageInfo = new PageInfo(list); System.out.println(pageInfo.getList().get(0)); System.out.println(pageInfo.getList().get(1)); System.out.println(pageInfo.getList().get(2)); System.out.println(\"上一页:\"+pageInfo.getPrePage()); System.out.println(\"下一页:\"+pageInfo.getNextPage()); System.out.println(\"总页数:\"+pageInfo.getSize()); System.out.println(\"首页:\"+pageInfo.getNavigateFirstPage()); System.out.println(\"尾页:\"+pageInfo.getNavigateLastPage()); }} 前台:我的前台很丑不过还是放一下吧&gt; edit.jsp 用户编辑页面&gt;1234567891011121314151617&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;用户编辑页面&lt;/h1&gt;&lt;form action=\"/user/saveOrUpdate.do\" method=\"post\"&gt; &lt;input type=\"hidden\" value=\"${user.id}\" name=\"id\"&gt; 姓名:&lt;input type=\"text\" name=\"username\" value=\"${user.username}\"&gt;&lt;br&gt; 密码:&lt;input type=\"text\" name=\"password\" value=\"${user.password}\"&gt;&lt;br&gt; 年龄:&lt;input type=\"text\" name=\"age\" value=\"${user.age}\"&gt;&lt;br&gt; 月薪:&lt;input type=\"text\" name=\"salary\" value=\"${user.salary}\"&gt;&lt;br&gt; &lt;input type=\"submit\" value=\"ok!~\"&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; list.jsp 主页面&gt;123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;%@taglib prefix=\"c\" uri=\"http://java.sun.com/jsp/jstl/core\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script&gt; function goPage(page) { //修改currentPage文本框的值 if(page != undefined){ document.getElementById(\"currentPage\").value = page; } //提交分页查询的表单 var pageForm = document.getElementById(\"pageForm\"); pageForm.submit(); } &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;form id=\"pageForm\" action=\"/user/query.do\" method=\"post\"&gt; &lt;h1&gt;用户列表&lt;/h1&gt; &lt;table&gt; &lt;tr&gt; 姓名:&lt;input type=\"text\" name=\"username\" value=\"${qo.username}\"&gt; 工资:&lt;input type=\"text\" name=\"salary\" value=\"${qo.salary}\"&gt; &lt;input type=\"submit\" value=\"查询\"&gt; &lt;/tr&gt; &lt;/table&gt; &lt;a href=\"/user/edit.do\"&gt;新增&lt;/a&gt; &lt;br/&gt; &lt;table border=\"1\" width=\"60%\"&gt; &lt;tr&gt; &lt;th&gt;编号&lt;/th&gt; &lt;th&gt;姓名&lt;/th&gt; &lt;th&gt;年龄&lt;/th&gt; &lt;th&gt;工资&lt;/th&gt; &lt;th&gt;操作&lt;/th&gt; &lt;/tr&gt; &lt;c:forEach items=\"${pageInfo.list}\" var=\"user\"&gt; &lt;tr&gt; &lt;td&gt;${user.id}&lt;/td&gt; &lt;td&gt;${user.username}&lt;/td&gt; &lt;td&gt;${user.age}&lt;/td&gt; &lt;td&gt;${user.salary}&lt;/td&gt; &lt;td&gt; &lt;a href=\"/user/edit.do?id=${user.id}\"&gt;修改&lt;/a&gt; &lt;a href=\"/user/delete.do?id=${user.id}\"&gt;删除&lt;/a&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/c:forEach&gt; &lt;tr&gt; &lt;td colspan=\"5\"&gt; &lt;a href=\"javascript:void(0);\" onclick=\"goPage(1)\"&gt;首页&lt;/a&gt; &lt;a href=\"javascript:void(0);\" onclick=\"goPage(${pageInfo.prePage})\"&gt;上一页&lt;/a&gt; &lt;a href=\"javascript:void(0);\" onclick=\"goPage(${pageInfo.nextPage})\"&gt;下一页&lt;/a&gt; &lt;a href=\"javascript:void(0);\" onclick=\"goPage(${pageInfo.navigateLastPage})\"&gt;尾页&lt;/a&gt; 每个显示 &lt;select name=\"pageSize\" onchange=\"goPage(1)\"&gt; &lt;option value=\"3\" ${qo.pageSize == 3?\"selected\":\"\"}&gt;3&lt;/option&gt; &lt;option value=\"5\" ${qo.pageSize == 5?\"selected\":\"\"}&gt;5&lt;/option&gt; &lt;option value=\"10\" ${qo.pageSize == 10?\"selected\":\"\"}&gt;10&lt;/option&gt; &lt;/select&gt; 条 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;input type=\"text\" id=\"currentPage\" name=\"currentPage\" style=\"width: 50px\" value=\"${qo.currentPage}\"&gt; &lt;button onclick=\"goPage()\"&gt;跳转&lt;/button&gt; 总共${pageInfo.total}条/共${pageInfo.navigateLastPage}页 &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; login.jsp&gt;12345678910111213141516&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;login&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;登录&lt;/h1&gt;&lt;%--如果获取到msg说明密码错误--%&gt;&lt;font color=\"red\"&gt;${msg}&lt;/font&gt; &lt;form action=\"/login.do\" method=\"post\"&gt; 账号:&lt;input type=\"text\" name=\"username\"&gt; &lt;br&gt; 密码:&lt;input type=\"text\" name=\"password\"&gt;&lt;br&gt; &lt;input type=\"submit\" value=\"登录\"&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt;","link":"/2019/05/24/ssm/"}],"tags":[],"categories":[{"name":"博客搭建","slug":"博客搭建","link":"/categories/博客搭建/"},{"name":"Hello World!","slug":"Hello-World","link":"/categories/Hello-World/"},{"name":"Spring Boot","slug":"Spring-Boot","link":"/categories/Spring-Boot/"},{"name":"数据结构与算法","slug":"数据结构与算法","link":"/categories/数据结构与算法/"},{"name":"Hadoop生态圈","slug":"Hadoop生态圈","link":"/categories/Hadoop生态圈/"}]}